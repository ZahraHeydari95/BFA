{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c6560bee066c48e798a49a3b8ebffa12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8776de44b43340779dc2479f529775f4",
              "IPY_MODEL_85ef706bc53540dfbb9910d9db61a9e1",
              "IPY_MODEL_dd368c3363f340949ab20e33931de20c"
            ],
            "layout": "IPY_MODEL_0c3996257662477884c62f6f038b8d1c"
          }
        },
        "8776de44b43340779dc2479f529775f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dfced125709b4fea9ce8651c61ec285e",
            "placeholder": "​",
            "style": "IPY_MODEL_80cae95c0fc64d519168422fe6b1bf5f",
            "value": "100%"
          }
        },
        "85ef706bc53540dfbb9910d9db61a9e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7838ae2dc7054316ad80e72cc42f98d8",
            "max": 170498071,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5880749a1ccc4f3aa4d2e2357eb09848",
            "value": 170498071
          }
        },
        "dd368c3363f340949ab20e33931de20c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_382a78a4fd2848329df46fb3882714c5",
            "placeholder": "​",
            "style": "IPY_MODEL_ae38dd56b8e040cab4d4846d813ff79f",
            "value": " 170498071/170498071 [00:03&lt;00:00, 54697526.24it/s]"
          }
        },
        "0c3996257662477884c62f6f038b8d1c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dfced125709b4fea9ce8651c61ec285e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "80cae95c0fc64d519168422fe6b1bf5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7838ae2dc7054316ad80e72cc42f98d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5880749a1ccc4f3aa4d2e2357eb09848": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "382a78a4fd2848329df46fb3882714c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ae38dd56b8e040cab4d4846d813ff79f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9cc746289f49468ea8202f4a4a660577": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_42f18a78f8024de2a6f7f4b8d2355a19",
              "IPY_MODEL_29a3a9e3229e4475a1b1a93b98762bd6",
              "IPY_MODEL_fcc6dacf100842fd9c24effc700fafe8"
            ],
            "layout": "IPY_MODEL_c1a7e50170074b0d992b51e38a4c4a1a"
          }
        },
        "42f18a78f8024de2a6f7f4b8d2355a19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a3f49f0893bc42b68b0dc97c6d407244",
            "placeholder": "​",
            "style": "IPY_MODEL_dde9f7af6d0b4eac81286f9508ee0ff3",
            "value": "100%"
          }
        },
        "29a3a9e3229e4475a1b1a93b98762bd6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1f4a2cbc2b7346a1b3df787343acb816",
            "max": 46827520,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6e577595f3d947f4a804e7e2fb4a74f6",
            "value": 46827520
          }
        },
        "fcc6dacf100842fd9c24effc700fafe8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3ed963a4272c4f1ab7d6541dd0bc6641",
            "placeholder": "​",
            "style": "IPY_MODEL_ccf4b1ec45f84102aeef0b2db9510664",
            "value": " 44.7M/44.7M [00:01&lt;00:00, 38.4MB/s]"
          }
        },
        "c1a7e50170074b0d992b51e38a4c4a1a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a3f49f0893bc42b68b0dc97c6d407244": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dde9f7af6d0b4eac81286f9508ee0ff3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1f4a2cbc2b7346a1b3df787343acb816": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e577595f3d947f4a804e7e2fb4a74f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3ed963a4272c4f1ab7d6541dd0bc6641": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ccf4b1ec45f84102aeef0b2db9510664": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RVA8zavxfHLk"
      },
      "source": [
        "-------------------------------------------------------\n",
        "**Defending and Harnessing the Bit-Flip based Adversarial Weight Attack**\n",
        "-------------------------------------------------------\n",
        "\n",
        "**CVPR2020 paper**\n",
        "\n",
        "**Implemented with changes on google colab by zahra heydari**\n",
        "-------------------------------------------------------\n",
        "\n",
        "**IPM**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GPU Specifications**"
      ],
      "metadata": {
        "id": "GTvBXBZKKJtp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xTSz0GPsD6B2",
        "outputId": "9e5d225a-9682-40dc-dfab-806fc124ecc2"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Nov 15 05:18:56 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   48C    P8    10W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7DEa8-jMkhcf"
      },
      "source": [
        "**Number of cuda device**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "rc44xw6spJRM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5c9989d-a058-4eb1-f880-b2642547b3e8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import torch\n",
        "torch.cuda.device_count()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dCna0jILe8NX"
      },
      "source": [
        "# **Install Conda on Google Colab**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "4qWGuGjtHxX0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d92efa9e-c412-4544-fb33-c280b4d9e384"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-11-15 05:19:03--  https://repo.anaconda.com/miniconda/Miniconda3-py37_4.10.3-Linux-x86_64.sh\n",
            "Resolving repo.anaconda.com (repo.anaconda.com)... 104.16.130.3, 104.16.131.3, 2606:4700::6810:8303, ...\n",
            "Connecting to repo.anaconda.com (repo.anaconda.com)|104.16.130.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 89026327 (85M) [application/x-sh]\n",
            "Saving to: ‘Miniconda3-py37_4.10.3-Linux-x86_64.sh’\n",
            "\n",
            "Miniconda3-py37_4.1 100%[===================>]  84.90M  45.8MB/s    in 1.9s    \n",
            "\n",
            "2022-11-15 05:19:05 (45.8 MB/s) - ‘Miniconda3-py37_4.10.3-Linux-x86_64.sh’ saved [89026327/89026327]\n",
            "\n",
            "PREFIX=/usr/local\n",
            "Unpacking payload ...\n",
            "Collecting package metadata (current_repodata.json): - \b\b\\ \b\bdone\n",
            "Solving environment: / \b\b- \b\b\\ \b\bdone\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "  added / updated specs:\n",
            "    - _libgcc_mutex==0.1=main\n",
            "    - _openmp_mutex==4.5=1_gnu\n",
            "    - brotlipy==0.7.0=py37h27cfd23_1003\n",
            "    - ca-certificates==2021.7.5=h06a4308_1\n",
            "    - certifi==2021.5.30=py37h06a4308_0\n",
            "    - cffi==1.14.6=py37h400218f_0\n",
            "    - chardet==4.0.0=py37h06a4308_1003\n",
            "    - conda-package-handling==1.7.3=py37h27cfd23_1\n",
            "    - conda==4.10.3=py37h06a4308_0\n",
            "    - cryptography==3.4.7=py37hd23ed53_0\n",
            "    - idna==2.10=pyhd3eb1b0_0\n",
            "    - ld_impl_linux-64==2.35.1=h7274673_9\n",
            "    - libffi==3.3=he6710b0_2\n",
            "    - libgcc-ng==9.3.0=h5101ec6_17\n",
            "    - libgomp==9.3.0=h5101ec6_17\n",
            "    - libstdcxx-ng==9.3.0=hd4cf53a_17\n",
            "    - ncurses==6.2=he6710b0_1\n",
            "    - openssl==1.1.1k=h27cfd23_0\n",
            "    - pip==21.1.3=py37h06a4308_0\n",
            "    - pycosat==0.6.3=py37h27cfd23_0\n",
            "    - pycparser==2.20=py_2\n",
            "    - pyopenssl==20.0.1=pyhd3eb1b0_1\n",
            "    - pysocks==1.7.1=py37_1\n",
            "    - python==3.7.10=h12debd9_4\n",
            "    - readline==8.1=h27cfd23_0\n",
            "    - requests==2.25.1=pyhd3eb1b0_0\n",
            "    - ruamel_yaml==0.15.100=py37h27cfd23_0\n",
            "    - setuptools==52.0.0=py37h06a4308_0\n",
            "    - six==1.16.0=pyhd3eb1b0_0\n",
            "    - sqlite==3.36.0=hc218d9a_0\n",
            "    - tk==8.6.10=hbc83047_0\n",
            "    - tqdm==4.61.2=pyhd3eb1b0_1\n",
            "    - urllib3==1.26.6=pyhd3eb1b0_1\n",
            "    - wheel==0.36.2=pyhd3eb1b0_0\n",
            "    - xz==5.2.5=h7b6447c_0\n",
            "    - yaml==0.2.5=h7b6447c_0\n",
            "    - zlib==1.2.11=h7b6447c_3\n",
            "\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  _libgcc_mutex      pkgs/main/linux-64::_libgcc_mutex-0.1-main\n",
            "  _openmp_mutex      pkgs/main/linux-64::_openmp_mutex-4.5-1_gnu\n",
            "  brotlipy           pkgs/main/linux-64::brotlipy-0.7.0-py37h27cfd23_1003\n",
            "  ca-certificates    pkgs/main/linux-64::ca-certificates-2021.7.5-h06a4308_1\n",
            "  certifi            pkgs/main/linux-64::certifi-2021.5.30-py37h06a4308_0\n",
            "  cffi               pkgs/main/linux-64::cffi-1.14.6-py37h400218f_0\n",
            "  chardet            pkgs/main/linux-64::chardet-4.0.0-py37h06a4308_1003\n",
            "  conda              pkgs/main/linux-64::conda-4.10.3-py37h06a4308_0\n",
            "  conda-package-han~ pkgs/main/linux-64::conda-package-handling-1.7.3-py37h27cfd23_1\n",
            "  cryptography       pkgs/main/linux-64::cryptography-3.4.7-py37hd23ed53_0\n",
            "  idna               pkgs/main/noarch::idna-2.10-pyhd3eb1b0_0\n",
            "  ld_impl_linux-64   pkgs/main/linux-64::ld_impl_linux-64-2.35.1-h7274673_9\n",
            "  libffi             pkgs/main/linux-64::libffi-3.3-he6710b0_2\n",
            "  libgcc-ng          pkgs/main/linux-64::libgcc-ng-9.3.0-h5101ec6_17\n",
            "  libgomp            pkgs/main/linux-64::libgomp-9.3.0-h5101ec6_17\n",
            "  libstdcxx-ng       pkgs/main/linux-64::libstdcxx-ng-9.3.0-hd4cf53a_17\n",
            "  ncurses            pkgs/main/linux-64::ncurses-6.2-he6710b0_1\n",
            "  openssl            pkgs/main/linux-64::openssl-1.1.1k-h27cfd23_0\n",
            "  pip                pkgs/main/linux-64::pip-21.1.3-py37h06a4308_0\n",
            "  pycosat            pkgs/main/linux-64::pycosat-0.6.3-py37h27cfd23_0\n",
            "  pycparser          pkgs/main/noarch::pycparser-2.20-py_2\n",
            "  pyopenssl          pkgs/main/noarch::pyopenssl-20.0.1-pyhd3eb1b0_1\n",
            "  pysocks            pkgs/main/linux-64::pysocks-1.7.1-py37_1\n",
            "  python             pkgs/main/linux-64::python-3.7.10-h12debd9_4\n",
            "  readline           pkgs/main/linux-64::readline-8.1-h27cfd23_0\n",
            "  requests           pkgs/main/noarch::requests-2.25.1-pyhd3eb1b0_0\n",
            "  ruamel_yaml        pkgs/main/linux-64::ruamel_yaml-0.15.100-py37h27cfd23_0\n",
            "  setuptools         pkgs/main/linux-64::setuptools-52.0.0-py37h06a4308_0\n",
            "  six                pkgs/main/noarch::six-1.16.0-pyhd3eb1b0_0\n",
            "  sqlite             pkgs/main/linux-64::sqlite-3.36.0-hc218d9a_0\n",
            "  tk                 pkgs/main/linux-64::tk-8.6.10-hbc83047_0\n",
            "  tqdm               pkgs/main/noarch::tqdm-4.61.2-pyhd3eb1b0_1\n",
            "  urllib3            pkgs/main/noarch::urllib3-1.26.6-pyhd3eb1b0_1\n",
            "  wheel              pkgs/main/noarch::wheel-0.36.2-pyhd3eb1b0_0\n",
            "  xz                 pkgs/main/linux-64::xz-5.2.5-h7b6447c_0\n",
            "  yaml               pkgs/main/linux-64::yaml-0.2.5-h7b6447c_0\n",
            "  zlib               pkgs/main/linux-64::zlib-1.2.11-h7b6447c_3\n",
            "\n",
            "\n",
            "Preparing transaction: / \b\b- \b\b\\ \b\bdone\n",
            "Executing transaction: / \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\bdone\n",
            "installation finished.\n",
            "WARNING:\n",
            "    You currently have a PYTHONPATH environment variable set. This may cause\n",
            "    unexpected behavior when running the Python interpreter in Miniconda3.\n",
            "    For best results, please verify that your PYTHONPATH only points to\n",
            "    directories of packages that are compatible with the Python interpreter\n",
            "    in Miniconda3: /usr/local\n",
            "Collecting package metadata (current_repodata.json): ...working... done\n",
            "Solving environment: ...working... done\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "  added / updated specs:\n",
            "    - python=3.7\n",
            "    - ujson\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    ca-certificates-2022.10.11 |       h06a4308_0         124 KB\n",
            "    certifi-2022.9.24          |   py37h06a4308_0         154 KB\n",
            "    conda-22.9.0               |   py37h06a4308_0         878 KB\n",
            "    openssl-1.1.1s             |       h7f8727e_0         3.6 MB\n",
            "    toolz-0.12.0               |   py37h06a4308_0         104 KB\n",
            "    ujson-1.35                 |   py37h14c3975_0          25 KB\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:         4.8 MB\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  toolz              pkgs/main/linux-64::toolz-0.12.0-py37h06a4308_0\n",
            "  ujson              pkgs/main/linux-64::ujson-1.35-py37h14c3975_0\n",
            "\n",
            "The following packages will be UPDATED:\n",
            "\n",
            "  ca-certificates                       2021.7.5-h06a4308_1 --> 2022.10.11-h06a4308_0\n",
            "  certifi                          2021.5.30-py37h06a4308_0 --> 2022.9.24-py37h06a4308_0\n",
            "  conda                               4.10.3-py37h06a4308_0 --> 22.9.0-py37h06a4308_0\n",
            "  openssl                                 1.1.1k-h27cfd23_0 --> 1.1.1s-h7f8727e_0\n",
            "\n",
            "\n",
            "Preparing transaction: ...working... done\n",
            "Verifying transaction: ...working... done\n",
            "Executing transaction: ...working... done\n",
            "Collecting package metadata (current_repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n",
            "Solving environment: | \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\bdone\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "  added / updated specs:\n",
            "    - conda\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    _openmp_mutex-5.1          |            1_gnu          21 KB\n",
            "    cffi-1.15.1                |   py37h74dc2b5_0         227 KB\n",
            "    charset-normalizer-2.0.4   |     pyhd3eb1b0_0          35 KB\n",
            "    conda-package-handling-1.9.0|   py37h5eee18b_1         945 KB\n",
            "    cryptography-38.0.1        |   py37h9ce1e76_0         1.3 MB\n",
            "    idna-3.4                   |   py37h06a4308_0          91 KB\n",
            "    ld_impl_linux-64-2.38      |       h1181459_1         654 KB\n",
            "    libgcc-ng-11.2.0           |       h1234567_1         5.3 MB\n",
            "    libgomp-11.2.0             |       h1234567_1         474 KB\n",
            "    libstdcxx-ng-11.2.0        |       h1234567_1         4.7 MB\n",
            "    ncurses-6.3                |       h5eee18b_3         781 KB\n",
            "    pycosat-0.6.4              |   py37h5eee18b_0          84 KB\n",
            "    pycparser-2.21             |     pyhd3eb1b0_0          94 KB\n",
            "    pyopenssl-22.0.0           |     pyhd3eb1b0_0          50 KB\n",
            "    readline-8.2               |       h5eee18b_0         357 KB\n",
            "    requests-2.28.1            |   py37h06a4308_0          92 KB\n",
            "    setuptools-65.5.0          |   py37h06a4308_0         1.1 MB\n",
            "    sqlite-3.39.3              |       h5082296_0         1.1 MB\n",
            "    tk-8.6.12                  |       h1ccaba5_0         3.0 MB\n",
            "    tqdm-4.64.1                |   py37h06a4308_0         126 KB\n",
            "    urllib3-1.26.12            |   py37h06a4308_0         181 KB\n",
            "    xz-5.2.6                   |       h5eee18b_0         394 KB\n",
            "    zlib-1.2.13                |       h5eee18b_0         103 KB\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:        21.1 MB\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  charset-normalizer pkgs/main/noarch::charset-normalizer-2.0.4-pyhd3eb1b0_0 None\n",
            "\n",
            "The following packages will be REMOVED:\n",
            "\n",
            "  chardet-4.0.0-py37h06a4308_1003\n",
            "  pip-21.1.3-py37h06a4308_0\n",
            "  six-1.16.0-pyhd3eb1b0_0\n",
            "  wheel-0.36.2-pyhd3eb1b0_0\n",
            "\n",
            "The following packages will be UPDATED:\n",
            "\n",
            "  _openmp_mutex                                   4.5-1_gnu --> 5.1-1_gnu None\n",
            "  cffi                                1.14.6-py37h400218f_0 --> 1.15.1-py37h74dc2b5_0 None\n",
            "  conda-package-han~                   1.7.3-py37h27cfd23_1 --> 1.9.0-py37h5eee18b_1 None\n",
            "  cryptography                         3.4.7-py37hd23ed53_0 --> 38.0.1-py37h9ce1e76_0 None\n",
            "  idna               pkgs/main/noarch::idna-2.10-pyhd3eb1b~ --> pkgs/main/linux-64::idna-3.4-py37h06a4308_0 None\n",
            "  ld_impl_linux-64                        2.35.1-h7274673_9 --> 2.38-h1181459_1 None\n",
            "  libgcc-ng                               9.3.0-h5101ec6_17 --> 11.2.0-h1234567_1 None\n",
            "  libgomp                                 9.3.0-h5101ec6_17 --> 11.2.0-h1234567_1 None\n",
            "  libstdcxx-ng                            9.3.0-hd4cf53a_17 --> 11.2.0-h1234567_1 None\n",
            "  ncurses                                    6.2-he6710b0_1 --> 6.3-h5eee18b_3 None\n",
            "  pycosat                              0.6.3-py37h27cfd23_0 --> 0.6.4-py37h5eee18b_0 None\n",
            "  pycparser                                       2.20-py_2 --> 2.21-pyhd3eb1b0_0 None\n",
            "  pyopenssl                             20.0.1-pyhd3eb1b0_1 --> 22.0.0-pyhd3eb1b0_0 None\n",
            "  readline                                   8.1-h27cfd23_0 --> 8.2-h5eee18b_0 None\n",
            "  requests           pkgs/main/noarch::requests-2.25.1-pyh~ --> pkgs/main/linux-64::requests-2.28.1-py37h06a4308_0 None\n",
            "  setuptools                          52.0.0-py37h06a4308_0 --> 65.5.0-py37h06a4308_0 None\n",
            "  sqlite                                  3.36.0-hc218d9a_0 --> 3.39.3-h5082296_0 None\n",
            "  tk                                      8.6.10-hbc83047_0 --> 8.6.12-h1ccaba5_0 None\n",
            "  tqdm               pkgs/main/noarch::tqdm-4.61.2-pyhd3eb~ --> pkgs/main/linux-64::tqdm-4.64.1-py37h06a4308_0 None\n",
            "  urllib3            pkgs/main/noarch::urllib3-1.26.6-pyhd~ --> pkgs/main/linux-64::urllib3-1.26.12-py37h06a4308_0 None\n",
            "  xz                                       5.2.5-h7b6447c_0 --> 5.2.6-h5eee18b_0 None\n",
            "  zlib                                    1.2.11-h7b6447c_3 --> 1.2.13-h5eee18b_0 None\n",
            "\n",
            "\n",
            "Proceed ([y]/n)? y\n",
            "\n",
            "\n",
            "Downloading and Extracting Packages\n",
            "tqdm-4.64.1          | 126 KB    | : 100% 1.0/1 [00:00<00:00,  9.30it/s]\n",
            "pycparser-2.21       | 94 KB     | : 100% 1.0/1 [00:00<00:00, 14.91it/s]\n",
            "charset-normalizer-2 | 35 KB     | : 100% 1.0/1 [00:00<00:00, 20.50it/s]\n",
            "requests-2.28.1      | 92 KB     | : 100% 1.0/1 [00:00<00:00, 20.25it/s]\n",
            "xz-5.2.6             | 394 KB    | : 100% 1.0/1 [00:00<00:00, 13.64it/s]\n",
            "pycosat-0.6.4        | 84 KB     | : 100% 1.0/1 [00:00<00:00, 19.68it/s]\n",
            "libstdcxx-ng-11.2.0  | 4.7 MB    | : 100% 1.0/1 [00:00<00:00,  5.63it/s]\n",
            "urllib3-1.26.12      | 181 KB    | : 100% 1.0/1 [00:00<00:00, 17.84it/s]\n",
            "setuptools-65.5.0    | 1.1 MB    | : 100% 1.0/1 [00:00<00:00,  8.97it/s]\n",
            "libgomp-11.2.0       | 474 KB    | : 100% 1.0/1 [00:00<00:00, 17.72it/s]\n",
            "cffi-1.15.1          | 227 KB    | : 100% 1.0/1 [00:00<00:00, 18.92it/s]\n",
            "ld_impl_linux-64-2.3 | 654 KB    | : 100% 1.0/1 [00:00<00:00, 17.07it/s]\n",
            "pyopenssl-22.0.0     | 50 KB     | : 100% 1.0/1 [00:00<00:00, 24.11it/s]\n",
            "ncurses-6.3          | 781 KB    | : 100% 1.0/1 [00:00<00:00,  4.26it/s]\n",
            "readline-8.2         | 357 KB    | : 100% 1.0/1 [00:00<00:00, 17.65it/s]\n",
            "cryptography-38.0.1  | 1.3 MB    | : 100% 1.0/1 [00:00<00:00, 10.07it/s]\n",
            "sqlite-3.39.3        | 1.1 MB    | : 100% 1.0/1 [00:00<00:00, 14.23it/s]\n",
            "conda-package-handli | 945 KB    | : 100% 1.0/1 [00:00<00:00, 14.44it/s]\n",
            "tk-8.6.12            | 3.0 MB    | : 100% 1.0/1 [00:00<00:00,  5.32it/s]\n",
            "idna-3.4             | 91 KB     | : 100% 1.0/1 [00:00<00:00, 17.22it/s]\n",
            "_openmp_mutex-5.1    | 21 KB     | : 100% 1.0/1 [00:00<00:00, 22.29it/s]\n",
            "zlib-1.2.13          | 103 KB    | : 100% 1.0/1 [00:00<00:00, 22.00it/s]\n",
            "libgcc-ng-11.2.0     | 5.3 MB    | : 100% 1.0/1 [00:00<00:00,  4.72it/s]\n",
            "Preparing transaction: - \b\b\\ \b\b| \b\bdone\n",
            "Verifying transaction: - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "Executing transaction: / \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "Retrieving notices: ...working... done\n"
          ]
        }
      ],
      "source": [
        "!wget -c https://repo.anaconda.com/miniconda/Miniconda3-py37_4.10.3-Linux-x86_64.sh\n",
        "!chmod +x Miniconda3-py37_4.10.3-Linux-x86_64.sh\n",
        "!bash ./Miniconda3-py37_4.10.3-Linux-x86_64.sh -b -f -p /usr/local\n",
        "!conda install -q -y --prefix /usr/local python=3.7 ujson\n",
        "import sys\n",
        "sys.path.append('/usr/local/lib/python3.7/site-packages')\n",
        "!conda update -n base -c defaults conda"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **CIFAR10 DATASET**"
      ],
      "metadata": {
        "id": "mphswugJN2l-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "Z674joELqyj9"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms"
      ],
      "metadata": {
        "id": "371J8e4Dq5vG"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bx2fvDQCgQdf"
      },
      "source": [
        "**Dataset Definition**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101,
          "referenced_widgets": [
            "c6560bee066c48e798a49a3b8ebffa12",
            "8776de44b43340779dc2479f529775f4",
            "85ef706bc53540dfbb9910d9db61a9e1",
            "dd368c3363f340949ab20e33931de20c",
            "0c3996257662477884c62f6f038b8d1c",
            "dfced125709b4fea9ce8651c61ec285e",
            "80cae95c0fc64d519168422fe6b1bf5f",
            "7838ae2dc7054316ad80e72cc42f98d8",
            "5880749a1ccc4f3aa4d2e2357eb09848",
            "382a78a4fd2848329df46fb3882714c5",
            "ae38dd56b8e040cab4d4846d813ff79f"
          ]
        },
        "id": "FufSvzInrHs4",
        "outputId": "f17da1b5-4790-4d22-f08e-c4e8c725d09e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/170498071 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c6560bee066c48e798a49a3b8ebffa12"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKGwdVYlgw19"
      },
      "source": [
        "**Visualizing CIFAR10 Data**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# functions to show an image\n",
        "\n",
        "\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5     # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "\n",
        "\n",
        "# get some random training images\n",
        "dataiter = iter(trainloader)\n",
        "images, labels = dataiter.next()\n",
        "\n",
        "# show images\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "# print labels\n",
        "print(' '.join('%5s' % classes[labels[j]] for j in range(4)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 155
        },
        "id": "6cEjNbn6rAn-",
        "outputId": "5b878760-3213-4360-e1b7-576eb96aa2aa"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " frog  ship   car  frog\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k0yHbDXXnML-"
      },
      "source": [
        "# **Clone BFA from my github**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y9q_oazQbLlF",
        "outputId": "b0e35c76-61af-4616-f492-a7c32e9340d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'BFA'...\n",
            "remote: Enumerating objects: 760, done.\u001b[K\n",
            "remote: Counting objects: 100% (331/331), done.\u001b[K\n",
            "remote: Compressing objects: 100% (169/169), done.\u001b[K\n",
            "remote: Total 760 (delta 220), reused 224 (delta 159), pack-reused 429\u001b[K\n",
            "Receiving objects: 100% (760/760), 2.61 MiB | 29.74 MiB/s, done.\n",
            "Resolving deltas: 100% (452/452), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/ZahraHeydari95/BFA.git"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Delete the folder if you want**"
      ],
      "metadata": {
        "id": "BVa4BiRuUiPj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd ..\n",
        "%rm -r BFA"
      ],
      "metadata": {
        "id": "9c3oocWcUXRl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The contents of the current folder**"
      ],
      "metadata": {
        "id": "6QVkvVvtOyXj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_UtExC1FnNRH",
        "outputId": "997ba9d3-f7d1-44db-de90-7c07325e2cf9"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BFA  data  Miniconda3-py37_4.10.3-Linux-x86_64.sh  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C1PVq1nRi50w"
      },
      "source": [
        "**Go to BFA Folder**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd BFA"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aaB-fzXLvcV0",
        "outputId": "46f972f8-c64d-42cb-8874-ceb5439af5a8"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/BFA\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5s6A43xAoOak"
      },
      "source": [
        "# **Install requirements**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "a9Aumu4KJc9K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4c30278-b127-488b-b0c2-c37cf3056482"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting package metadata (current_repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "Solving environment: \\ \b\bfailed with initial frozen solve. Retrying with flexible solve.\n",
            "Collecting package metadata (repodata.json): / \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "Solving environment: \\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "  added / updated specs:\n",
            "    - cudatoolkit=10.0\n",
            "    - pytorch=1.1.0\n",
            "    - torchvision=0.3.0\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    blas-1.0                   |              mkl           6 KB\n",
            "    cudatoolkit-10.0.130       |                0       261.2 MB\n",
            "    freetype-2.12.1            |       h4a9f257_0         626 KB\n",
            "    giflib-5.2.1               |       h7b6447c_0          78 KB\n",
            "    intel-openmp-2021.4.0      |    h06a4308_3561         4.2 MB\n",
            "    jpeg-9e                    |       h7f8727e_0         240 KB\n",
            "    lcms2-2.12                 |       h3be6417_0         312 KB\n",
            "    lerc-3.0                   |       h295c915_0         196 KB\n",
            "    libdeflate-1.8             |       h7f8727e_5          51 KB\n",
            "    libpng-1.6.37              |       hbc83047_0         278 KB\n",
            "    libtiff-4.4.0              |       hecacb30_1         516 KB\n",
            "    libwebp-1.2.4              |       h11a3e52_0          79 KB\n",
            "    libwebp-base-1.2.4         |       h5eee18b_0         347 KB\n",
            "    lz4-c-1.9.3                |       h295c915_1         185 KB\n",
            "    mkl-2021.4.0               |     h06a4308_640       142.6 MB\n",
            "    mkl-service-2.4.0          |   py37h7f8727e_0          56 KB\n",
            "    mkl_fft-1.3.1              |   py37hd3c417c_0         172 KB\n",
            "    mkl_random-1.2.2           |   py37h51133e4_0         287 KB\n",
            "    ninja-1.10.2               |       h06a4308_5           8 KB\n",
            "    ninja-base-1.10.2          |       hd09550d_5         109 KB\n",
            "    numpy-1.21.5               |   py37h6c91a56_3          10 KB\n",
            "    numpy-base-1.21.5          |   py37ha15fc14_3         4.8 MB\n",
            "    pillow-9.2.0               |   py37hace64e9_1         664 KB\n",
            "    pip-22.2.2                 |   py37h06a4308_0         2.3 MB\n",
            "    pytorch-1.1.0              |py3.7_cuda10.0.130_cudnn7.5.1_0       455.0 MB  pytorch\n",
            "    six-1.16.0                 |     pyhd3eb1b0_1          18 KB\n",
            "    torchvision-0.3.0          |py37_cu10.0.130_1         3.7 MB  pytorch\n",
            "    wheel-0.37.1               |     pyhd3eb1b0_0          33 KB\n",
            "    zstd-1.5.2                 |       ha4553b6_0         488 KB\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:       878.4 MB\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  blas               pkgs/main/linux-64::blas-1.0-mkl None\n",
            "  cudatoolkit        pkgs/main/linux-64::cudatoolkit-10.0.130-0 None\n",
            "  freetype           pkgs/main/linux-64::freetype-2.12.1-h4a9f257_0 None\n",
            "  giflib             pkgs/main/linux-64::giflib-5.2.1-h7b6447c_0 None\n",
            "  intel-openmp       pkgs/main/linux-64::intel-openmp-2021.4.0-h06a4308_3561 None\n",
            "  jpeg               pkgs/main/linux-64::jpeg-9e-h7f8727e_0 None\n",
            "  lcms2              pkgs/main/linux-64::lcms2-2.12-h3be6417_0 None\n",
            "  lerc               pkgs/main/linux-64::lerc-3.0-h295c915_0 None\n",
            "  libdeflate         pkgs/main/linux-64::libdeflate-1.8-h7f8727e_5 None\n",
            "  libpng             pkgs/main/linux-64::libpng-1.6.37-hbc83047_0 None\n",
            "  libtiff            pkgs/main/linux-64::libtiff-4.4.0-hecacb30_1 None\n",
            "  libwebp            pkgs/main/linux-64::libwebp-1.2.4-h11a3e52_0 None\n",
            "  libwebp-base       pkgs/main/linux-64::libwebp-base-1.2.4-h5eee18b_0 None\n",
            "  lz4-c              pkgs/main/linux-64::lz4-c-1.9.3-h295c915_1 None\n",
            "  mkl                pkgs/main/linux-64::mkl-2021.4.0-h06a4308_640 None\n",
            "  mkl-service        pkgs/main/linux-64::mkl-service-2.4.0-py37h7f8727e_0 None\n",
            "  mkl_fft            pkgs/main/linux-64::mkl_fft-1.3.1-py37hd3c417c_0 None\n",
            "  mkl_random         pkgs/main/linux-64::mkl_random-1.2.2-py37h51133e4_0 None\n",
            "  ninja              pkgs/main/linux-64::ninja-1.10.2-h06a4308_5 None\n",
            "  ninja-base         pkgs/main/linux-64::ninja-base-1.10.2-hd09550d_5 None\n",
            "  numpy              pkgs/main/linux-64::numpy-1.21.5-py37h6c91a56_3 None\n",
            "  numpy-base         pkgs/main/linux-64::numpy-base-1.21.5-py37ha15fc14_3 None\n",
            "  pillow             pkgs/main/linux-64::pillow-9.2.0-py37hace64e9_1 None\n",
            "  pip                pkgs/main/linux-64::pip-22.2.2-py37h06a4308_0 None\n",
            "  pytorch            pytorch/linux-64::pytorch-1.1.0-py3.7_cuda10.0.130_cudnn7.5.1_0 None\n",
            "  six                pkgs/main/noarch::six-1.16.0-pyhd3eb1b0_1 None\n",
            "  torchvision        pytorch/linux-64::torchvision-0.3.0-py37_cu10.0.130_1 None\n",
            "  wheel              pkgs/main/noarch::wheel-0.37.1-pyhd3eb1b0_0 None\n",
            "  zstd               pkgs/main/linux-64::zstd-1.5.2-ha4553b6_0 None\n",
            "\n",
            "\n",
            "Proceed ([y]/n)? y\n",
            "\n",
            "\n",
            "Downloading and Extracting Packages\n",
            "libdeflate-1.8       | 51 KB     | : 100% 1.0/1 [00:00<00:00, 11.07it/s]\n",
            "six-1.16.0           | 18 KB     | : 100% 1.0/1 [00:00<00:00, 17.64it/s]\n",
            "mkl-2021.4.0         | 142.6 MB  | : 100% 1.0/1 [00:04<00:00,  4.84s/it]               \n",
            "jpeg-9e              | 240 KB    | : 100% 1.0/1 [00:00<00:00, 12.02it/s]\n",
            "blas-1.0             | 6 KB      | : 100% 1.0/1 [00:00<00:00, 18.97it/s]\n",
            "libtiff-4.4.0        | 516 KB    | : 100% 1.0/1 [00:00<00:00, 13.40it/s]\n",
            "numpy-base-1.21.5    | 4.8 MB    | : 100% 1.0/1 [00:00<00:00,  3.83it/s]\n",
            "ninja-base-1.10.2    | 109 KB    | : 100% 1.0/1 [00:00<00:00, 18.10it/s]\n",
            "pip-22.2.2           | 2.3 MB    | : 100% 1.0/1 [00:00<00:00,  5.57it/s]\n",
            "cudatoolkit-10.0.130 | 261.2 MB  | : 100% 1.0/1 [00:05<00:00,  5.80s/it]               \n",
            "ninja-1.10.2         | 8 KB      | : 100% 1.0/1 [00:00<00:00, 14.44it/s]\n",
            "lcms2-2.12           | 312 KB    | : 100% 1.0/1 [00:00<00:00, 15.12it/s]\n",
            "pytorch-1.1.0        | 455.0 MB  | : 100% 1.0/1 [00:59<00:00, 59.88s/it]               \n",
            "mkl_random-1.2.2     | 287 KB    | : 100% 1.0/1 [00:00<00:00, 13.99it/s]\n",
            "giflib-5.2.1         | 78 KB     | : 100% 1.0/1 [00:00<00:00, 16.60it/s]\n",
            "lerc-3.0             | 196 KB    | : 100% 1.0/1 [00:00<00:00, 18.16it/s]\n",
            "wheel-0.37.1         | 33 KB     | : 100% 1.0/1 [00:00<00:00, 17.30it/s]\n",
            "zstd-1.5.2           | 488 KB    | : 100% 1.0/1 [00:00<00:00, 12.58it/s]\n",
            "mkl_fft-1.3.1        | 172 KB    | : 100% 1.0/1 [00:00<00:00, 16.13it/s]\n",
            "intel-openmp-2021.4. | 4.2 MB    | : 100% 1.0/1 [00:00<00:00,  4.08it/s]\n",
            "mkl-service-2.4.0    | 56 KB     | : 100% 1.0/1 [00:00<00:00, 17.24it/s]\n",
            "libpng-1.6.37        | 278 KB    | : 100% 1.0/1 [00:00<00:00, 14.45it/s]\n",
            "pillow-9.2.0         | 664 KB    | : 100% 1.0/1 [00:00<00:00, 12.27it/s]\n",
            "numpy-1.21.5         | 10 KB     | : 100% 1.0/1 [00:00<00:00, 16.24it/s]\n",
            "libwebp-base-1.2.4   | 347 KB    | : 100% 1.0/1 [00:00<00:00, 16.73it/s]\n",
            "lz4-c-1.9.3          | 185 KB    | : 100% 1.0/1 [00:00<00:00,  6.31it/s]               \n",
            "freetype-2.12.1      | 626 KB    | : 100% 1.0/1 [00:00<00:00,  1.83it/s]\n",
            "libwebp-1.2.4        | 79 KB     | : 100% 1.0/1 [00:00<00:00, 15.43it/s]\n",
            "torchvision-0.3.0    | 3.7 MB    | : 100% 1.0/1 [00:00<00:00,  1.24it/s]\n",
            "Preparing transaction: / \b\b- \b\b\\ \b\bdone\n",
            "Verifying transaction: / \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\bdone\n",
            "Executing transaction: - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\bdone\n",
            "Retrieving notices: ...working... done\n",
            "Collecting package metadata (current_repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\bdone\n",
            "Solving environment: - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "  added / updated specs:\n",
            "    - python\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    python-3.7.15              |       haa1d7c7_0        40.8 MB\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:        40.8 MB\n",
            "\n",
            "The following packages will be UPDATED:\n",
            "\n",
            "  python                                  3.7.10-h12debd9_4 --> 3.7.15-haa1d7c7_0 None\n",
            "\n",
            "\n",
            "Proceed ([y]/n)? y\n",
            "\n",
            "\n",
            "Downloading and Extracting Packages\n",
            "python-3.7.15        | 40.8 MB   | : 100% 1.0/1 [00:01<00:00,  1.04s/it]               \n",
            "Preparing transaction: / \b\bdone\n",
            "Verifying transaction: \\ \b\b| \b\b/ \b\bdone\n",
            "Executing transaction: \\ \b\b| \b\b/ \b\b- \b\bdone\n",
            "Retrieving notices: ...working... done\n"
          ]
        }
      ],
      "source": [
        "!conda install pytorch=1.1.0 torchvision=0.3.0 cudatoolkit=10.0 -c pytorch\n",
        "!conda install python"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!conda install tensorboardX"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "80HFDQqSS7u9",
        "outputId": "553b3e39-e15a-48e5-e174-f0647f35c19f"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting package metadata (current_repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "Solving environment: / \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "  added / updated specs:\n",
            "    - tensorboardx\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    libprotobuf-3.20.1         |       h4ff587b_0         2.1 MB\n",
            "    protobuf-3.20.1            |   py37h295c915_0         290 KB\n",
            "    tensorboardx-2.2           |     pyhd3eb1b0_0          86 KB\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:         2.4 MB\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  libprotobuf        pkgs/main/linux-64::libprotobuf-3.20.1-h4ff587b_0 None\n",
            "  protobuf           pkgs/main/linux-64::protobuf-3.20.1-py37h295c915_0 None\n",
            "  tensorboardx       pkgs/main/noarch::tensorboardx-2.2-pyhd3eb1b0_0 None\n",
            "\n",
            "\n",
            "Proceed ([y]/n)? y\n",
            "\n",
            "\n",
            "Downloading and Extracting Packages\n",
            "libprotobuf-3.20.1   | 2.1 MB    | : 100% 1.0/1 [00:00<00:00,  5.50it/s]               \n",
            "protobuf-3.20.1      | 290 KB    | : 100% 1.0/1 [00:00<00:00, 14.97it/s]\n",
            "tensorboardx-2.2     | 86 KB     | : 100% 1.0/1 [00:00<00:00, 14.81it/s]\n",
            "Preparing transaction: | \b\bdone\n",
            "Verifying transaction: - \b\bdone\n",
            "Executing transaction: | \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n",
            "Retrieving notices: ...working... done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip --no-cache-dir install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6I8Aa3X-kIii",
        "outputId": "5de77038-81bd-4aaf-975d-0b48117021ec"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting astroid==2.1.0\n",
            "  Downloading astroid-2.1.0-py3-none-any.whl (176 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting autopep8==1.4.3\n",
            "  Downloading autopep8-1.4.3.tar.gz (113 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m113.9/113.9 kB\u001b[0m \u001b[31m246.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting backcall==0.1.0\n",
            "  Downloading backcall-0.1.0.zip (11 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting certifi==2019.3.9\n",
            "  Downloading certifi-2019.3.9-py2.py3-none-any.whl (158 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.6/158.6 kB\u001b[0m \u001b[31m263.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cycler==0.10.0\n",
            "  Downloading cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\n",
            "Collecting cython==0.29\n",
            "  Downloading Cython-0.29-cp37-cp37m-manylinux1_x86_64.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m147.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting decorator==4.3.0\n",
            "  Downloading decorator-4.3.0-py2.py3-none-any.whl (9.2 kB)\n",
            "Collecting entrypoints==0.3\n",
            "  Downloading entrypoints-0.3-py2.py3-none-any.whl (11 kB)\n",
            "Collecting ipykernel==5.1.0\n",
            "  Downloading ipykernel-5.1.0-py3-none-any.whl (113 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m113.9/113.9 kB\u001b[0m \u001b[31m248.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ipython==7.2.0\n",
            "  Downloading ipython-7.2.0-py3-none-any.whl (765 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m765.6/765.6 kB\u001b[0m \u001b[31m312.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ipython_genutils==0.2.0\n",
            "  Downloading ipython_genutils-0.2.0-py2.py3-none-any.whl (26 kB)\n",
            "Collecting isort==4.3.4\n",
            "  Downloading isort-4.3.4-py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.4/45.4 kB\u001b[0m \u001b[31m152.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jedi==0.13.2\n",
            "  Downloading jedi-0.13.2-py2.py3-none-any.whl (177 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.5/177.5 kB\u001b[0m \u001b[31m244.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jinja2==2.10\n",
            "  Downloading Jinja2-2.10-py2.py3-none-any.whl (126 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.4/126.4 kB\u001b[0m \u001b[31m235.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jsonschema==2.6.0\n",
            "  Downloading jsonschema-2.6.0-py2.py3-none-any.whl (39 kB)\n",
            "Collecting jupyter_client==5.2.4\n",
            "  Downloading jupyter_client-5.2.4-py2.py3-none-any.whl (89 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.7/89.7 kB\u001b[0m \u001b[31m224.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jupyter_core==4.4.0\n",
            "  Downloading jupyter_core-4.4.0-py2.py3-none-any.whl (126 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.8/126.8 kB\u001b[0m \u001b[31m285.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting kiwisolver==1.0.1\n",
            "  Downloading kiwisolver-1.0.1-cp37-cp37m-manylinux1_x86_64.whl (89 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.5/89.5 kB\u001b[0m \u001b[31m201.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting lazy-object-proxy==1.3.1\n",
            "  Downloading lazy-object-proxy-1.3.1.tar.gz (32 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting markupsafe==1.1.0\n",
            "  Downloading MarkupSafe-1.1.0-cp37-cp37m-manylinux1_x86_64.whl (27 kB)\n",
            "Collecting matplotlib==3.0.1\n",
            "  Downloading matplotlib-3.0.1-cp37-cp37m-manylinux1_x86_64.whl (12.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.9/12.9 MB\u001b[0m \u001b[31m266.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mccabe==0.6.1\n",
            "  Downloading mccabe-0.6.1-py2.py3-none-any.whl (8.6 kB)\n",
            "Collecting mistune==0.8.4\n",
            "  Downloading mistune-0.8.4-py2.py3-none-any.whl (16 kB)\n",
            "Collecting nbconvert==5.3.1\n",
            "  Downloading nbconvert-5.3.1-py2.py3-none-any.whl (387 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m387.2/387.2 kB\u001b[0m \u001b[31m134.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nbformat==4.4.0\n",
            "  Downloading nbformat-4.4.0-py2.py3-none-any.whl (155 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.8/155.8 kB\u001b[0m \u001b[31m242.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting notebook==5.7.4\n",
            "  Downloading notebook-5.7.4-py2.py3-none-any.whl (9.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.0/9.0 MB\u001b[0m \u001b[31m234.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting olefile==0.46\n",
            "  Downloading olefile-0.46.zip (112 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.2/112.2 kB\u001b[0m \u001b[31m271.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pandocfilters==1.4.2\n",
            "  Downloading pandocfilters-1.4.2.tar.gz (14 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting parso==0.3.1\n",
            "  Downloading parso-0.3.1-py2.py3-none-any.whl (88 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.8/88.8 kB\u001b[0m \u001b[31m210.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting patsy==0.5.1\n",
            "  Downloading patsy-0.5.1-py2.py3-none-any.whl (231 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m231.2/231.2 kB\u001b[0m \u001b[31m219.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pexpect==4.6.0\n",
            "  Downloading pexpect-4.6.0-py2.py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.9/57.9 kB\u001b[0m \u001b[31m140.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pickleshare==0.7.5\n",
            "  Downloading pickleshare-0.7.5-py2.py3-none-any.whl (6.9 kB)\n",
            "Collecting pillow==5.4.1\n",
            "  Downloading Pillow-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m328.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting prometheus_client==0.5.0\n",
            "  Downloading prometheus_client-0.5.0.tar.gz (31 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting prompt_toolkit==2.0.7\n",
            "  Downloading prompt_toolkit-2.0.7-py3-none-any.whl (338 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m338.7/338.7 kB\u001b[0m \u001b[31m301.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ptyprocess==0.6.0\n",
            "  Downloading ptyprocess-0.6.0-py2.py3-none-any.whl (39 kB)\n",
            "Collecting pycodestyle==2.5.0\n",
            "  Downloading pycodestyle-2.5.0-py2.py3-none-any.whl (51 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.2/51.2 kB\u001b[0m \u001b[31m210.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pycparser==2.19\n",
            "  Downloading pycparser-2.19.tar.gz (158 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.3/158.3 kB\u001b[0m \u001b[31m262.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pygments==2.3.1\n",
            "  Downloading Pygments-2.3.1-py2.py3-none-any.whl (849 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.5/849.5 kB\u001b[0m \u001b[31m280.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyhamcrest==1.9.0\n",
            "  Downloading PyHamcrest-1.9.0-py2.py3-none-any.whl (52 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.3/52.3 kB\u001b[0m \u001b[31m205.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pylint==2.2.2\n",
            "  Downloading pylint-2.2.2-py3-none-any.whl (750 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m750.4/750.4 kB\u001b[0m \u001b[31m330.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyparsing==2.3.0\n",
            "  Downloading pyparsing-2.3.0-py2.py3-none-any.whl (59 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.0/59.0 kB\u001b[0m \u001b[31m220.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-dateutil==2.7.5\n",
            "  Downloading python_dateutil-2.7.5-py2.py3-none-any.whl (225 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m225.7/225.7 kB\u001b[0m \u001b[31m281.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pytz==2018.7\n",
            "  Downloading pytz-2018.7-py2.py3-none-any.whl (506 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m506.6/506.6 kB\u001b[0m \u001b[31m289.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyzmq==17.1.2\n",
            "  Downloading pyzmq-17.1.2-cp37-cp37m-manylinux1_x86_64.whl (997 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m997.8/997.8 kB\u001b[0m \u001b[31m332.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scipy==1.1.0\n",
            "  Downloading scipy-1.1.0-cp37-cp37m-manylinux1_x86_64.whl (31.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.2/31.2 MB\u001b[0m \u001b[31m274.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting seaborn==0.9.0\n",
            "  Downloading seaborn-0.9.0-py3-none-any.whl (208 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m208.1/208.1 kB\u001b[0m \u001b[31m299.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting send2trash==1.5.0\n",
            "  Downloading Send2Trash-1.5.0-py3-none-any.whl (12 kB)\n",
            "Collecting statsmodels==0.9.0\n",
            "  Downloading statsmodels-0.9.0-cp37-cp37m-manylinux1_x86_64.whl (7.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m265.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting terminado==0.8.1\n",
            "  Downloading terminado-0.8.1-py2.py3-none-any.whl (33 kB)\n",
            "Collecting testpath==0.4.2\n",
            "  Downloading testpath-0.4.2-py2.py3-none-any.whl (163 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.8/163.8 kB\u001b[0m \u001b[31m227.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchvision==0.2.2\n",
            "  Downloading torchvision-0.2.2-py2.py3-none-any.whl (64 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.3/64.3 kB\u001b[0m \u001b[31m222.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tornado==5.1.1\n",
            "  Downloading tornado-5.1.1.tar.gz (516 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m516.8/516.8 kB\u001b[0m \u001b[31m291.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting traitlets==4.3.2\n",
            "  Downloading traitlets-4.3.2-py2.py3-none-any.whl (74 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.7/74.7 kB\u001b[0m \u001b[31m201.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typed-ast==1.1.0\n",
            "  Downloading typed_ast-1.1.0-cp37-cp37m-manylinux1_x86_64.whl (723 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m723.8/723.8 kB\u001b[0m \u001b[31m324.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting wcwidth==0.1.7\n",
            "  Downloading wcwidth-0.1.7-py2.py3-none-any.whl (21 kB)\n",
            "Collecting webencodings==0.5.1\n",
            "  Downloading webencodings-0.5.1-py2.py3-none-any.whl (11 kB)\n",
            "Collecting wrapt==1.10.11\n",
            "  Downloading wrapt-1.10.11.tar.gz (27 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting absl-py==0.7.0\n",
            "  Downloading absl-py-0.7.0.tar.gz (96 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.0/96.0 kB\u001b[0m \u001b[31m229.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting astor==0.7.1\n",
            "  Downloading astor-0.7.1-py2.py3-none-any.whl (27 kB)\n",
            "Collecting atomicwrites==1.2.1\n",
            "  Downloading atomicwrites-1.2.1-py2.py3-none-any.whl (5.9 kB)\n",
            "Collecting attrs==18.2.0\n",
            "  Downloading attrs-18.2.0-py2.py3-none-any.whl (34 kB)\n",
            "Collecting bleach==3.1.0\n",
            "  Downloading bleach-3.1.0-py2.py3-none-any.whl (157 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m157.5/157.5 kB\u001b[0m \u001b[31m254.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting chardet==3.0.4\n",
            "  Downloading chardet-3.0.4-py2.py3-none-any.whl (133 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.4/133.4 kB\u001b[0m \u001b[31m244.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cloudpickle==0.7.0\n",
            "  Downloading cloudpickle-0.7.0-py2.py3-none-any.whl (16 kB)\n",
            "Collecting dask==1.1.0\n",
            "  Downloading dask-1.1.0-py2.py3-none-any.whl (699 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m699.8/699.8 kB\u001b[0m \u001b[31m296.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting future==0.17.1\n",
            "  Downloading future-0.17.1.tar.gz (829 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m829.1/829.1 kB\u001b[0m \u001b[31m311.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gast==0.2.2\n",
            "  Downloading gast-0.2.2.tar.gz (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting grpcio==1.18.0\n",
            "  Downloading grpcio-1.18.0-cp37-cp37m-manylinux1_x86_64.whl (10.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.6/10.6 MB\u001b[0m \u001b[31m183.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gym==0.10.9\n",
            "  Downloading gym-0.10.9.tar.gz (1.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m328.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting h5py==2.9.0\n",
            "  Downloading h5py-2.9.0-cp37-cp37m-manylinux1_x86_64.whl (2.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m327.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting idna==2.8\n",
            "  Downloading idna-2.8-py2.py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.6/58.6 kB\u001b[0m \u001b[31m206.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting keras-applications==1.0.6\n",
            "  Downloading Keras_Applications-1.0.6-py2.py3-none-any.whl (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m187.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting keras-preprocessing==1.0.5\n",
            "  Downloading Keras_Preprocessing-1.0.5-py2.py3-none-any.whl (30 kB)\n",
            "Collecting markdown==3.0.1\n",
            "  Downloading Markdown-3.0.1-py2.py3-none-any.whl (89 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.4/89.4 kB\u001b[0m \u001b[31m258.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting more-itertools==5.0.0\n",
            "  Downloading more_itertools-5.0.0-py3-none-any.whl (52 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.3/52.3 kB\u001b[0m \u001b[31m153.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting networkx==2.2\n",
            "  Downloading networkx-2.2.zip (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m319.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting numpy==1.16.0\n",
            "  Downloading numpy-1.16.0-cp37-cp37m-manylinux1_x86_64.whl (17.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m263.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opencv-python==4.0.0.21\n",
            "  Downloading opencv_python-4.0.0.21-cp37-cp37m-manylinux1_x86_64.whl (25.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m25.4/25.4 MB\u001b[0m \u001b[31m161.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pandas==0.24.0\n",
            "  Downloading pandas-0.24.0-cp37-cp37m-manylinux1_x86_64.whl (10.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m73.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pluggy==0.8.1\n",
            "  Downloading pluggy-0.8.1-py2.py3-none-any.whl (17 kB)\n",
            "Collecting protobuf==3.6.1\n",
            "  Downloading protobuf-3.6.1-cp37-cp37m-manylinux1_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m327.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting py==1.7.0\n",
            "  Downloading py-1.7.0-py2.py3-none-any.whl (83 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m249.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyglet==1.3.2\n",
            "  Downloading pyglet-1.3.2-py2.py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m326.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pytest==4.1.1\n",
            "  Downloading pytest-4.1.1-py2.py3-none-any.whl (216 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.0/216.0 kB\u001b[0m \u001b[31m174.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pywavelets==1.0.1\n",
            "  Downloading PyWavelets-1.0.1-cp37-cp37m-manylinux1_x86_64.whl (4.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m295.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyyaml==5.1.1\n",
            "  Downloading PyYAML-5.1.1.tar.gz (274 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m274.4/274.4 kB\u001b[0m \u001b[31m220.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting requests==2.21.0\n",
            "  Downloading requests-2.21.0-py2.py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.0/58.0 kB\u001b[0m \u001b[31m198.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scikit-image==0.14.2\n",
            "  Downloading scikit_image-0.14.2-cp37-cp37m-manylinux1_x86_64.whl (25.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m25.3/25.3 MB\u001b[0m \u001b[31m86.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scikit-learn==0.20.2\n",
            "  Downloading scikit_learn-0.20.2-cp37-cp37m-manylinux1_x86_64.whl (5.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m84.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting setuptools==40.6.3\n",
            "  Downloading setuptools-40.6.3-py2.py3-none-any.whl (573 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m573.1/573.1 kB\u001b[0m \u001b[31m316.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting six==1.12.0\n",
            "  Downloading six-1.12.0-py2.py3-none-any.whl (10 kB)\n",
            "Collecting tensorboard==1.12.2\n",
            "  Downloading tensorboard-1.12.2-py3-none-any.whl (3.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m95.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorboardx==1.6\n",
            "  Downloading tensorboardX-1.6-py2.py3-none-any.whl (129 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.4/129.4 kB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting termcolor==1.1.0\n",
            "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting toolz==0.9.0\n",
            "  Downloading toolz-0.9.0.tar.gz (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m106.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting torchfile==0.1.0\n",
            "  Downloading torchfile-0.1.0.tar.gz (5.2 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting urllib3==1.24.1\n",
            "  Downloading urllib3-1.24.1-py2.py3-none-any.whl (118 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.1/118.1 kB\u001b[0m \u001b[31m259.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting visdom==0.1.8.8\n",
            "  Downloading visdom-0.1.8.8.tar.gz (1.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m106.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting websocket-client==0.54.0\n",
            "  Downloading websocket_client-0.54.0-py2.py3-none-any.whl (200 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.1/200.1 kB\u001b[0m \u001b[31m158.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting werkzeug==0.14.1\n",
            "  Downloading Werkzeug-0.14.1-py2.py3-none-any.whl (322 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.9/322.9 kB\u001b[0m \u001b[31m296.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting wheel==0.32.3\n",
            "  Downloading wheel-0.32.3-py2.py3-none-any.whl (21 kB)\n",
            "Collecting yacs==0.1.6\n",
            "  Downloading yacs-0.1.6-py3-none-any.whl (9.6 kB)\n",
            "Collecting tqdm==4.19.9\n",
            "  Downloading tqdm-4.19.9-py2.py3-none-any.whl (52 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.7/52.7 kB\u001b[0m \u001b[31m160.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.7/site-packages (from torchvision==0.2.2->-r requirements.txt (line 52)) (1.1.0)\n",
            "Collecting dask[array]>=1.0.0\n",
            "  Downloading dask-2022.2.0-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m329.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading dask-2022.1.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m252.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading dask-2022.1.0-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m306.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading dask-2021.12.0-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m332.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading dask-2021.11.2-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m186.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading dask-2021.11.1-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m316.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading dask-2021.11.0-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m319.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading dask-2021.10.0-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m329.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading dask-2021.9.1-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m301.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading dask-2021.9.0-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m309.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading dask-2021.8.1-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m323.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading dask-2021.8.0-py3-none-any.whl (995 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m995.6/995.6 kB\u001b[0m \u001b[31m322.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading dask-2021.7.2-py3-none-any.whl (987 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m987.9/987.9 kB\u001b[0m \u001b[31m330.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading dask-2021.7.1-py3-none-any.whl (984 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m984.3/984.3 kB\u001b[0m \u001b[31m132.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading dask-2021.7.0-py3-none-any.whl (977 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m978.0/978.0 kB\u001b[0m \u001b[31m311.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading dask-2021.6.2-py3-none-any.whl (973 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m973.9/973.9 kB\u001b[0m \u001b[31m323.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading dask-2021.6.1-py3-none-any.whl (973 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m973.8/973.8 kB\u001b[0m \u001b[31m319.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading dask-2021.6.0-py3-none-any.whl (965 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m965.6/965.6 kB\u001b[0m \u001b[31m323.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading dask-2021.5.1-py3-none-any.whl (964 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m964.4/964.4 kB\u001b[0m \u001b[31m325.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading dask-2021.5.0-py3-none-any.whl (960 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m960.7/960.7 kB\u001b[0m \u001b[31m329.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading dask-2021.4.1-py3-none-any.whl (952 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m952.3/952.3 kB\u001b[0m \u001b[31m300.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading dask-2021.4.0-py3-none-any.whl (941 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m941.1/941.1 kB\u001b[0m \u001b[31m332.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading dask-2021.3.1-py3-none-any.whl (935 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m935.6/935.6 kB\u001b[0m \u001b[31m189.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading dask-2021.3.0-py3-none-any.whl (925 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m925.7/925.7 kB\u001b[0m \u001b[31m326.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading dask-2021.2.0-py3-none-any.whl (900 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m900.6/900.6 kB\u001b[0m \u001b[31m316.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading dask-2021.1.1-py3-none-any.whl (891 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m891.1/891.1 kB\u001b[0m \u001b[31m328.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading dask-2021.1.0-py3-none-any.whl (889 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m889.4/889.4 kB\u001b[0m \u001b[31m327.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading dask-2020.12.0-py3-none-any.whl (884 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m885.0/885.0 kB\u001b[0m \u001b[31m314.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading dask-2.30.0-py3-none-any.whl (848 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m848.4/848.4 kB\u001b[0m \u001b[31m278.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading dask-2.29.0-py3-none-any.whl (847 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m847.2/847.2 kB\u001b[0m \u001b[31m326.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading dask-2.28.0-py3-none-any.whl (848 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m848.4/848.4 kB\u001b[0m \u001b[31m281.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading dask-2.27.0-py3-none-any.whl (843 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m843.7/843.7 kB\u001b[0m \u001b[31m311.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading dask-2.26.0-py3-none-any.whl (843 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m843.5/843.5 kB\u001b[0m \u001b[31m305.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading dask-2.25.0-py3-none-any.whl (834 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m834.2/834.2 kB\u001b[0m \u001b[31m303.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading dask-2.24.0-py3-none-any.whl (834 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m834.3/834.3 kB\u001b[0m \u001b[31m289.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading dask-2.23.0-py3-none-any.whl (831 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m831.9/831.9 kB\u001b[0m \u001b[31m311.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading dask-2.22.0-py3-none-any.whl (828 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m828.7/828.7 kB\u001b[0m \u001b[31m333.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading dask-2.21.0-py3-none-any.whl (826 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m826.8/826.8 kB\u001b[0m \u001b[31m331.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading dask-2.20.0-py3-none-any.whl (826 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m826.5/826.5 kB\u001b[0m \u001b[31m254.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading dask-2.19.0-py3-none-any.whl (824 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m824.0/824.0 kB\u001b[0m \u001b[31m316.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading dask-2.18.1-py3-none-any.whl (823 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.4/823.4 kB\u001b[0m \u001b[31m318.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading dask-2.18.0-py3-none-any.whl (822 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m822.0/822.0 kB\u001b[0m \u001b[31m292.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading dask-2.17.2-py3-none-any.whl (813 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m813.6/813.6 kB\u001b[0m \u001b[31m237.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading dask-2.17.1-py3-none-any.whl (813 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m813.3/813.3 kB\u001b[0m \u001b[31m319.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading dask-2.17.0-py3-none-any.whl (812 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m812.6/812.6 kB\u001b[0m \u001b[31m245.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading dask-2.16.0-py3-none-any.whl (802 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m802.8/802.8 kB\u001b[0m \u001b[31m316.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading dask-2.15.0-py3-none-any.whl (799 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m799.6/799.6 kB\u001b[0m \u001b[31m117.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading dask-2.14.0-py3-none-any.whl (794 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m794.6/794.6 kB\u001b[0m \u001b[31m324.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading dask-2.13.0-py3-none-any.whl (791 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m791.5/791.5 kB\u001b[0m \u001b[31m301.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading dask-2.12.0-py3-none-any.whl (789 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m789.3/789.3 kB\u001b[0m \u001b[31m310.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading dask-2.11.0-py3-none-any.whl (785 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m785.1/785.1 kB\u001b[0m \u001b[31m303.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading dask-2.10.1-py3-none-any.whl (783 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m783.1/783.1 kB\u001b[0m \u001b[31m199.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading dask-2.10.0-py3-none-any.whl (783 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m783.2/783.2 kB\u001b[0m \u001b[31m322.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading dask-2.9.2-py3-none-any.whl (780 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m780.5/780.5 kB\u001b[0m \u001b[31m315.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading dask-2.9.1-py3-none-any.whl (772 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m773.0/773.0 kB\u001b[0m \u001b[31m141.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading dask-2.9.0-py3-none-any.whl (770 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m770.8/770.8 kB\u001b[0m \u001b[31m258.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading dask-2.8.1-py3-none-any.whl (769 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m769.5/769.5 kB\u001b[0m \u001b[31m293.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading dask-2.8.0-py3-none-any.whl (767 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m767.8/767.8 kB\u001b[0m \u001b[31m330.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading dask-2.7.0-py3-none-any.whl (765 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m765.5/765.5 kB\u001b[0m \u001b[31m305.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading dask-2.6.0-py3-none-any.whl (760 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m760.6/760.6 kB\u001b[0m \u001b[31m315.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading dask-2.5.2-py3-none-any.whl (760 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m760.0/760.0 kB\u001b[0m \u001b[31m272.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading dask-2.5.0-py3-none-any.whl (759 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m760.0/760.0 kB\u001b[0m \u001b[31m304.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading dask-2.4.0-py3-none-any.whl (766 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m766.3/766.3 kB\u001b[0m \u001b[31m305.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading dask-2.3.0-py3-none-any.whl (763 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m763.4/763.4 kB\u001b[0m \u001b[31m326.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading dask-2.2.0-py3-none-any.whl (757 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m757.9/757.9 kB\u001b[0m \u001b[31m316.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading dask-2.1.0-py3-none-any.whl (763 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m763.9/763.9 kB\u001b[0m \u001b[31m308.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading dask-2.0.0-py3-none-any.whl (760 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m760.4/760.4 kB\u001b[0m \u001b[31m325.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading dask-1.2.2-py2.py3-none-any.whl (717 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m717.9/717.9 kB\u001b[0m \u001b[31m325.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading dask-1.2.1-py2.py3-none-any.whl (714 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m714.2/714.2 kB\u001b[0m \u001b[31m303.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading dask-1.2.0-py2.py3-none-any.whl (711 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m711.4/711.4 kB\u001b[0m \u001b[31m321.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading dask-1.1.5-py2.py3-none-any.whl (708 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m708.1/708.1 kB\u001b[0m \u001b[31m279.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading dask-1.1.4-py2.py3-none-any.whl (704 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m704.6/704.6 kB\u001b[0m \u001b[31m306.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading dask-1.1.3-py2.py3-none-any.whl (703 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m703.2/703.2 kB\u001b[0m \u001b[31m272.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading dask-1.1.2-py2.py3-none-any.whl (704 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m704.6/704.6 kB\u001b[0m \u001b[31m312.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading dask-1.1.1-py2.py3-none-any.whl (701 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m701.3/701.3 kB\u001b[0m \u001b[31m306.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: autopep8, backcall, lazy-object-proxy, olefile, pandocfilters, prometheus_client, pycparser, tornado, wrapt, absl-py, future, gast, gym, networkx, pyyaml, termcolor, toolz, torchfile, visdom\n",
            "  Building wheel for autopep8 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for autopep8: filename=autopep8-1.4.3-py2.py3-none-any.whl size=42240 sha256=c5f8c16d2db4dd536f922a711cc0c16715154b6a22bdb7ec780aec8244868a54\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-ckfab_co/wheels/cb/ca/0d/db843e5869db016f92974eb145021a3920eec623f3e6adff59\n",
            "  Building wheel for backcall (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for backcall: filename=backcall-0.1.0-py3-none-any.whl size=10396 sha256=d880a6b709064ec8f63ca51b56ec69c2600063447962c52383941895e760e4f7\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-ckfab_co/wheels/60/5a/10/2177abb11261d49069a732cbc0e66207783c7ee79c1f807167\n",
            "  Building wheel for lazy-object-proxy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lazy-object-proxy: filename=lazy_object_proxy-1.3.1-cp37-cp37m-linux_x86_64.whl size=55995 sha256=b8700a28213ef6e4c837a55d2c0ee877145adcd2831561cecc22f62cfaa7efa6\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-ckfab_co/wheels/6a/5f/fa/04ce96d53f9d70f20fe6d97f9b5c541def3d0765ed0036a679\n",
            "  Building wheel for olefile (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for olefile: filename=olefile-0.46-py2.py3-none-any.whl size=35415 sha256=f719c286d1633e19b6e0f9577ccfdd10d6fe1e6fcca8fb1efe39baf65eeca6c2\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-ckfab_co/wheels/84/53/e6/37d90ccb3ad1a3ca98d2b17107e9fda401a7c541ea1eb6a65a\n",
            "  Building wheel for pandocfilters (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pandocfilters: filename=pandocfilters-1.4.2-py3-none-any.whl size=7853 sha256=427447b03acf42ef50eb645c25d9950d35d7e36af58cba2fab47814ce34256c4\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-ckfab_co/wheels/63/99/01/9fe785b86d1e091a6b2a61e06ddb3d8eb1bc9acae5933d4740\n",
            "  Building wheel for prometheus_client (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for prometheus_client: filename=prometheus_client-0.5.0-py3-none-any.whl size=39647 sha256=cb431f8a4f1af039c79720dfe4d7a5c3227274bd03b0d9eacfdb0e0f59802222\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-ckfab_co/wheels/f0/db/ca/8a51f172da26edafd8c84078efed565637b02bb5a71051f580\n",
            "  Building wheel for pycparser (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycparser: filename=pycparser-2.19-py2.py3-none-any.whl size=111053 sha256=d68f9d0ba37ad45b499ab4251b6fcb3c0c4f7bd09c6c0039c7fce428ae52b954\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-ckfab_co/wheels/0e/53/27/fee7fd9562e10dd046caccfc0340b8cf789b46846e660f3380\n",
            "  Building wheel for tornado (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tornado: filename=tornado-5.1.1-cp37-cp37m-linux_x86_64.whl size=463211 sha256=35351c489360296b44a22973ba1711a0f880cb65a8162ece6347c9ec30d30a28\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-ckfab_co/wheels/83/91/4b/ee8ffb993d3372fc4129c52c9140792c118dda0373b41e7a8f\n",
            "  Building wheel for wrapt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wrapt: filename=wrapt-1.10.11-cp37-cp37m-linux_x86_64.whl size=67346 sha256=39ea88e2c18d1faa5d78c7988b011a2c2cd88cbd5192d79b2e51366aa854a7fd\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-ckfab_co/wheels/b4/73/c0/df8f4b8bdfc554d2ba0823c8f80d566cabf702c858e2a49d7b\n",
            "  Building wheel for absl-py (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for absl-py: filename=absl_py-0.7.0-py3-none-any.whl size=113512 sha256=6b1241ca77b052e6fb82f95fcf985d28438eccc64e180175df8778149ba290e3\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-ckfab_co/wheels/7a/3a/ce/7f67462856699d5adaf0bab747964f5db6a138473374d46c4d\n",
            "  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for future: filename=future-0.17.1-py3-none-any.whl size=488726 sha256=bdb9f673e75203af21c7c5c37735b9f9d52dd823a1396e61a9c384bf6f267523\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-ckfab_co/wheels/16/4c/84/8a6161d44282ede60ed233d090156c6109a7ab865e49c1c9f6\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-py3-none-any.whl size=7538 sha256=50a1f3363c4888cafefeaad6ea172343d151e8c57c11014f5f4368652f884f9d\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-ckfab_co/wheels/21/7f/02/420f32a803f7d0967b48dd823da3f558c5166991bfd204eef3\n",
            "  Building wheel for gym (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gym: filename=gym-0.10.9-py3-none-any.whl size=1587002 sha256=7314f0f8faa33f7f8ee56620754dafcb38ea4ffce7213b2fd7c55411ffd9fee6\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-ckfab_co/wheels/e7/3d/73/929b7d38e163e1ed40ebb4400fc9a10533221fe694935a52ee\n",
            "  Building wheel for networkx (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for networkx: filename=networkx-2.2-py2.py3-none-any.whl size=1526919 sha256=4af1679e28581ae63689338621449839616b8ce0c325066fa9ed922b970fc3e7\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-ckfab_co/wheels/49/fb/7f/02c31ca537b34e1073844b733832e4c3a94071d8edda2c0faa\n",
            "  Building wheel for pyyaml (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyyaml: filename=PyYAML-5.1.1-cp37-cp37m-linux_x86_64.whl size=392084 sha256=b5785713605adf4b6e65fcaa6ac40471b7c98da1164b485cceb834514c1931af\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-ckfab_co/wheels/6f/a6/e1/6ab3225ed36801d672de2a9a8b04b30e4b1ac9efe3fa31c7a1\n",
            "  Building wheel for termcolor (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4832 sha256=dc3b8b2cf0c22b63bca20caff6404d1335d896d4b5af60493e995db5cef4fc58\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-ckfab_co/wheels/3f/e3/ec/8a8336ff196023622fbcb36de0c5a5c218cbb24111d1d4c7f2\n",
            "  Building wheel for toolz (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for toolz: filename=toolz-0.9.0-py3-none-any.whl size=53230 sha256=87d1aa30754326ce82a2df47a1d315edb9203ce404de87681fab2d2f797b3310\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-ckfab_co/wheels/58/85/f9/3a8ac8d6acedfb76fb78ed9dedd7b5c86dc5bfdef4b2427219\n",
            "  Building wheel for torchfile (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torchfile: filename=torchfile-0.1.0-py3-none-any.whl size=5693 sha256=c1e1aced1735ad9b8eccae9450d2028c056d1f5fe8b39375741e1b2110f68fe5\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-ckfab_co/wheels/ac/5c/3a/a80e1c65880945c71fd833408cd1e9a8cb7e2f8f37620bb75b\n",
            "  Building wheel for visdom (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for visdom: filename=visdom-0.1.8.8-py3-none-any.whl size=1350585 sha256=b484a08d5c1cd6e7aa4a8548509ffb5924ac7334982afc03e09ce907b17023c8\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-ckfab_co/wheels/31/53/a8/e831cd613dd98ac203485fb31a3938bb865d879d3332d026ef\n",
            "Successfully built autopep8 backcall lazy-object-proxy olefile pandocfilters prometheus_client pycparser tornado wrapt absl-py future gast gym networkx pyyaml termcolor toolz torchfile visdom\n",
            "Installing collected packages: wrapt, werkzeug, webencodings, wcwidth, typed-ast, tqdm, torchfile, toolz, testpath, termcolor, send2trash, pytz, pygments, ptyprocess, prometheus_client, pickleshare, parso, pandocfilters, mistune, mccabe, lazy-object-proxy, jsonschema, ipython_genutils, decorator, cloudpickle, chardet, certifi, backcall, attrs, wheel, urllib3, tornado, six, setuptools, pyzmq, pyyaml, pyparsing, pycparser, pycodestyle, py, pluggy, pillow, pexpect, olefile, numpy, networkx, markupsafe, markdown, jedi, isort, idna, gast, future, entrypoints, dask, cython, atomicwrites, astor, yacs, websocket-client, traitlets, terminado, scipy, requests, pywavelets, python-dateutil, pyhamcrest, pyglet, protobuf, prompt_toolkit, patsy, opencv-python, more-itertools, kiwisolver, keras-preprocessing, jinja2, h5py, grpcio, cycler, bleach, autopep8, astroid, absl-py, visdom, torchvision, tensorboardx, tensorboard, scikit-learn, pytest, pylint, pandas, matplotlib, keras-applications, jupyter_core, ipython, gym, statsmodels, seaborn, scikit-image, nbformat, jupyter_client, nbconvert, ipykernel, notebook\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.64.1\n",
            "    Uninstalling tqdm-4.64.1:\n",
            "      Successfully uninstalled tqdm-4.64.1\n",
            "  Attempting uninstall: toolz\n",
            "    Found existing installation: toolz 0.12.0\n",
            "    Uninstalling toolz-0.12.0:\n",
            "      Successfully uninstalled toolz-0.12.0\n",
            "  Attempting uninstall: certifi\n",
            "    Found existing installation: certifi 2022.9.24\n",
            "    Uninstalling certifi-2022.9.24:\n",
            "      Successfully uninstalled certifi-2022.9.24\n",
            "  Attempting uninstall: wheel\n",
            "    Found existing installation: wheel 0.37.1\n",
            "    Uninstalling wheel-0.37.1:\n",
            "      Successfully uninstalled wheel-0.37.1\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.26.12\n",
            "    Uninstalling urllib3-1.26.12:\n",
            "      Successfully uninstalled urllib3-1.26.12\n",
            "  Attempting uninstall: six\n",
            "    Found existing installation: six 1.16.0\n",
            "    Uninstalling six-1.16.0:\n",
            "      Successfully uninstalled six-1.16.0\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 65.5.0\n",
            "    Uninstalling setuptools-65.5.0:\n",
            "      Successfully uninstalled setuptools-65.5.0\n",
            "  Attempting uninstall: pycparser\n",
            "    Found existing installation: pycparser 2.21\n",
            "    Uninstalling pycparser-2.21:\n",
            "      Successfully uninstalled pycparser-2.21\n",
            "  Attempting uninstall: pillow\n",
            "    Found existing installation: Pillow 9.2.0\n",
            "    Uninstalling Pillow-9.2.0:\n",
            "      Successfully uninstalled Pillow-9.2.0\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.21.5\n",
            "    Uninstalling numpy-1.21.5:\n",
            "      Successfully uninstalled numpy-1.21.5\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.4\n",
            "    Uninstalling idna-3.4:\n",
            "      Successfully uninstalled idna-3.4\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.28.1\n",
            "    Uninstalling requests-2.28.1:\n",
            "      Successfully uninstalled requests-2.28.1\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.20.1\n",
            "    Uninstalling protobuf-3.20.1:\n",
            "      Successfully uninstalled protobuf-3.20.1\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.3.0\n",
            "    Uninstalling torchvision-0.3.0:\n",
            "      Successfully uninstalled torchvision-0.3.0\n",
            "  Attempting uninstall: tensorboardx\n",
            "    Found existing installation: tensorboardX 2.2\n",
            "    Uninstalling tensorboardX-2.2:\n",
            "      Successfully uninstalled tensorboardX-2.2\n",
            "Successfully installed absl-py-0.7.0 astor-0.7.1 astroid-2.1.0 atomicwrites-1.2.1 attrs-18.2.0 autopep8-1.4.3 backcall-0.1.0 bleach-3.1.0 certifi-2019.3.9 chardet-3.0.4 cloudpickle-0.7.0 cycler-0.10.0 cython-0.29 dask-1.1.0 decorator-4.3.0 entrypoints-0.3 future-0.17.1 gast-0.2.2 grpcio-1.18.0 gym-0.10.9 h5py-2.9.0 idna-2.8 ipykernel-5.1.0 ipython-7.2.0 ipython_genutils-0.2.0 isort-4.3.4 jedi-0.13.2 jinja2-2.10 jsonschema-2.6.0 jupyter_client-5.2.4 jupyter_core-4.4.0 keras-applications-1.0.6 keras-preprocessing-1.0.5 kiwisolver-1.0.1 lazy-object-proxy-1.3.1 markdown-3.0.1 markupsafe-1.1.0 matplotlib-3.0.1 mccabe-0.6.1 mistune-0.8.4 more-itertools-5.0.0 nbconvert-5.3.1 nbformat-4.4.0 networkx-2.2 notebook-5.7.4 numpy-1.16.0 olefile-0.46 opencv-python-4.0.0.21 pandas-0.24.0 pandocfilters-1.4.2 parso-0.3.1 patsy-0.5.1 pexpect-4.6.0 pickleshare-0.7.5 pillow-5.4.1 pluggy-0.8.1 prometheus_client-0.5.0 prompt_toolkit-2.0.7 protobuf-3.6.1 ptyprocess-0.6.0 py-1.7.0 pycodestyle-2.5.0 pycparser-2.19 pyglet-1.3.2 pygments-2.3.1 pyhamcrest-1.9.0 pylint-2.2.2 pyparsing-2.3.0 pytest-4.1.1 python-dateutil-2.7.5 pytz-2018.7 pywavelets-1.0.1 pyyaml-5.1.1 pyzmq-17.1.2 requests-2.21.0 scikit-image-0.14.2 scikit-learn-0.20.2 scipy-1.1.0 seaborn-0.9.0 send2trash-1.5.0 setuptools-40.6.3 six-1.12.0 statsmodels-0.9.0 tensorboard-1.12.2 tensorboardx-1.6 termcolor-1.1.0 terminado-0.8.1 testpath-0.4.2 toolz-0.9.0 torchfile-0.1.0 torchvision-0.2.2 tornado-5.1.1 tqdm-4.19.9 traitlets-4.3.2 typed-ast-1.1.0 urllib3-1.24.1 visdom-0.1.8.8 wcwidth-0.1.7 webencodings-0.5.1 websocket-client-0.54.0 werkzeug-0.14.1 wheel-0.32.3 wrapt-1.10.11 yacs-0.1.6\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U setuptools"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bd_bZEvDE8Ed",
        "outputId": "2f83c6ae-2514-49f2-9a92-01820f32c9bc"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing line 1 of /usr/local/lib/python3.7/site-packages/distutils-precedence.pth:\n",
            "\n",
            "  Traceback (most recent call last):\n",
            "    File \"/usr/local/lib/python3.7/site.py\", line 168, in addpackage\n",
            "      exec(line)\n",
            "    File \"<string>\", line 1, in <module>\n",
            "  ModuleNotFoundError: No module named '_distutils_hack'\n",
            "\n",
            "Remainder of file ignored\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/site-packages (40.6.3)\n",
            "Collecting setuptools\n",
            "  Downloading setuptools-65.5.1-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: setuptools\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 40.6.3\n",
            "    Uninstalling setuptools-40.6.3:\n",
            "      Successfully uninstalled setuptools-40.6.3\n",
            "Successfully installed setuptools-65.5.1\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **HOST Name**"
      ],
      "metadata": {
        "id": "g1bW2ibsDexO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!hostname alpha"
      ],
      "metadata": {
        "id": "yJttPj1bMbrH"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!hostname"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AEJy1_oWM402",
        "outputId": "3f05438a-3da9-4d0a-b50f-f53059d2109b"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "alpha\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vUwlWoJoO7LX",
        "outputId": "dedffe4f-2261-4749-981b-169c65c41605"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/BFA\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Path**"
      ],
      "metadata": {
        "id": "KvKDE9B3v3Qi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!whereis tensorboard"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p_RN4Bc3OnjM",
        "outputId": "30121118-8b96-44fd-84c7-3cbbf0b37e52"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensorboard: /usr/local/bin/tensorboard\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YStFI6mY1LOO",
        "outputId": "1b614e51-8250-47c7-f653-b9dad42dfa89"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.7.15\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Attack on the model trained in floating-point**"
      ],
      "metadata": {
        "id": "ACD5v75gwr-i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**BFA**"
      ],
      "metadata": {
        "id": "NJJgvF-MkZfE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!bash BFA_CIFAR_Attack_on_model_trained_in_floating_point.sh"
      ],
      "metadata": {
        "id": "t_Gh18hPvi_J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "041b77db-f92e-416e-9d6a-9253b420fa0e"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current host is: alpha\n",
            "save path : ./save/2022-11-15/cifar10_resnet18_quan_BFA\n",
            "{'arch': 'resnet18_quan', 'attack_sample_size': 64, 'clustering': False, 'data_path': '/content/data/cifar-10-batches-py', 'dataset': 'cifar10', 'decay': 0.0001, 'enable_bfa': True, 'epochs': 200, 'evaluate': False, 'fine_tune': False, 'gammas': [0.1, 0.1], 'gpu_id': 1, 'k_top': 10, 'lambda_coeff': 0.001, 'learning_rate': 0.001, 'manualSeed': 3884, 'model_only': False, 'momentum': 0.9, 'n_iter': 50, 'ngpu': 1, 'optimizer': 'SGD', 'print_freq': 50, 'quan_bitwidth': None, 'random_bfa': False, 'reset_weight': True, 'resume': '', 'save_path': './save/2022-11-15/cifar10_resnet18_quan_BFA', 'schedule': [80, 120], 'start_epoch': 0, 'test_batch_size': 256, 'use_cuda': False, 'workers': 8}\n",
            "Random Seed: 3884\n",
            "python version : 3.7.15 (default, Nov  7 2022, 22:00:21)  [GCC 11.2.0]\n",
            "torch  version : 1.1.0\n",
            "cudnn  version : 7501\n",
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to /content/data/cifar-10-batches-py/cifar-10-python.tar.gz\n",
            "171MB [00:03, 46.3MB/s]               \n",
            "Files already downloaded and verified\n",
            "=> creating model 'resnet18_quan'\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to /root/.cache/torch/checkpoints/resnet18-5c106cde.pth\n",
            "100% 46827520/46827520 [00:02<00:00, 21979064.48it/s]\n",
            "=> network :\n",
            " ResNet(\n",
            "  (conv1): quan_Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace)\n",
            "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (layer1): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): quan_Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace)\n",
            "      (conv2): quan_Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): quan_Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace)\n",
            "      (conv2): quan_Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): quan_Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace)\n",
            "      (conv2): quan_Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): quan_Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): quan_Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace)\n",
            "      (conv2): quan_Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): quan_Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace)\n",
            "      (conv2): quan_Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): quan_Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): quan_Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace)\n",
            "      (conv2): quan_Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): quan_Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace)\n",
            "      (conv2): quan_Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): quan_Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): quan_Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace)\n",
            "      (conv2): quan_Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (fc): quan_Linear(in_features=512, out_features=1000, bias=True)\n",
            ")\n",
            "using SGD as optimizer\n",
            "=> do not use any checkpoint for resnet18_quan model\n",
            "  **Test** Prec@1 0.020 Prec@5 0.210 Error@1 99.980\n",
            "k_top is set to 10\n",
            "Attack sample size is 64\n",
            "**********************************\n",
            "attacked module: layer2.0.downsample.0\n",
            "attacked weight index: [114  50   0   0]\n",
            "weight before attack: -0.0\n",
            "weight after attack: -128.0\n",
            "Iteration: [001/050]   Attack Time 4.141 (4.141)  [2022-11-15 05:26:55]\n",
            "loss before attack: 1.9617\n",
            "loss after attack: 2.2037\n",
            "bit flips: 1\n",
            "hamming_dist: 1\n",
            "  **Test** Prec@1 0.010 Prec@5 0.220 Error@1 99.990\n",
            "iteration Time 20.776 (20.776)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Random BFA**"
      ],
      "metadata": {
        "id": "1l-gHpfMkfCx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!bash BFA_CIFAR_Attack_on_model_trained_in_floating_point.sh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VDrtiZ47kXkN",
        "outputId": "8120f4da-cab2-4b93-d88f-9ae36e52fc98"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current host is: alpha\n",
            "mkdir: cannot create directory ‘save’: File exists\n",
            "mkdir: cannot create directory ‘2022-11-15’: File exists\n",
            "save path : ./save/2022-11-15/cifar10_resnet18_quan_BFA\n",
            "{'arch': 'resnet18_quan', 'attack_sample_size': 64, 'clustering': False, 'data_path': '/content/data/cifar-10-batches-py', 'dataset': 'cifar10', 'decay': 0.0001, 'enable_bfa': True, 'epochs': 200, 'evaluate': False, 'fine_tune': False, 'gammas': [0.1, 0.1], 'gpu_id': 1, 'k_top': 10, 'lambda_coeff': 0.001, 'learning_rate': 0.001, 'manualSeed': 6741, 'model_only': False, 'momentum': 0.9, 'n_iter': 50, 'ngpu': 1, 'optimizer': 'SGD', 'print_freq': 50, 'quan_bitwidth': None, 'random_bfa': True, 'reset_weight': True, 'resume': '', 'save_path': './save/2022-11-15/cifar10_resnet18_quan_BFA', 'schedule': [80, 120], 'start_epoch': 0, 'test_batch_size': 256, 'use_cuda': False, 'workers': 8}\n",
            "Random Seed: 6741\n",
            "python version : 3.7.15 (default, Nov  7 2022, 22:00:21)  [GCC 11.2.0]\n",
            "torch  version : 1.1.0\n",
            "cudnn  version : 7501\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "=> creating model 'resnet18_quan'\n",
            "=> network :\n",
            " ResNet(\n",
            "  (conv1): quan_Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace)\n",
            "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (layer1): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): quan_Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace)\n",
            "      (conv2): quan_Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): quan_Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace)\n",
            "      (conv2): quan_Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): quan_Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace)\n",
            "      (conv2): quan_Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): quan_Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): quan_Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace)\n",
            "      (conv2): quan_Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): quan_Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace)\n",
            "      (conv2): quan_Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): quan_Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): quan_Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace)\n",
            "      (conv2): quan_Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): quan_Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace)\n",
            "      (conv2): quan_Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): quan_Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): quan_Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace)\n",
            "      (conv2): quan_Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (fc): quan_Linear(in_features=512, out_features=1000, bias=True)\n",
            ")\n",
            "using SGD as optimizer\n",
            "=> do not use any checkpoint for resnet18_quan model\n",
            "  **Test** Prec@1 0.020 Prec@5 0.210 Error@1 99.980\n",
            "k_top is set to 10\n",
            "Attack sample size is 64\n",
            "**********************************\n",
            "attacked module: layer3.0.conv1\n",
            "attacked weight index: 235465\n",
            "weight before attack: tensor(-7.)\n",
            "weight after attack: tensor(-3.)\n",
            "Iteration: [001/050]   Attack Time 0.003 (0.003)  [2022-11-15 05:28:00]\n",
            "bit flips: 1\n",
            "hamming_dist: 1\n",
            "  **Test** Prec@1 0.020 Prec@5 0.210 Error@1 99.980\n",
            "iteration Time 21.533 (21.533)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluation CIFAR resnet18 after Bit-Fltp**"
      ],
      "metadata": {
        "id": "gq6JFJQQldsd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!bash eval_CIFAR_resnet18.sh"
      ],
      "metadata": {
        "id": "1iT1IkRr1Jj6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78b88f18-c33e-44ae-e1fb-43d563731a43"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current host is: alpha\n",
            "mkdir: cannot create directory ‘save’: File exists\n",
            "mkdir: cannot create directory ‘2022-11-15’: File exists\n",
            "save path : ./save/2022-11-15/cifar10_resnet18_eval/\n",
            "{'arch': 'resnet18', 'attack_sample_size': 128, 'clustering': False, 'data_path': '/content/data/cifar-10-batches-py', 'dataset': 'cifar10', 'decay': 0.0001, 'enable_bfa': False, 'epochs': 200, 'evaluate': True, 'fine_tune': False, 'gammas': [0.1, 0.1], 'gpu_id': 1, 'k_top': None, 'lambda_coeff': 0.001, 'learning_rate': 0.001, 'manualSeed': 3186, 'model_only': False, 'momentum': 0.9, 'n_iter': 20, 'ngpu': 1, 'optimizer': 'SGD', 'print_freq': 100, 'quan_bitwidth': None, 'random_bfa': False, 'reset_weight': False, 'resume': '', 'save_path': './save/2022-11-15/cifar10_resnet18_eval/', 'schedule': [80, 120], 'start_epoch': 0, 'test_batch_size': 256, 'use_cuda': False, 'workers': 8}\n",
            "Random Seed: 3186\n",
            "python version : 3.7.15 (default, Nov  7 2022, 22:00:21)  [GCC 11.2.0]\n",
            "torch  version : 1.1.0\n",
            "cudnn  version : 7501\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "=> creating model 'resnet18'\n",
            "=> network :\n",
            " ResNet(\n",
            "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace)\n",
            "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (layer1): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
            ")\n",
            "using SGD as optimizer\n",
            "=> do not use any checkpoint for resnet18 model\n",
            "  **Test** Prec@1 0.020 Prec@5 0.210 Error@1 99.980\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluation CIFAR  Quantized resnet18 after Bit-Fltp**"
      ],
      "metadata": {
        "id": "7McERFLBlwT7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!bash eval_CIFAR_resnet18_quan.sh"
      ],
      "metadata": {
        "id": "3Xmpjath1tzV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8fc24b14-a104-48e9-f203-68520eddfe6c"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current host is: alpha\n",
            "mkdir: cannot create directory ‘save’: File exists\n",
            "mkdir: cannot create directory ‘2022-11-15’: File exists\n",
            "save path : ./save/2022-11-15/cifar10_resnet18_quan_eval/\n",
            "{'arch': 'resnet18_quan', 'attack_sample_size': 128, 'clustering': False, 'data_path': '/content/data/cifar-10-batches-py', 'dataset': 'cifar10', 'decay': 0.0001, 'enable_bfa': False, 'epochs': 200, 'evaluate': True, 'fine_tune': False, 'gammas': [0.1, 0.1], 'gpu_id': 1, 'k_top': None, 'lambda_coeff': 0.001, 'learning_rate': 0.001, 'manualSeed': 1410, 'model_only': False, 'momentum': 0.9, 'n_iter': 20, 'ngpu': 1, 'optimizer': 'SGD', 'print_freq': 100, 'quan_bitwidth': None, 'random_bfa': False, 'reset_weight': True, 'resume': '', 'save_path': './save/2022-11-15/cifar10_resnet18_quan_eval/', 'schedule': [80, 120], 'start_epoch': 0, 'test_batch_size': 256, 'use_cuda': False, 'workers': 8}\n",
            "Random Seed: 1410\n",
            "python version : 3.7.15 (default, Nov  7 2022, 22:00:21)  [GCC 11.2.0]\n",
            "torch  version : 1.1.0\n",
            "cudnn  version : 7501\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "=> creating model 'resnet18_quan'\n",
            "=> network :\n",
            " ResNet(\n",
            "  (conv1): quan_Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace)\n",
            "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (layer1): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): quan_Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace)\n",
            "      (conv2): quan_Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): quan_Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace)\n",
            "      (conv2): quan_Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): quan_Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace)\n",
            "      (conv2): quan_Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): quan_Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): quan_Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace)\n",
            "      (conv2): quan_Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): quan_Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace)\n",
            "      (conv2): quan_Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): quan_Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): quan_Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace)\n",
            "      (conv2): quan_Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): quan_Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace)\n",
            "      (conv2): quan_Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): quan_Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): quan_Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace)\n",
            "      (conv2): quan_Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (fc): quan_Linear(in_features=512, out_features=1000, bias=True)\n",
            ")\n",
            "using SGD as optimizer\n",
            "=> do not use any checkpoint for resnet18_quan model\n",
            "  **Test** Prec@1 0.020 Prec@5 0.210 Error@1 99.980\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Training-based BFA defense**"
      ],
      "metadata": {
        "id": "eQuxZ4nM6l0w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1. Binarization-aware training**"
      ],
      "metadata": {
        "id": "DyD9kRo46too"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Copy file quantization-binariztaion.py from models folder in quantization.py**"
      ],
      "metadata": {
        "id": "ueD9qHZamUk8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "for 10 epoches"
      ],
      "metadata": {
        "id": "IVsHMNb0BGBM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!bash train_CIFAR.sh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HPNVd6uq2D5R",
        "outputId": "0c9fcb2e-91d2-4c9f-f8d1-10db3d99cad9"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current host is: alpha\n",
            "mkdir: cannot create directory ‘save’: File exists\n",
            "mkdir: cannot create directory ‘2022-11-15’: File exists\n",
            "save path : ./save/2022-11-15/cifar10_resnet18_quan_10_SGD_binarized\n",
            "{'arch': 'resnet18_quan', 'attack_sample_size': 128, 'clustering': False, 'data_path': '/content/data/cifar-10-batches-py', 'dataset': 'cifar10', 'decay': 0.0003, 'enable_bfa': False, 'epochs': 10, 'evaluate': False, 'fine_tune': False, 'gammas': [0.1, 0.1], 'gpu_id': 1, 'k_top': None, 'lambda_coeff': 0.001, 'learning_rate': 0.1, 'manualSeed': 995, 'model_only': False, 'momentum': 0.9, 'n_iter': 20, 'ngpu': 1, 'optimizer': 'SGD', 'print_freq': 100, 'quan_bitwidth': None, 'random_bfa': False, 'reset_weight': False, 'resume': '', 'save_path': './save/2022-11-15/cifar10_resnet18_quan_10_SGD_binarized', 'schedule': [80, 120], 'start_epoch': 0, 'test_batch_size': 128, 'use_cuda': False, 'workers': 4}\n",
            "Random Seed: 995\n",
            "python version : 3.7.15 (default, Nov  7 2022, 22:00:21)  [GCC 11.2.0]\n",
            "torch  version : 1.1.0\n",
            "cudnn  version : 7501\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "=> creating model 'resnet18_quan'\n",
            "=> network :\n",
            " ResNet(\n",
            "  (conv1): quan_Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace)\n",
            "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (layer1): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): quan_Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace)\n",
            "      (conv2): quan_Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): quan_Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace)\n",
            "      (conv2): quan_Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): quan_Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace)\n",
            "      (conv2): quan_Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): quan_Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): quan_Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace)\n",
            "      (conv2): quan_Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): quan_Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace)\n",
            "      (conv2): quan_Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): quan_Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): quan_Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace)\n",
            "      (conv2): quan_Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): quan_Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace)\n",
            "      (conv2): quan_Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): quan_Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): quan_Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace)\n",
            "      (conv2): quan_Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (fc): quan_Linear(in_features=512, out_features=1000, bias=True)\n",
            ")\n",
            "using SGD as optimizer\n",
            "=> do not use any checkpoint for resnet18_quan model\n",
            "\n",
            "==>>[2022-11-15 05:30:36] [Epoch=000/010] [Need: 00:00:00] [LR=0.1000][M=0.90] [Best : Accuracy=0.00, Error=100.00]\n",
            "  Epoch: [000][000/391]   Time 2.563 (2.563)   Data 0.305 (0.305)   Loss 9.3409 (9.3409)   Prec@1 0.000 (0.000)   Prec@5 0.000 (0.000)   [2022-11-15 05:30:38]\n",
            "  Epoch: [000][100/391]   Time 1.358 (1.418)   Data 0.002 (0.005)   Loss 2.1083 (2.6635)   Prec@1 17.969 (12.631)   Prec@5 73.438 (55.871)   [2022-11-15 05:32:59]\n",
            "  Epoch: [000][200/391]   Time 1.389 (1.421)   Data 0.002 (0.003)   Loss 1.8548 (2.3478)   Prec@1 30.469 (18.074)   Prec@5 85.156 (68.657)   [2022-11-15 05:35:21]\n",
            "  Epoch: [000][300/391]   Time 1.382 (1.408)   Data 0.002 (0.003)   Loss 1.8603 (2.1851)   Prec@1 27.344 (22.680)   Prec@5 85.938 (74.374)   [2022-11-15 05:37:39]\n",
            "  **Train** Prec@1 25.412 Prec@5 77.340 Error@1 74.588\n",
            "  **Test** Prec@1 36.700 Prec@5 87.010 Error@1 63.300\n",
            "---- save figure the accuracy/loss curve of train/val into ./save/2022-11-15/cifar10_resnet18_quan_10_SGD_binarized/curve.png\n",
            "total weight changes: 0\n",
            "\n",
            "==>>[2022-11-15 05:40:17] [Epoch=001/010] [Need: 01:26:46] [LR=0.1000][M=0.90] [Best : Accuracy=36.70, Error=63.30]\n",
            "  Epoch: [001][000/391]   Time 1.920 (1.920)   Data 0.180 (0.180)   Loss 1.8618 (1.8618)   Prec@1 35.938 (35.938)   Prec@5 82.812 (82.812)   [2022-11-15 05:40:19]\n",
            "  Epoch: [001][100/391]   Time 1.376 (1.389)   Data 0.002 (0.004)   Loss 1.6640 (1.7157)   Prec@1 38.281 (36.231)   Prec@5 86.719 (88.219)   [2022-11-15 05:42:38]\n",
            "  Epoch: [001][200/391]   Time 1.362 (1.402)   Data 0.002 (0.003)   Loss 1.6420 (1.6747)   Prec@1 41.406 (38.056)   Prec@5 87.500 (88.895)   [2022-11-15 05:44:59]\n",
            "  Epoch: [001][300/391]   Time 1.877 (1.396)   Data 0.002 (0.002)   Loss 1.8101 (1.6523)   Prec@1 39.062 (39.070)   Prec@5 85.156 (89.213)   [2022-11-15 05:47:18]\n",
            "  **Train** Prec@1 40.290 Prec@5 89.606 Error@1 59.710\n",
            "  **Test** Prec@1 44.700 Prec@5 92.180 Error@1 55.300\n",
            "---- save figure the accuracy/loss curve of train/val into ./save/2022-11-15/cifar10_resnet18_quan_10_SGD_binarized/curve.png\n",
            "total weight changes: 0\n",
            "\n",
            "==>>[2022-11-15 05:49:54] [Epoch=002/010] [Need: 01:17:00] [LR=0.1000][M=0.90] [Best : Accuracy=44.70, Error=55.30]\n",
            "  Epoch: [002][000/391]   Time 1.900 (1.900)   Data 0.183 (0.183)   Loss 1.6074 (1.6074)   Prec@1 37.500 (37.500)   Prec@5 94.531 (94.531)   [2022-11-15 05:49:56]\n",
            "  Epoch: [002][100/391]   Time 1.402 (1.432)   Data 0.002 (0.004)   Loss 1.4504 (1.4871)   Prec@1 43.750 (46.117)   Prec@5 90.625 (91.801)   [2022-11-15 05:52:19]\n",
            "  Epoch: [002][200/391]   Time 1.392 (1.410)   Data 0.002 (0.003)   Loss 1.5976 (1.4671)   Prec@1 44.531 (47.065)   Prec@5 90.625 (91.908)   [2022-11-15 05:54:37]\n",
            "  Epoch: [002][300/391]   Time 1.379 (1.417)   Data 0.002 (0.002)   Loss 1.6557 (1.4526)   Prec@1 47.656 (47.560)   Prec@5 89.844 (92.221)   [2022-11-15 05:57:01]\n",
            "  **Train** Prec@1 48.204 Prec@5 92.576 Error@1 51.796\n",
            "  **Test** Prec@1 48.380 Prec@5 92.840 Error@1 51.620\n",
            "---- save figure the accuracy/loss curve of train/val into ./save/2022-11-15/cifar10_resnet18_quan_10_SGD_binarized/curve.png\n",
            "total weight changes: 0\n",
            "\n",
            "==>>[2022-11-15 05:59:35] [Epoch=003/010] [Need: 01:07:30] [LR=0.1000][M=0.90] [Best : Accuracy=48.38, Error=51.62]\n",
            "  Epoch: [003][000/391]   Time 1.867 (1.867)   Data 0.165 (0.165)   Loss 1.4158 (1.4158)   Prec@1 46.875 (46.875)   Prec@5 92.969 (92.969)   [2022-11-15 05:59:37]\n",
            "  Epoch: [003][100/391]   Time 1.404 (1.429)   Data 0.002 (0.004)   Loss 1.4356 (1.3509)   Prec@1 48.438 (50.990)   Prec@5 91.406 (93.781)   [2022-11-15 06:01:59]\n",
            "  Epoch: [003][200/391]   Time 1.410 (1.428)   Data 0.002 (0.003)   Loss 1.4782 (1.3532)   Prec@1 49.219 (51.104)   Prec@5 94.531 (93.723)   [2022-11-15 06:04:22]\n",
            "  Epoch: [003][300/391]   Time 1.376 (1.415)   Data 0.002 (0.002)   Loss 1.3633 (1.3373)   Prec@1 55.469 (51.752)   Prec@5 96.094 (93.760)   [2022-11-15 06:06:41]\n",
            "  **Train** Prec@1 52.260 Prec@5 93.790 Error@1 47.740\n",
            "  **Test** Prec@1 51.180 Prec@5 93.630 Error@1 48.820\n",
            "---- save figure the accuracy/loss curve of train/val into ./save/2022-11-15/cifar10_resnet18_quan_10_SGD_binarized/curve.png\n",
            "total weight changes: 0\n",
            "\n",
            "==>>[2022-11-15 06:09:18] [Epoch=004/010] [Need: 00:57:59] [LR=0.1000][M=0.90] [Best : Accuracy=51.18, Error=48.82]\n",
            "  Epoch: [004][000/391]   Time 1.841 (1.841)   Data 0.126 (0.126)   Loss 1.3465 (1.3465)   Prec@1 57.812 (57.812)   Prec@5 92.969 (92.969)   [2022-11-15 06:09:20]\n",
            "  Epoch: [004][100/391]   Time 1.381 (1.396)   Data 0.002 (0.003)   Loss 1.3876 (1.2575)   Prec@1 46.875 (55.175)   Prec@5 94.531 (94.554)   [2022-11-15 06:11:39]\n",
            "  Epoch: [004][200/391]   Time 1.396 (1.410)   Data 0.002 (0.002)   Loss 1.4353 (1.2507)   Prec@1 46.094 (55.473)   Prec@5 96.094 (94.601)   [2022-11-15 06:14:02]\n",
            "  Epoch: [004][300/391]   Time 1.362 (1.401)   Data 0.002 (0.002)   Loss 1.2424 (1.2454)   Prec@1 57.812 (55.894)   Prec@5 96.094 (94.518)   [2022-11-15 06:16:20]\n",
            "  **Train** Prec@1 56.058 Prec@5 94.644 Error@1 43.942\n",
            "  **Test** Prec@1 48.220 Prec@5 91.910 Error@1 51.780\n",
            "---- save figure the accuracy/loss curve of train/val into ./save/2022-11-15/cifar10_resnet18_quan_10_SGD_binarized/curve.png\n",
            "total weight changes: 0\n",
            "\n",
            "==>>[2022-11-15 06:18:58] [Epoch=005/010] [Need: 00:48:18] [LR=0.1000][M=0.90] [Best : Accuracy=51.18, Error=48.82]\n",
            "  Epoch: [005][000/391]   Time 1.883 (1.883)   Data 0.126 (0.126)   Loss 1.1870 (1.1870)   Prec@1 60.938 (60.938)   Prec@5 93.750 (93.750)   [2022-11-15 06:18:59]\n",
            "  Epoch: [005][100/391]   Time 1.383 (1.430)   Data 0.002 (0.003)   Loss 1.3041 (1.2049)   Prec@1 53.906 (57.457)   Prec@5 93.750 (94.964)   [2022-11-15 06:21:22]\n",
            "  Epoch: [005][200/391]   Time 1.407 (1.407)   Data 0.002 (0.003)   Loss 1.1114 (1.1897)   Prec@1 62.500 (57.933)   Prec@5 94.531 (95.200)   [2022-11-15 06:23:40]\n",
            "  Epoch: [005][300/391]   Time 1.458 (1.421)   Data 0.002 (0.002)   Loss 0.9760 (1.1814)   Prec@1 66.406 (58.303)   Prec@5 96.875 (95.263)   [2022-11-15 06:26:05]\n",
            "  **Train** Prec@1 58.390 Prec@5 95.256 Error@1 41.610\n",
            "  **Test** Prec@1 60.310 Prec@5 95.520 Error@1 39.690\n",
            "---- save figure the accuracy/loss curve of train/val into ./save/2022-11-15/cifar10_resnet18_quan_10_SGD_binarized/curve.png\n",
            "total weight changes: 0\n",
            "\n",
            "==>>[2022-11-15 06:28:44] [Epoch=006/010] [Need: 00:38:43] [LR=0.1000][M=0.90] [Best : Accuracy=60.31, Error=39.69]\n",
            "  Epoch: [006][000/391]   Time 1.908 (1.908)   Data 0.187 (0.187)   Loss 1.1252 (1.1252)   Prec@1 60.156 (60.156)   Prec@5 92.188 (92.188)   [2022-11-15 06:28:45]\n",
            "  Epoch: [006][100/391]   Time 1.382 (1.440)   Data 0.002 (0.004)   Loss 1.1805 (1.1426)   Prec@1 64.844 (59.692)   Prec@5 96.875 (95.692)   [2022-11-15 06:31:09]\n",
            "  Epoch: [006][200/391]   Time 1.396 (1.416)   Data 0.002 (0.003)   Loss 1.0057 (1.1284)   Prec@1 65.625 (60.172)   Prec@5 96.875 (95.826)   [2022-11-15 06:33:28]\n",
            "  Epoch: [006][300/391]   Time 1.389 (1.422)   Data 0.002 (0.003)   Loss 1.1976 (1.1288)   Prec@1 57.031 (60.128)   Prec@5 96.875 (95.816)   [2022-11-15 06:35:52]\n",
            "  **Train** Prec@1 60.238 Prec@5 95.854 Error@1 39.762\n",
            "  **Test** Prec@1 59.980 Prec@5 95.540 Error@1 40.020\n",
            "---- save figure the accuracy/loss curve of train/val into ./save/2022-11-15/cifar10_resnet18_quan_10_SGD_binarized/curve.png\n",
            "total weight changes: 0\n",
            "\n",
            "==>>[2022-11-15 06:38:30] [Epoch=007/010] [Need: 00:29:04] [LR=0.1000][M=0.90] [Best : Accuracy=60.31, Error=39.69]\n",
            "  Epoch: [007][000/391]   Time 1.913 (1.913)   Data 0.185 (0.185)   Loss 1.0862 (1.0862)   Prec@1 61.719 (61.719)   Prec@5 96.875 (96.875)   [2022-11-15 06:38:32]\n",
            "  Epoch: [007][100/391]   Time 1.427 (1.427)   Data 0.002 (0.004)   Loss 1.1943 (1.0931)   Prec@1 58.594 (61.502)   Prec@5 93.750 (96.101)   [2022-11-15 06:40:54]\n",
            "  Epoch: [007][200/391]   Time 1.414 (1.440)   Data 0.002 (0.003)   Loss 0.8566 (1.0913)   Prec@1 70.312 (61.664)   Prec@5 95.312 (96.179)   [2022-11-15 06:43:20]\n",
            "  Epoch: [007][300/391]   Time 1.405 (1.430)   Data 0.002 (0.003)   Loss 1.1616 (1.0873)   Prec@1 53.906 (61.685)   Prec@5 97.656 (96.169)   [2022-11-15 06:45:40]\n",
            "  **Train** Prec@1 61.918 Prec@5 96.070 Error@1 38.082\n",
            "  **Test** Prec@1 60.150 Prec@5 95.570 Error@1 39.850\n",
            "---- save figure the accuracy/loss curve of train/val into ./save/2022-11-15/cifar10_resnet18_quan_10_SGD_binarized/curve.png\n",
            "total weight changes: 0\n",
            "\n",
            "==>>[2022-11-15 06:48:21] [Epoch=008/010] [Need: 00:19:25] [LR=0.1000][M=0.90] [Best : Accuracy=60.31, Error=39.69]\n",
            "  Epoch: [008][000/391]   Time 1.952 (1.952)   Data 0.227 (0.227)   Loss 1.0724 (1.0724)   Prec@1 61.719 (61.719)   Prec@5 95.312 (95.312)   [2022-11-15 06:48:23]\n",
            "  Epoch: [008][100/391]   Time 1.376 (1.409)   Data 0.002 (0.004)   Loss 0.9244 (1.0699)   Prec@1 67.969 (62.794)   Prec@5 96.094 (96.086)   [2022-11-15 06:50:43]\n",
            "  Epoch: [008][200/391]   Time 1.394 (1.421)   Data 0.002 (0.003)   Loss 0.9323 (1.0562)   Prec@1 65.625 (63.188)   Prec@5 98.438 (96.311)   [2022-11-15 06:53:06]\n",
            "  Epoch: [008][300/391]   Time 1.921 (1.414)   Data 0.002 (0.003)   Loss 1.0941 (1.0538)   Prec@1 63.281 (63.263)   Prec@5 95.312 (96.320)   [2022-11-15 06:55:27]\n",
            "  **Train** Prec@1 63.224 Prec@5 96.340 Error@1 36.776\n",
            "  **Test** Prec@1 64.460 Prec@5 96.680 Error@1 35.540\n",
            "=> Obtain best accuracy, and update the best model\n",
            "---- save figure the accuracy/loss curve of train/val into ./save/2022-11-15/cifar10_resnet18_quan_10_SGD_binarized/curve.png\n",
            "total weight changes: 0\n",
            "\n",
            "==>>[2022-11-15 06:58:05] [Epoch=009/010] [Need: 00:09:42] [LR=0.1000][M=0.90] [Best : Accuracy=64.46, Error=35.54]\n",
            "  Epoch: [009][000/391]   Time 1.906 (1.906)   Data 0.187 (0.187)   Loss 0.9177 (0.9177)   Prec@1 71.875 (71.875)   Prec@5 96.875 (96.875)   [2022-11-15 06:58:07]\n",
            "  Epoch: [009][100/391]   Time 1.381 (1.446)   Data 0.002 (0.004)   Loss 1.0211 (1.0298)   Prec@1 60.938 (63.606)   Prec@5 96.875 (96.488)   [2022-11-15 07:00:31]\n",
            "  Epoch: [009][200/391]   Time 1.402 (1.428)   Data 0.002 (0.003)   Loss 1.0905 (1.0333)   Prec@1 65.625 (63.643)   Prec@5 96.094 (96.521)   [2022-11-15 07:02:52]\n",
            "  Epoch: [009][300/391]   Time 1.401 (1.433)   Data 0.002 (0.003)   Loss 1.0334 (1.0254)   Prec@1 64.844 (64.138)   Prec@5 96.875 (96.639)   [2022-11-15 07:05:16]\n",
            "  **Train** Prec@1 64.174 Prec@5 96.674 Error@1 35.826\n",
            "  **Test** Prec@1 62.360 Prec@5 96.230 Error@1 37.640\n",
            "---- save figure the accuracy/loss curve of train/val into ./save/2022-11-15/cifar10_resnet18_quan_10_SGD_binarized/curve.png\n",
            "total weight changes: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!bash BFA_CIFAR.sh"
      ],
      "metadata": {
        "id": "Zmi90cn8xQxn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f8023ba-939e-4716-89a3-a39116eed8c4"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current host is: alpha\n",
            "mkdir: cannot create directory ‘save’: File exists\n",
            "mkdir: cannot create directory ‘2022-11-15’: File exists\n",
            "save path : ./save/2022-11-15/cifar10_resnet18_quan_BFA_defense_test_binarized\n",
            "{'arch': 'resnet18_quan', 'attack_sample_size': 128, 'clustering': False, 'data_path': '/content/data/cifar-10-batches-py', 'dataset': 'cifar10', 'decay': 0.0001, 'enable_bfa': True, 'epochs': 200, 'evaluate': True, 'fine_tune': True, 'gammas': [0.1, 0.1], 'gpu_id': 1, 'k_top': None, 'lambda_coeff': 0.001, 'learning_rate': 0.001, 'manualSeed': 7442, 'model_only': False, 'momentum': 0.9, 'n_iter': 50, 'ngpu': 1, 'optimizer': 'SGD', 'print_freq': 50, 'quan_bitwidth': None, 'random_bfa': False, 'reset_weight': True, 'resume': '/content/BFA/save/2022-11-15/cifar10_resnet18_quan_10_SGD_binarized/checkpoint.pth.tar', 'save_path': './save/2022-11-15/cifar10_resnet18_quan_BFA_defense_test_binarized', 'schedule': [80, 120], 'start_epoch': 0, 'test_batch_size': 128, 'use_cuda': False, 'workers': 8}\n",
            "Random Seed: 7442\n",
            "python version : 3.7.15 (default, Nov  7 2022, 22:00:21)  [GCC 11.2.0]\n",
            "torch  version : 1.1.0\n",
            "cudnn  version : 7501\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "=> creating model 'resnet18_quan'\n",
            "=> network :\n",
            " ResNet(\n",
            "  (conv1): quan_Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace)\n",
            "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (layer1): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): quan_Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace)\n",
            "      (conv2): quan_Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): quan_Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace)\n",
            "      (conv2): quan_Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): quan_Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace)\n",
            "      (conv2): quan_Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): quan_Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): quan_Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace)\n",
            "      (conv2): quan_Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): quan_Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace)\n",
            "      (conv2): quan_Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): quan_Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): quan_Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace)\n",
            "      (conv2): quan_Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): quan_Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace)\n",
            "      (conv2): quan_Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): quan_Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): quan_Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace)\n",
            "      (conv2): quan_Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (fc): quan_Linear(in_features=512, out_features=1000, bias=True)\n",
            ")\n",
            "using SGD as optimizer\n",
            "=> loading checkpoint '/content/BFA/save/2022-11-15/cifar10_resnet18_quan_10_SGD_binarized/checkpoint.pth.tar'\n",
            "=> loaded checkpoint '/content/BFA/save/2022-11-15/cifar10_resnet18_quan_10_SGD_binarized/checkpoint.pth.tar' (epoch 0)\n",
            "  **Test** Prec@1 62.360 Prec@5 96.230 Error@1 37.640\n",
            "k_top is set to None\n",
            "Attack sample size is 128\n",
            "**********************************\n",
            "attacked module: conv1\n",
            "attacked weight index: [55  1  1  1]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [55  1  3  0]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [55  1  6  6]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [55  2  3  0]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [59  1  2  0]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [62  0  6  0]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "Iteration: [001/050]   Attack Time 45.252 (45.252)  [2022-11-15 07:09:03]\n",
            "loss before attack: 0.4650\n",
            "loss after attack: 0.4693\n",
            "bit flips: 6\n",
            "hamming_dist: 6\n",
            "  **Test** Prec@1 61.600 Prec@5 96.100 Error@1 38.400\n",
            "iteration Time 20.341 (20.341)\n",
            "**********************************\n",
            "attacked module: conv1\n",
            "attacked weight index: [55  1  0  0]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [55  1  1  1]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [55  1  1  3]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [55  1  3  0]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [55  1  4  0]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [55  2  1  0]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "Iteration: [002/050]   Attack Time 41.623 (43.438)  [2022-11-15 07:10:05]\n",
            "loss before attack: 0.4693\n",
            "loss after attack: 0.4732\n",
            "bit flips: 12\n",
            "hamming_dist: 8\n",
            "  **Test** Prec@1 62.450 Prec@5 96.080 Error@1 37.550\n",
            "iteration Time 20.727 (20.534)\n",
            "**********************************\n",
            "attacked module: conv1\n",
            "attacked weight index: [55  1  1  3]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [55  2  1  0]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [55  2  1  1]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [55  2  2  0]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [62  2  0  6]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [62  2  1  2]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [62  2  1  3]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [62  2  1  4]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "Iteration: [003/050]   Attack Time 54.718 (47.198)  [2022-11-15 07:11:20]\n",
            "loss before attack: 0.4732\n",
            "loss after attack: 0.4801\n",
            "bit flips: 20\n",
            "hamming_dist: 12\n",
            "  **Test** Prec@1 60.150 Prec@5 96.020 Error@1 39.850\n",
            "iteration Time 20.773 (20.614)\n",
            "**********************************\n",
            "attacked module: layer1.0.conv1\n",
            "attacked weight index: [22 62  1  1]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [22 62  1  2]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [22 62  2  1]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [28 62  0  1]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [28 62  0  2]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [28 62  1  2]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "Iteration: [004/050]   Attack Time 41.628 (45.805)  [2022-11-15 07:12:23]\n",
            "loss before attack: 0.4801\n",
            "loss after attack: 0.4839\n",
            "bit flips: 26\n",
            "hamming_dist: 18\n",
            "  **Test** Prec@1 60.310 Prec@5 95.900 Error@1 39.690\n",
            "iteration Time 20.951 (20.698)\n",
            "**********************************\n",
            "attacked module: conv1\n",
            "attacked weight index: [62  0  1  1]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [62  0  1  5]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [62  0  2  1]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [62  0  2  6]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [62  1  1  1]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [62  1  1  5]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [62  1  2  6]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "Iteration: [005/050]   Attack Time 51.971 (47.039)  [2022-11-15 07:13:36]\n",
            "loss before attack: 0.4839\n",
            "loss after attack: 0.4968\n",
            "bit flips: 33\n",
            "hamming_dist: 25\n",
            "  **Test** Prec@1 61.600 Prec@5 95.950 Error@1 38.400\n",
            "iteration Time 20.707 (20.700)\n",
            "**********************************\n",
            "attacked module: conv1\n",
            "attacked weight index: [62  0  1  5]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [62  1  0  2]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [62  1  0  3]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [62  1  0  5]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [62  1  0  6]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [62  1  1  4]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [62  1  1  5]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [62  1  2  6]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "Iteration: [006/050]   Attack Time 54.794 (48.331)  [2022-11-15 07:14:51]\n",
            "loss before attack: 0.4968\n",
            "loss after attack: 0.5031\n",
            "bit flips: 41\n",
            "hamming_dist: 27\n",
            "  **Test** Prec@1 59.240 Prec@5 95.510 Error@1 40.760\n",
            "iteration Time 20.559 (20.676)\n",
            "**********************************\n",
            "attacked module: conv1\n",
            "attacked weight index: [62  1  0  3]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [62  1  0  4]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [62  1  0  5]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [62  1  0  6]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [62  1  1  5]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [62  1  1  6]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [62  1  2  6]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [62  2  0  4]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [62  2  0  6]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "Iteration: [007/050]   Attack Time 60.594 (50.083)  [2022-11-15 07:16:12]\n",
            "loss before attack: 0.5031\n",
            "loss after attack: 0.5164\n",
            "bit flips: 50\n",
            "hamming_dist: 28\n",
            "  **Test** Prec@1 61.630 Prec@5 95.940 Error@1 38.370\n",
            "iteration Time 20.859 (20.703)\n",
            "**********************************\n",
            "attacked module: conv1\n",
            "attacked weight index: [62  1  0  4]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [62  1  0  5]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [62  1  0  6]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [62  1  1  5]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [62  1  1  6]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [62  1  2  6]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [62  2  0  4]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [62  2  0  5]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [62  2  0  6]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [62  2  2  5]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "Iteration: [008/050]   Attack Time 71.372 (52.744)  [2022-11-15 07:17:45]\n",
            "loss before attack: 0.5164\n",
            "loss after attack: 0.5227\n",
            "bit flips: 60\n",
            "hamming_dist: 28\n",
            "  **Test** Prec@1 58.540 Prec@5 95.430 Error@1 41.460\n",
            "iteration Time 20.819 (20.717)\n",
            "**********************************\n",
            "attacked module: layer2.0.downsample.0\n",
            "attacked weight index: [39 62  0  0]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [42 10  0  0]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [42 19  0  0]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [42 32  0  0]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [42 62  0  0]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [43 62  0  0]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [45 62  0  0]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [54 62  0  0]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [59 62  0  0]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "Iteration: [009/050]   Attack Time 60.788 (53.638)  [2022-11-15 07:19:06]\n",
            "loss before attack: 0.5227\n",
            "loss after attack: 0.5450\n",
            "bit flips: 69\n",
            "hamming_dist: 37\n",
            "  **Test** Prec@1 53.340 Prec@5 94.970 Error@1 46.660\n",
            "iteration Time 20.955 (20.744)\n",
            "**********************************\n",
            "attacked module: fc\n",
            "attacked weight index: [ 2 26]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [ 2 63]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [  2 220]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [  2 226]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [  2 262]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [  2 284]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [  2 460]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "Iteration: [010/050]   Attack Time 48.255 (53.099)  [2022-11-15 07:20:15]\n",
            "loss before attack: 0.5450\n",
            "loss after attack: 0.5490\n",
            "bit flips: 76\n",
            "hamming_dist: 44\n",
            "  **Test** Prec@1 57.150 Prec@5 95.040 Error@1 42.850\n",
            "iteration Time 20.803 (20.750)\n",
            "**********************************\n",
            "attacked module: layer2.0.downsample.0\n",
            "attacked weight index: [42 62  0  0]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [43 62  0  0]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [45 62  0  0]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [80 62  0  0]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "Iteration: [011/050]   Attack Time 27.880 (50.807)  [2022-11-15 07:21:04]\n",
            "loss before attack: 0.5490\n",
            "loss after attack: 0.5492\n",
            "bit flips: 80\n",
            "hamming_dist: 42\n",
            "  **Test** Prec@1 59.650 Prec@5 95.750 Error@1 40.350\n",
            "iteration Time 20.765 (20.751)\n",
            "**********************************\n",
            "attacked module: layer2.0.downsample.0\n",
            "attacked weight index: [13 10  0  0]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [42 55  0  0]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [42 62  0  0]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [43 62  0  0]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [45 62  0  0]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [52 62  0  0]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "Iteration: [012/050]   Attack Time 45.380 (50.354)  [2022-11-15 07:22:10]\n",
            "loss before attack: 0.5492\n",
            "loss after attack: 0.5511\n",
            "bit flips: 86\n",
            "hamming_dist: 48\n",
            "  **Test** Prec@1 55.880 Prec@5 94.930 Error@1 44.120\n",
            "iteration Time 20.655 (20.743)\n",
            "**********************************\n",
            "attacked module: layer2.0.conv1\n",
            "attacked weight index: [41 62  2  1]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [124  62   1   1]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [124  62   1   2]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [124  62   2   0]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [124  62   2   1]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [124  62   2   2]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "Iteration: [013/050]   Attack Time 41.035 (49.638)  [2022-11-15 07:23:12]\n",
            "loss before attack: 0.5511\n",
            "loss after attack: 0.5541\n",
            "bit flips: 92\n",
            "hamming_dist: 54\n",
            "  **Test** Prec@1 57.480 Prec@5 95.410 Error@1 42.520\n",
            "iteration Time 22.133 (20.850)\n",
            "**********************************\n",
            "attacked module: layer2.0.conv1\n",
            "attacked weight index: [124  62   0   2]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [124  62   1   0]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [124  62   1   1]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [124  62   1   2]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [124  62   2   0]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [124  62   2   1]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [124  62   2   2]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "Iteration: [014/050]   Attack Time 48.234 (49.537)  [2022-11-15 07:24:22]\n",
            "loss before attack: 0.5541\n",
            "loss after attack: 0.5580\n",
            "bit flips: 99\n",
            "hamming_dist: 51\n",
            "  **Test** Prec@1 56.130 Prec@5 94.980 Error@1 43.870\n",
            "iteration Time 21.980 (20.931)\n",
            "**********************************\n",
            "attacked module: layer2.0.downsample.0\n",
            "attacked weight index: [42 10  0  0]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [42 19  0  0]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [42 55  0  0]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [42 62  0  0]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [43 62  0  0]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [77 62  0  0]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "Iteration: [015/050]   Attack Time 41.072 (48.973)  [2022-11-15 07:25:25]\n",
            "loss before attack: 0.5580\n",
            "loss after attack: 0.5585\n",
            "bit flips: 105\n",
            "hamming_dist: 47\n",
            "  **Test** Prec@1 59.220 Prec@5 95.750 Error@1 40.780\n",
            "iteration Time 21.933 (20.997)\n",
            "**********************************\n",
            "attacked module: layer2.0.downsample.0\n",
            "attacked weight index: [42 10  0  0]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [42 19  0  0]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [42 26  0  0]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [42 55  0  0]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [42 62  0  0]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [43 10  0  0]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [43 62  0  0]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "Iteration: [016/050]   Attack Time 51.831 (49.152)  [2022-11-15 07:26:39]\n",
            "loss before attack: 0.5585\n",
            "loss after attack: 0.5696\n",
            "bit flips: 112\n",
            "hamming_dist: 54\n",
            "  **Test** Prec@1 54.690 Prec@5 94.790 Error@1 45.310\n",
            "iteration Time 21.918 (21.055)\n",
            "**********************************\n",
            "attacked module: layer2.0.downsample.0\n",
            "attacked weight index: [42 10  0  0]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [42 14  0  0]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [42 19  0  0]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [42 55  0  0]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [42 60  0  0]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [42 62  0  0]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [43 10  0  0]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [43 62  0  0]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "Iteration: [017/050]   Attack Time 54.265 (49.452)  [2022-11-15 07:27:55]\n",
            "loss before attack: 0.5696\n",
            "loss after attack: 0.5723\n",
            "bit flips: 120\n",
            "hamming_dist: 50\n",
            "  **Test** Prec@1 59.440 Prec@5 95.770 Error@1 40.560\n",
            "iteration Time 22.162 (21.120)\n",
            "**********************************\n",
            "attacked module: layer2.0.downsample.0\n",
            "attacked weight index: [42 10  0  0]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [42 14  0  0]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [42 19  0  0]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [42 55  0  0]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [42 60  0  0]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [42 62  0  0]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [43 10  0  0]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [43 62  0  0]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [45 49  0  0]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "Iteration: [018/050]   Attack Time 61.224 (50.106)  [2022-11-15 07:29:19]\n",
            "loss before attack: 0.5723\n",
            "loss after attack: 0.5747\n",
            "bit flips: 129\n",
            "hamming_dist: 55\n",
            "  **Test** Prec@1 53.910 Prec@5 94.650 Error@1 46.090\n",
            "iteration Time 22.106 (21.175)\n",
            "**********************************\n",
            "attacked module: layer2.0.conv1\n",
            "attacked weight index: [124  10   2   2]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [124  62   0   1]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [124  62   1   0]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [124  62   1   1]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [124  62   1   2]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [124  62   2   0]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [124  62   2   1]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [124  62   2   2]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "Iteration: [019/050]   Attack Time 54.196 (50.322)  [2022-11-15 07:30:35]\n",
            "loss before attack: 0.5747\n",
            "loss after attack: 0.5778\n",
            "bit flips: 137\n",
            "hamming_dist: 61\n",
            "  **Test** Prec@1 55.700 Prec@5 94.940 Error@1 44.300\n",
            "iteration Time 26.305 (21.445)\n",
            "**********************************\n",
            "attacked module: layer2.0.conv1\n",
            "attacked weight index: [124  10   1   1]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [124  62   0   0]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [124  62   0   1]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [124  62   1   0]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [124  62   1   1]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [124  62   1   2]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [124  62   2   0]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [124  62   2   1]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [124  62   2   2]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "Iteration: [020/050]   Attack Time 61.179 (50.865)  [2022-11-15 07:32:02]\n",
            "loss before attack: 0.5778\n",
            "loss after attack: 0.5803\n",
            "bit flips: 146\n",
            "hamming_dist: 58\n",
            "  **Test** Prec@1 53.530 Prec@5 94.510 Error@1 46.470\n",
            "iteration Time 22.116 (21.478)\n",
            "**********************************\n",
            "attacked module: layer2.0.downsample.0\n",
            "attacked weight index: [42 10  0  0]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [42 19  0  0]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [42 55  0  0]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [42 60  0  0]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [42 62  0  0]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [43 10  0  0]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [43 41  0  0]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [43 62  0  0]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [45 62  0  0]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "Iteration: [021/050]   Attack Time 60.767 (51.336)  [2022-11-15 07:33:25]\n",
            "loss before attack: 0.5803\n",
            "loss after attack: 0.5817\n",
            "bit flips: 155\n",
            "hamming_dist: 53\n",
            "  **Test** Prec@1 59.130 Prec@5 95.690 Error@1 40.870\n",
            "iteration Time 22.018 (21.504)\n",
            "**********************************\n",
            "attacked module: layer2.0.downsample.0\n",
            "attacked weight index: [42 10  0  0]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [42 19  0  0]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [42 55  0  0]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [42 60  0  0]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [42 62  0  0]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [43 10  0  0]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [43 62  0  0]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [45 10  0  0]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [45 60  0  0]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [45 62  0  0]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [98 62  0  0]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "Iteration: [022/050]   Attack Time 74.506 (52.389)  [2022-11-15 07:35:02]\n",
            "loss before attack: 0.5817\n",
            "loss after attack: 0.6056\n",
            "bit flips: 166\n",
            "hamming_dist: 62\n",
            "  **Test** Prec@1 52.280 Prec@5 93.950 Error@1 47.720\n",
            "iteration Time 25.980 (21.708)\n",
            "**********************************\n",
            "attacked module: layer2.0.downsample.0\n",
            "attacked weight index: [39 62  0  0]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [42 10  0  0]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [42 14  0  0]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [42 19  0  0]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [42 55  0  0]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [42 60  0  0]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [42 62  0  0]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [43 10  0  0]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [43 62  0  0]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [45 10  0  0]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [45 19  0  0]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [45 60  0  0]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [45 62  0  0]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "Iteration: [023/050]   Attack Time 88.050 (53.940)  [2022-11-15 07:36:56]\n",
            "loss before attack: 0.6056\n",
            "loss after attack: 0.6074\n",
            "bit flips: 179\n",
            "hamming_dist: 55\n",
            "  **Test** Prec@1 58.990 Prec@5 95.550 Error@1 41.010\n",
            "iteration Time 22.062 (21.723)\n",
            "**********************************\n",
            "attacked module: conv1\n",
            "attacked weight index: [62  1  0  4]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [62  1  0  5]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [62  1  0  6]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [62  1  1  5]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [62  1  1  6]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [62  1  2  6]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [62  2  0  4]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [62  2  0  5]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [62  2  1  5]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [62  2  2  5]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [62  2  2  6]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "Iteration: [024/050]   Attack Time 74.689 (54.804)  [2022-11-15 07:38:33]\n",
            "loss before attack: 0.6074\n",
            "loss after attack: 0.6252\n",
            "bit flips: 190\n",
            "hamming_dist: 58\n",
            "  **Test** Prec@1 61.600 Prec@5 96.020 Error@1 38.400\n",
            "iteration Time 22.213 (21.743)\n",
            "**********************************\n",
            "attacked module: conv1\n",
            "attacked weight index: [62  1  0  4]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [62  1  0  5]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [62  1  0  6]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [62  1  1  5]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [62  1  1  6]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [62  1  2  5]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [62  1  2  6]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [62  2  0  4]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [62  2  0  5]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [62  2  1  5]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [62  2  2  4]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [62  2  2  5]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [62  2  2  6]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "Iteration: [025/050]   Attack Time 91.535 (56.274)  [2022-11-15 07:40:26]\n",
            "loss before attack: 0.6252\n",
            "loss after attack: 0.6401\n",
            "bit flips: 203\n",
            "hamming_dist: 57\n",
            "  **Test** Prec@1 57.440 Prec@5 95.240 Error@1 42.560\n",
            "iteration Time 21.987 (21.753)\n",
            "**********************************\n",
            "attacked module: layer2.0.downsample.0\n",
            "attacked weight index: [39 62  0  0]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [42 10  0  0]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [42 14  0  0]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [42 19  0  0]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [42 55  0  0]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [42 60  0  0]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [42 62  0  0]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [43 10  0  0]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [43 62  0  0]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [45 19  0  0]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [45 60  0  0]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [45 62  0  0]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [77 62  0  0]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "Iteration: [026/050]   Attack Time 87.542 (57.476)  [2022-11-15 07:42:16]\n",
            "loss before attack: 0.6401\n",
            "loss after attack: 0.6607\n",
            "bit flips: 216\n",
            "hamming_dist: 62\n",
            "  **Test** Prec@1 49.830 Prec@5 93.430 Error@1 50.170\n",
            "iteration Time 21.949 (21.761)\n",
            "**********************************\n",
            "attacked module: layer2.0.downsample.0\n",
            "attacked weight index: [13 62  0  0]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [39 62  0  0]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [42 10  0  0]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [42 14  0  0]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [42 19  0  0]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [42 55  0  0]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [42 60  0  0]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [42 62  0  0]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [43 10  0  0]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [43 62  0  0]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [45 19  0  0]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [45 60  0  0]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [45 62  0  0]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [77 62  0  0]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "Iteration: [027/050]   Attack Time 98.409 (58.992)  [2022-11-15 07:44:16]\n",
            "loss before attack: 0.6607\n",
            "loss after attack: 0.6650\n",
            "bit flips: 230\n",
            "hamming_dist: 58\n",
            "  **Test** Prec@1 57.700 Prec@5 95.260 Error@1 42.300\n",
            "iteration Time 20.895 (21.729)\n",
            "**********************************\n",
            "attacked module: layer2.0.downsample.0\n",
            "attacked weight index: [13 62  0  0]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [39 62  0  0]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [42 10  0  0]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [42 19  0  0]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [42 55  0  0]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [42 60  0  0]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [42 62  0  0]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [43 10  0  0]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [43 62  0  0]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [45 10  0  0]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [45 19  0  0]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [45 60  0  0]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [45 62  0  0]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [77 62  0  0]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "Iteration: [028/050]   Attack Time 94.531 (60.261)  [2022-11-15 07:46:12]\n",
            "loss before attack: 0.6650\n",
            "loss after attack: 0.6735\n",
            "bit flips: 244\n",
            "hamming_dist: 64\n",
            "  **Test** Prec@1 49.950 Prec@5 93.280 Error@1 50.050\n",
            "iteration Time 21.717 (21.728)\n",
            "**********************************\n",
            "attacked module: fc\n",
            "attacked weight index: [  2 102]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [  2 142]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [  2 288]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [  2 292]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [  2 368]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [  2 443]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [  9 443]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "Iteration: [029/050]   Attack Time 48.261 (59.848)  [2022-11-15 07:47:22]\n",
            "loss before attack: 0.6735\n",
            "loss after attack: 0.6775\n",
            "bit flips: 251\n",
            "hamming_dist: 71\n",
            "  **Test** Prec@1 52.960 Prec@5 93.370 Error@1 47.040\n",
            "iteration Time 22.128 (21.742)\n",
            "**********************************\n",
            "attacked module: fc\n",
            "attacked weight index: [  2 220]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [  2 262]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [  2 284]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [  2 288]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [  2 368]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [  2 443]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [  6 220]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [  6 262]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [  6 284]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "Iteration: [030/050]   Attack Time 65.397 (60.033)  [2022-11-15 07:48:49]\n",
            "loss before attack: 0.6775\n",
            "loss after attack: 0.6846\n",
            "bit flips: 260\n",
            "hamming_dist: 68\n",
            "  **Test** Prec@1 47.650 Prec@5 93.510 Error@1 52.350\n",
            "iteration Time 22.188 (21.757)\n",
            "**********************************\n",
            "attacked module: fc\n",
            "attacked weight index: [ 2 78]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [  2 204]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [  2 208]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [  2 220]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [  2 262]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [  2 284]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [  2 288]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [  2 443]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [  6 220]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "Iteration: [031/050]   Attack Time 61.436 (60.078)  [2022-11-15 07:50:13]\n",
            "loss before attack: 0.6846\n",
            "loss after attack: 0.6920\n",
            "bit flips: 269\n",
            "hamming_dist: 75\n",
            "  **Test** Prec@1 54.030 Prec@5 93.400 Error@1 45.970\n",
            "iteration Time 21.960 (21.763)\n",
            "**********************************\n",
            "attacked module: layer2.0.downsample.0\n",
            "attacked weight index: [39 62  0  0]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [42 10  0  0]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [42 19  0  0]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [42 62  0  0]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [43 62  0  0]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [45 10  0  0]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [45 19  0  0]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [45 62  0  0]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [77 62  0  0]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "Iteration: [032/050]   Attack Time 61.554 (60.124)  [2022-11-15 07:51:36]\n",
            "loss before attack: 0.6920\n",
            "loss after attack: 0.7018\n",
            "bit flips: 278\n",
            "hamming_dist: 70\n",
            "  **Test** Prec@1 57.550 Prec@5 95.380 Error@1 42.450\n",
            "iteration Time 22.061 (21.773)\n",
            "**********************************\n",
            "attacked module: layer2.0.downsample.0\n",
            "attacked weight index: [39 62  0  0]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [42 10  0  0]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [42 14  0  0]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [42 16  0  0]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [42 19  0  0]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [42 41  0  0]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [42 62  0  0]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [43 55  0  0]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [43 62  0  0]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [45 19  0  0]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [45 62  0  0]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "Iteration: [033/050]   Attack Time 78.836 (60.691)  [2022-11-15 07:53:17]\n",
            "loss before attack: 0.7018\n",
            "loss after attack: 0.7233\n",
            "bit flips: 289\n",
            "hamming_dist: 77\n",
            "  **Test** Prec@1 51.450 Prec@5 93.050 Error@1 48.550\n",
            "iteration Time 21.918 (21.777)\n",
            "**********************************\n",
            "attacked module: layer2.0.downsample.0\n",
            "attacked weight index: [13 62  0  0]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [42 10  0  0]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [42 14  0  0]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [42 19  0  0]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [42 26  0  0]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [42 41  0  0]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [42 55  0  0]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [42 60  0  0]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [42 62  0  0]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [43 10  0  0]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [43 62  0  0]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [45 62  0  0]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "Iteration: [034/050]   Attack Time 81.566 (61.305)  [2022-11-15 07:55:01]\n",
            "loss before attack: 0.7233\n",
            "loss after attack: 0.7356\n",
            "bit flips: 301\n",
            "hamming_dist: 71\n",
            "  **Test** Prec@1 58.170 Prec@5 95.660 Error@1 41.830\n",
            "iteration Time 21.859 (21.780)\n",
            "**********************************\n",
            "attacked module: conv1\n",
            "attacked weight index: [62  1  0  4]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [62  1  0  5]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [62  1  1  4]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [62  1  1  5]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [62  1  1  6]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [62  1  2  5]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [62  1  2  6]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [62  1  3  3]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [62  1  4  4]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [62  1  5  4]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [62  2  1  5]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [62  2  2  4]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [62  2  2  5]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [62  2  2  6]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "Iteration: [035/050]   Attack Time 94.080 (62.241)  [2022-11-15 07:56:57]\n",
            "loss before attack: 0.7356\n",
            "loss after attack: 0.7443\n",
            "bit flips: 315\n",
            "hamming_dist: 75\n",
            "  **Test** Prec@1 61.760 Prec@5 95.760 Error@1 38.240\n",
            "iteration Time 26.056 (21.902)\n",
            "**********************************\n",
            "attacked module: conv1\n",
            "attacked weight index: [62  1  1  2]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [62  1  1  3]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [62  1  1  4]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [62  1  1  5]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [62  1  1  6]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [62  1  2  4]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [62  1  2  6]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [62  1  3  4]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [62  1  4  4]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [62  1  4  5]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [62  2  1  5]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [62  2  2  3]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [62  2  2  4]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [62  2  2  5]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [62  2  2  6]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "Iteration: [036/050]   Attack Time 101.155 (63.322)  [2022-11-15 07:59:04]\n",
            "loss before attack: 0.7443\n",
            "loss after attack: 0.7505\n",
            "bit flips: 330\n",
            "hamming_dist: 78\n",
            "  **Test** Prec@1 56.980 Prec@5 95.430 Error@1 43.020\n",
            "iteration Time 21.819 (21.899)\n",
            "**********************************\n",
            "attacked module: conv1\n",
            "attacked weight index: [62  1  1  3]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [62  1  1  4]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [62  1  1  5]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [62  1  1  6]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [62  1  2  2]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [62  1  2  4]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [62  1  2  6]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [62  1  3  4]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [62  1  4  5]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [62  1  5  5]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [62  1  6  5]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [62  2  1  5]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [62  2  1  6]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [62  2  2  3]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [62  2  2  4]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [62  2  2  5]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "Iteration: [037/050]   Attack Time 107.087 (64.505)  [2022-11-15 08:01:13]\n",
            "loss before attack: 0.7505\n",
            "loss after attack: 0.7638\n",
            "bit flips: 346\n",
            "hamming_dist: 78\n",
            "  **Test** Prec@1 61.720 Prec@5 95.740 Error@1 38.280\n",
            "iteration Time 24.866 (21.980)\n",
            "**********************************\n",
            "attacked module: layer1.0.conv1\n",
            "attacked weight index: [22 10  2  0]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [22 10  2  1]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [22 10  2  2]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [22 11  0  0]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [22 11  0  1]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [22 11  0  2]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [22 41  0  1]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [22 55  0  1]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [22 55  0  2]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [22 62  0  0]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [22 62  0  1]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [22 62  0  2]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [22 62  1  1]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [22 62  1  2]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [28 10  1  0]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [28 62  0  1]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "Iteration: [038/050]   Attack Time 109.167 (65.681)  [2022-11-15 08:03:27]\n",
            "loss before attack: 0.7638\n",
            "loss after attack: 0.7655\n",
            "bit flips: 362\n",
            "hamming_dist: 88\n",
            "  **Test** Prec@1 61.230 Prec@5 96.150 Error@1 38.770\n",
            "iteration Time 21.085 (21.956)\n",
            "**********************************\n",
            "attacked module: conv1\n",
            "attacked weight index: [62  1  1  3]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [62  1  1  4]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [62  1  1  5]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [62  1  1  6]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [62  1  2  2]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [62  1  2  3]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [62  1  2  4]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [62  1  2  5]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [62  1  2  6]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [62  1  3  4]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [62  1  3  5]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [62  1  4  5]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [62  1  5  5]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [62  2  1  5]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "Iteration: [039/050]   Attack Time 94.363 (66.416)  [2022-11-15 08:05:22]\n",
            "loss before attack: 0.7655\n",
            "loss after attack: 0.7674\n",
            "bit flips: 376\n",
            "hamming_dist: 90\n",
            "  **Test** Prec@1 56.850 Prec@5 95.580 Error@1 43.150\n",
            "iteration Time 21.833 (21.953)\n",
            "**********************************\n",
            "attacked module: layer1.0.conv1\n",
            "attacked weight index: [27 62  0  1]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [27 62  0  2]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [27 62  1  0]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [27 62  1  1]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [27 62  1  2]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [27 62  2  1]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [27 62  2  2]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [28 62  0  1]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [28 62  1  1]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [28 62  2  0]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [28 62  2  1]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [28 62  2  2]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "Iteration: [040/050]   Attack Time 87.076 (66.933)  [2022-11-15 08:07:11]\n",
            "loss before attack: 0.7674\n",
            "loss after attack: 0.7731\n",
            "bit flips: 388\n",
            "hamming_dist: 102\n",
            "  **Test** Prec@1 59.290 Prec@5 95.350 Error@1 40.710\n",
            "iteration Time 23.827 (22.000)\n",
            "**********************************\n",
            "attacked module: conv1\n",
            "attacked weight index: [37  0  5  0]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [37  0  5  6]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [37  0  6  0]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [37  1  5  6]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [37  2  5  0]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [37  2  5  6]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [59  2  5  4]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [59  2  6  4]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "Iteration: [041/050]   Attack Time 59.035 (66.740)  [2022-11-15 08:08:34]\n",
            "loss before attack: 0.7731\n",
            "loss after attack: 0.7802\n",
            "bit flips: 396\n",
            "hamming_dist: 110\n",
            "  **Test** Prec@1 58.080 Prec@5 95.050 Error@1 41.920\n",
            "iteration Time 23.841 (22.045)\n",
            "**********************************\n",
            "attacked module: conv1\n",
            "attacked weight index: [59  0  4  2]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [59  0  4  3]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [59  1  2  2]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [59  1  3  2]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [59  1  4  2]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [59  1  4  3]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "Iteration: [042/050]   Attack Time 44.604 (66.213)  [2022-11-15 08:09:43]\n",
            "loss before attack: 0.7802\n",
            "loss after attack: 0.7871\n",
            "bit flips: 402\n",
            "hamming_dist: 116\n",
            "  **Test** Prec@1 58.660 Prec@5 95.190 Error@1 41.340\n",
            "iteration Time 24.093 (22.093)\n",
            "**********************************\n",
            "attacked module: conv1\n",
            "attacked weight index: [59  0  4  2]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [59  0  4  3]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [59  0  4  4]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [59  1  4  1]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [59  1  4  2]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [59  1  4  3]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [59  1  4  4]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "Iteration: [043/050]   Attack Time 55.574 (65.965)  [2022-11-15 08:11:02]\n",
            "loss before attack: 0.7871\n",
            "loss after attack: 0.8040\n",
            "bit flips: 409\n",
            "hamming_dist: 115\n",
            "  **Test** Prec@1 57.550 Prec@5 94.910 Error@1 42.450\n",
            "iteration Time 23.064 (22.116)\n",
            "**********************************\n",
            "attacked module: layer1.0.conv1\n",
            "attacked weight index: [28 62  0  0]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [28 62  0  1]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [28 62  1  0]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [28 62  1  1]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [28 62  1  2]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [28 62  2  0]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [28 62  2  1]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "Iteration: [044/050]   Attack Time 47.480 (65.545)  [2022-11-15 08:12:13]\n",
            "loss before attack: 0.8040\n",
            "loss after attack: 0.8093\n",
            "bit flips: 416\n",
            "hamming_dist: 112\n",
            "  **Test** Prec@1 57.080 Prec@5 95.190 Error@1 42.920\n",
            "iteration Time 21.992 (22.113)\n",
            "**********************************\n",
            "attacked module: layer1.0.conv1\n",
            "attacked weight index: [19 62  1  1]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [19 62  2  1]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [28 62  0  0]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [28 62  0  1]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [28 62  1  0]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [28 62  1  1]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [28 62  1  2]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [28 62  2  0]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [28 62  2  1]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "Iteration: [045/050]   Attack Time 60.401 (65.431)  [2022-11-15 08:13:35]\n",
            "loss before attack: 0.8093\n",
            "loss after attack: 0.8118\n",
            "bit flips: 425\n",
            "hamming_dist: 117\n",
            "  **Test** Prec@1 58.290 Prec@5 95.000 Error@1 41.710\n",
            "iteration Time 21.542 (22.100)\n",
            "**********************************\n",
            "attacked module: conv1\n",
            "attacked weight index: [59  0  4  2]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [59  0  4  3]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [59  0  4  4]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [59  0  5  3]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [59  1  4  2]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [59  1  4  3]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [59  1  4  4]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [59  1  5  3]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "Iteration: [046/050]   Attack Time 55.356 (65.212)  [2022-11-15 08:14:52]\n",
            "loss before attack: 0.8118\n",
            "loss after attack: 0.8280\n",
            "bit flips: 433\n",
            "hamming_dist: 121\n",
            "  **Test** Prec@1 58.800 Prec@5 95.250 Error@1 41.200\n",
            "iteration Time 23.577 (22.133)\n",
            "**********************************\n",
            "attacked module: conv1\n",
            "attacked weight index: [59  0  4  2]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [59  0  4  3]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [59  0  4  4]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [59  0  5  3]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [59  1  3  4]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [59  1  4  2]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [59  1  4  3]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [59  1  4  4]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [59  1  5  3]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [59  1  5  4]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "Iteration: [047/050]   Attack Time 67.022 (65.250)  [2022-11-15 08:16:23]\n",
            "loss before attack: 0.8280\n",
            "loss after attack: 0.8540\n",
            "bit flips: 443\n",
            "hamming_dist: 119\n",
            "  **Test** Prec@1 57.080 Prec@5 94.760 Error@1 42.920\n",
            "iteration Time 21.965 (22.129)\n",
            "**********************************\n",
            "attacked module: layer1.0.conv1\n",
            "attacked weight index: [28 62  0  0]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [28 62  0  1]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [28 62  0  2]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [28 62  1  0]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [28 62  1  1]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [28 62  1  2]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [28 62  2  0]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [28 62  2  1]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [28 62  2  2]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "Iteration: [048/050]   Attack Time 60.525 (65.152)  [2022-11-15 08:17:45]\n",
            "loss before attack: 0.8540\n",
            "loss after attack: 0.8556\n",
            "bit flips: 452\n",
            "hamming_dist: 114\n",
            "  **Test** Prec@1 56.330 Prec@5 94.980 Error@1 43.670\n",
            "iteration Time 22.231 (22.131)\n",
            "**********************************\n",
            "attacked module: layer1.0.conv1\n",
            "attacked weight index: [ 1 62  0  0]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [ 1 62  1  0]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [ 1 62  1  1]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [ 1 62  2  0]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [ 1 62  2  1]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [27 62  0  0]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [27 62  2  0]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [28 62  0  0]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [28 62  0  1]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [28 62  1  0]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [28 62  1  1]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [28 62  2  1]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "Iteration: [049/050]   Attack Time 84.272 (65.542)  [2022-11-15 08:19:32]\n",
            "loss before attack: 0.8556\n",
            "loss after attack: 0.8600\n",
            "bit flips: 464\n",
            "hamming_dist: 122\n",
            "  **Test** Prec@1 56.920 Prec@5 94.670 Error@1 43.080\n",
            "iteration Time 21.851 (22.125)\n",
            "**********************************\n",
            "attacked module: conv1\n",
            "attacked weight index: [59  0  4  2]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [59  0  4  3]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [59  0  4  4]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [59  0  4  6]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [59  0  5  2]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [59  0  5  3]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [59  0  6  3]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [59  1  4  2]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [59  1  4  3]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [59  1  4  4]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [59  1  5  3]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [59  1  5  4]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "Iteration: [050/050]   Attack Time 79.665 (65.825)  [2022-11-15 08:21:13]\n",
            "loss before attack: 0.8600\n",
            "loss after attack: 0.8856\n",
            "bit flips: 476\n",
            "hamming_dist: 128\n",
            "  **Test** Prec@1 58.300 Prec@5 95.300 Error@1 41.700\n",
            "iteration Time 21.722 (22.117)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2. Piecewise Weight Clustering (PC)**"
      ],
      "metadata": {
        "id": "8vmGVd2q61Z_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**return to first quantization.py file from models folder**"
      ],
      "metadata": {
        "id": "5GcXFf2WZ7-i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "for 2 epoches"
      ],
      "metadata": {
        "id": "nuecmOHmBL_d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!bash train_CIFAR.sh"
      ],
      "metadata": {
        "id": "5QtuPkGKRbQs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1a6146e-7ffb-4e17-8346-d00c4da49148"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current host is: alpha\n",
            "mkdir: cannot create directory ‘save’: File exists\n",
            "mkdir: cannot create directory ‘2022-11-15’: File exists\n",
            "save path : ./save/2022-11-15/cifar10_resnet18_quan_2_SGD_binarized\n",
            "{'arch': 'resnet18_quan', 'attack_sample_size': 128, 'clustering': False, 'data_path': '/content/data/cifar-10-batches-py', 'dataset': 'cifar10', 'decay': 0.0003, 'enable_bfa': False, 'epochs': 2, 'evaluate': False, 'fine_tune': False, 'gammas': [0.1, 0.1], 'gpu_id': 1, 'k_top': None, 'lambda_coeff': 0.001, 'learning_rate': 0.1, 'manualSeed': 1306, 'model_only': False, 'momentum': 0.9, 'n_iter': 20, 'ngpu': 1, 'optimizer': 'SGD', 'print_freq': 100, 'quan_bitwidth': None, 'random_bfa': False, 'reset_weight': False, 'resume': '', 'save_path': './save/2022-11-15/cifar10_resnet18_quan_2_SGD_binarized', 'schedule': [80, 120], 'start_epoch': 0, 'test_batch_size': 128, 'use_cuda': False, 'workers': 4}\n",
            "Random Seed: 1306\n",
            "python version : 3.7.15 (default, Nov  7 2022, 22:00:21)  [GCC 11.2.0]\n",
            "torch  version : 1.1.0\n",
            "cudnn  version : 7501\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "=> creating model 'resnet18_quan'\n",
            "=> network :\n",
            " ResNet(\n",
            "  (conv1): quan_Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace)\n",
            "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (layer1): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): quan_Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace)\n",
            "      (conv2): quan_Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): quan_Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace)\n",
            "      (conv2): quan_Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): quan_Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace)\n",
            "      (conv2): quan_Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): quan_Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): quan_Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace)\n",
            "      (conv2): quan_Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): quan_Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace)\n",
            "      (conv2): quan_Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): quan_Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): quan_Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace)\n",
            "      (conv2): quan_Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): quan_Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace)\n",
            "      (conv2): quan_Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): quan_Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): quan_Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace)\n",
            "      (conv2): quan_Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (fc): quan_Linear(in_features=512, out_features=1000, bias=True)\n",
            ")\n",
            "using SGD as optimizer\n",
            "=> do not use any checkpoint for resnet18_quan model\n",
            "\n",
            "==>>[2022-11-15 08:31:29] [Epoch=000/002] [Need: 00:00:00] [LR=0.1000][M=0.90] [Best : Accuracy=0.00, Error=100.00]\n",
            "  Epoch: [000][000/391]   Time 1.744 (1.744)   Data 0.111 (0.111)   Loss 9.1288 (9.1288)   Prec@1 0.000 (0.000)   Prec@5 0.000 (0.000)   [2022-11-15 08:31:30]\n",
            "  Epoch: [000][100/391]   Time 1.396 (1.440)   Data 0.002 (0.003)   Loss 2.0699 (2.4490)   Prec@1 28.125 (19.554)   Prec@5 89.062 (73.639)   [2022-11-15 08:33:54]\n",
            "  Epoch: [000][200/391]   Time 1.381 (1.414)   Data 0.002 (0.002)   Loss 1.6565 (2.1841)   Prec@1 37.500 (24.565)   Prec@5 92.969 (79.108)   [2022-11-15 08:36:13]\n",
            "  Epoch: [000][300/391]   Time 1.360 (1.416)   Data 0.002 (0.002)   Loss 1.8058 (2.0704)   Prec@1 32.812 (27.476)   Prec@5 85.156 (81.499)   [2022-11-15 08:38:35]\n",
            "  **Train** Prec@1 29.600 Prec@5 83.044 Error@1 70.400\n",
            "  **Test** Prec@1 38.240 Prec@5 88.210 Error@1 61.760\n",
            "---- save figure the accuracy/loss curve of train/val into ./save/2022-11-15/cifar10_resnet18_quan_2_SGD_binarized/curve.png\n",
            "total weight changes: 0\n",
            "\n",
            "==>>[2022-11-15 08:41:11] [Epoch=001/002] [Need: 00:09:37] [LR=0.1000][M=0.90] [Best : Accuracy=38.24, Error=61.76]\n",
            "  Epoch: [001][000/391]   Time 2.651 (2.651)   Data 0.277 (0.277)   Loss 1.8269 (1.8269)   Prec@1 35.938 (35.938)   Prec@5 86.719 (86.719)   [2022-11-15 08:41:14]\n",
            "  Epoch: [001][100/391]   Time 1.384 (1.402)   Data 0.002 (0.005)   Loss 1.6173 (1.6699)   Prec@1 39.062 (39.828)   Prec@5 89.844 (89.078)   [2022-11-15 08:43:32]\n",
            "  Epoch: [001][200/391]   Time 1.410 (1.415)   Data 0.002 (0.003)   Loss 1.6461 (1.6455)   Prec@1 40.625 (40.333)   Prec@5 89.062 (89.603)   [2022-11-15 08:45:55]\n",
            "  Epoch: [001][300/391]   Time 1.408 (1.407)   Data 0.002 (0.003)   Loss 1.5907 (1.6170)   Prec@1 41.406 (41.069)   Prec@5 91.406 (89.935)   [2022-11-15 08:48:14]\n",
            "  **Train** Prec@1 42.194 Prec@5 90.332 Error@1 57.806\n",
            "  **Test** Prec@1 48.800 Prec@5 93.080 Error@1 51.200\n",
            "=> Obtain best accuracy, and update the best model\n",
            "---- save figure the accuracy/loss curve of train/val into ./save/2022-11-15/cifar10_resnet18_quan_2_SGD_binarized/curve.png\n",
            "total weight changes: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!bash BFA_CIFAR.sh"
      ],
      "metadata": {
        "id": "uaeEnwVNWV5i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85b3cb5a-1be7-4af6-9d36-cf1cb10a7909"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current host is: alpha\n",
            "mkdir: cannot create directory ‘save’: File exists\n",
            "mkdir: cannot create directory ‘2022-11-15’: File exists\n",
            "save path : ./save/2022-11-15/cifar10_resnet18_quan_BFA_defense_test_binarized\n",
            "{'arch': 'resnet18_quan', 'attack_sample_size': 128, 'clustering': False, 'data_path': '/content/data/cifar-10-batches-py', 'dataset': 'cifar10', 'decay': 0.0001, 'enable_bfa': True, 'epochs': 200, 'evaluate': True, 'fine_tune': True, 'gammas': [0.1, 0.1], 'gpu_id': 1, 'k_top': None, 'lambda_coeff': 0.001, 'learning_rate': 0.001, 'manualSeed': 9348, 'model_only': False, 'momentum': 0.9, 'n_iter': 10, 'ngpu': 1, 'optimizer': 'SGD', 'print_freq': 50, 'quan_bitwidth': None, 'random_bfa': False, 'reset_weight': True, 'resume': '/content/BFA/save/2022-11-15/cifar10_resnet18_quan_2_SGD_binarized/checkpoint.pth.tar', 'save_path': './save/2022-11-15/cifar10_resnet18_quan_BFA_defense_test_binarized', 'schedule': [80, 120], 'start_epoch': 0, 'test_batch_size': 128, 'use_cuda': False, 'workers': 8}\n",
            "Random Seed: 9348\n",
            "python version : 3.7.15 (default, Nov  7 2022, 22:00:21)  [GCC 11.2.0]\n",
            "torch  version : 1.1.0\n",
            "cudnn  version : 7501\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "=> creating model 'resnet18_quan'\n",
            "=> network :\n",
            " ResNet(\n",
            "  (conv1): quan_Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace)\n",
            "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (layer1): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): quan_Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace)\n",
            "      (conv2): quan_Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): quan_Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace)\n",
            "      (conv2): quan_Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): quan_Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace)\n",
            "      (conv2): quan_Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): quan_Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): quan_Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace)\n",
            "      (conv2): quan_Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): quan_Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace)\n",
            "      (conv2): quan_Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): quan_Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): quan_Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace)\n",
            "      (conv2): quan_Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): quan_Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace)\n",
            "      (conv2): quan_Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): quan_Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): quan_Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace)\n",
            "      (conv2): quan_Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (fc): quan_Linear(in_features=512, out_features=1000, bias=True)\n",
            ")\n",
            "using SGD as optimizer\n",
            "=> loading checkpoint '/content/BFA/save/2022-11-15/cifar10_resnet18_quan_2_SGD_binarized/checkpoint.pth.tar'\n",
            "=> loaded checkpoint '/content/BFA/save/2022-11-15/cifar10_resnet18_quan_2_SGD_binarized/checkpoint.pth.tar' (epoch 0)\n",
            "  **Test** Prec@1 48.800 Prec@5 93.080 Error@1 51.200\n",
            "k_top is set to None\n",
            "Attack sample size is 128\n",
            "**********************************\n",
            "attacked module: layer1.0.conv1\n",
            "attacked weight index: [11 19  0  1]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [11 19  0  2]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [11 51  0  0]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [11 51  0  1]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [11 51  0  2]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "Iteration: [001/010]   Attack Time 34.654 (34.654)  [2022-11-15 08:51:53]\n",
            "loss before attack: 0.7264\n",
            "loss after attack: 0.7318\n",
            "bit flips: 5\n",
            "hamming_dist: 5\n",
            "  **Test** Prec@1 48.080 Prec@5 92.730 Error@1 51.920\n",
            "iteration Time 21.216 (21.216)\n",
            "**********************************\n",
            "attacked module: layer2.0.downsample.0\n",
            "attacked weight index: [54 51  0  0]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [75 51  0  0]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [121   8   0   0]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [121  11   0   0]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [121  35   0   0]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "Iteration: [002/010]   Attack Time 35.251 (34.953)  [2022-11-15 08:52:50]\n",
            "loss before attack: 0.7318\n",
            "loss after attack: 0.7334\n",
            "bit flips: 10\n",
            "hamming_dist: 10\n",
            "  **Test** Prec@1 45.540 Prec@5 92.820 Error@1 54.460\n",
            "iteration Time 21.594 (21.405)\n",
            "**********************************\n",
            "attacked module: layer1.1.conv1\n",
            "attacked weight index: [12 51  1  0]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [12 51  1  1]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [12 51  2  0]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [12 51  2  1]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "Iteration: [003/010]   Attack Time 27.894 (32.600)  [2022-11-15 08:53:39]\n",
            "loss before attack: 0.7334\n",
            "loss after attack: 0.7345\n",
            "bit flips: 14\n",
            "hamming_dist: 14\n",
            "  **Test** Prec@1 45.830 Prec@5 92.570 Error@1 54.170\n",
            "iteration Time 23.863 (22.224)\n",
            "**********************************\n",
            "attacked module: layer2.0.downsample.0\n",
            "attacked weight index: [106  25   0   0]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [106  51   0   0]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "Iteration: [004/010]   Attack Time 17.461 (28.815)  [2022-11-15 08:54:21]\n",
            "loss before attack: 0.7345\n",
            "loss after attack: 0.7373\n",
            "bit flips: 16\n",
            "hamming_dist: 16\n",
            "  **Test** Prec@1 47.070 Prec@5 92.820 Error@1 52.930\n",
            "iteration Time 22.410 (22.271)\n",
            "**********************************\n",
            "attacked module: layer2.0.downsample.0\n",
            "attacked weight index: [106   8   0   0]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [106  51   0   0]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "Iteration: [005/010]   Attack Time 14.364 (25.925)  [2022-11-15 08:54:57]\n",
            "loss before attack: 0.7373\n",
            "loss after attack: 0.7377\n",
            "bit flips: 18\n",
            "hamming_dist: 16\n",
            "  **Test** Prec@1 45.630 Prec@5 92.570 Error@1 54.370\n",
            "iteration Time 21.394 (22.095)\n",
            "**********************************\n",
            "attacked module: layer2.0.downsample.0\n",
            "attacked weight index: [106   8   0   0]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [106  28   0   0]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [106  51   0   0]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "Iteration: [006/010]   Attack Time 21.473 (25.183)  [2022-11-15 08:55:40]\n",
            "loss before attack: 0.7377\n",
            "loss after attack: 0.7593\n",
            "bit flips: 21\n",
            "hamming_dist: 17\n",
            "  **Test** Prec@1 47.440 Prec@5 92.720 Error@1 52.560\n",
            "iteration Time 21.431 (21.985)\n",
            "**********************************\n",
            "attacked module: layer2.0.downsample.0\n",
            "attacked weight index: [106   8   0   0]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [106  25   0   0]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [106  28   0   0]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [106  34   0   0]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [106  51   0   0]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "Iteration: [007/010]   Attack Time 34.559 (26.522)  [2022-11-15 08:56:36]\n",
            "loss before attack: 0.7593\n",
            "loss after attack: 0.7763\n",
            "bit flips: 26\n",
            "hamming_dist: 16\n",
            "  **Test** Prec@1 44.490 Prec@5 91.900 Error@1 55.510\n",
            "iteration Time 21.165 (21.868)\n",
            "**********************************\n",
            "attacked module: conv1\n",
            "attacked weight index: [51  1  6  6]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [51  2  5  6]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [51  2  6  5]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [51  2  6  6]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "Iteration: [008/010]   Attack Time 27.989 (26.706)  [2022-11-15 08:57:25]\n",
            "loss before attack: 0.7763\n",
            "loss after attack: 0.7832\n",
            "bit flips: 30\n",
            "hamming_dist: 20\n",
            "  **Test** Prec@1 44.320 Prec@5 91.840 Error@1 55.680\n",
            "iteration Time 21.117 (21.774)\n",
            "**********************************\n",
            "attacked module: conv1\n",
            "attacked weight index: [51  0  5  1]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [51  0  5  2]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [51  1  5  1]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [51  1  5  2]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [51  1  6  1]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [51  2  5  1]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [51  2  5  2]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "Iteration: [009/010]   Attack Time 51.880 (29.503)  [2022-11-15 08:58:38]\n",
            "loss before attack: 0.7832\n",
            "loss after attack: 0.7968\n",
            "bit flips: 37\n",
            "hamming_dist: 27\n",
            "  **Test** Prec@1 45.180 Prec@5 92.030 Error@1 54.820\n",
            "iteration Time 20.817 (21.668)\n",
            "**********************************\n",
            "attacked module: layer2.0.downsample.0\n",
            "attacked weight index: [29 11  0  0]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [89  8  0  0]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [89 51  0  0]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [89 60  0  0]\n",
            "weight before attack: -1.0\n",
            "weight after attack: 1.0\n",
            "attacked weight index: [106  25   0   0]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "attacked weight index: [106  51   0   0]\n",
            "weight before attack: 1.0\n",
            "weight after attack: -1.0\n",
            "Iteration: [010/010]   Attack Time 41.063 (30.659)  [2022-11-15 08:59:40]\n",
            "loss before attack: 0.7968\n",
            "loss after attack: 0.8034\n",
            "bit flips: 43\n",
            "hamming_dist: 33\n",
            "  **Test** Prec@1 47.060 Prec@5 92.370 Error@1 52.940\n",
            "iteration Time 21.142 (21.615)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!bash eval_CIFAR.sh"
      ],
      "metadata": {
        "id": "qq2IwAprWWru",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4789178c-eb90-4313-aac5-f778700e4ee2"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current host is: alpha\n",
            "mkdir: cannot create directory ‘save’: File exists\n",
            "mkdir: cannot create directory ‘2022-11-15’: File exists\n",
            "save path : ./save/2022-11-15/cifar10_resnet18_quan_new_exp\n",
            "{'arch': 'resnet18_quan', 'attack_sample_size': 128, 'clustering': False, 'data_path': '/content/data/cifar-10-batches-py', 'dataset': 'cifar10', 'decay': 0.0003, 'enable_bfa': False, 'epochs': 2, 'evaluate': True, 'fine_tune': True, 'gammas': [0.1, 0.1], 'gpu_id': 1, 'k_top': None, 'lambda_coeff': 0.001, 'learning_rate': 0.1, 'manualSeed': 5191, 'model_only': False, 'momentum': 0.9, 'n_iter': 20, 'ngpu': 1, 'optimizer': 'SGD', 'print_freq': 100, 'quan_bitwidth': None, 'random_bfa': False, 'reset_weight': False, 'resume': '/content/BFA/save/2022-11-15/cifar10_resnet18_quan_2_SGD_binarized/checkpoint.pth.tar', 'save_path': './save/2022-11-15/cifar10_resnet18_quan_new_exp', 'schedule': [80, 120], 'start_epoch': 0, 'test_batch_size': 100, 'use_cuda': False, 'workers': 4}\n",
            "Random Seed: 5191\n",
            "python version : 3.7.15 (default, Nov  7 2022, 22:00:21)  [GCC 11.2.0]\n",
            "torch  version : 1.1.0\n",
            "cudnn  version : 7501\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "=> creating model 'resnet18_quan'\n",
            "=> network :\n",
            " ResNet(\n",
            "  (conv1): quan_Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace)\n",
            "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (layer1): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): quan_Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace)\n",
            "      (conv2): quan_Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): quan_Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace)\n",
            "      (conv2): quan_Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): quan_Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace)\n",
            "      (conv2): quan_Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): quan_Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): quan_Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace)\n",
            "      (conv2): quan_Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): quan_Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace)\n",
            "      (conv2): quan_Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): quan_Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): quan_Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace)\n",
            "      (conv2): quan_Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): quan_Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace)\n",
            "      (conv2): quan_Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): quan_Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): quan_Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace)\n",
            "      (conv2): quan_Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (fc): quan_Linear(in_features=512, out_features=1000, bias=True)\n",
            ")\n",
            "using SGD as optimizer\n",
            "=> loading checkpoint '/content/BFA/save/2022-11-15/cifar10_resnet18_quan_2_SGD_binarized/checkpoint.pth.tar'\n",
            "=> loaded checkpoint '/content/BFA/save/2022-11-15/cifar10_resnet18_quan_2_SGD_binarized/checkpoint.pth.tar' (epoch 0)\n",
            "  **Test** Prec@1 48.800 Prec@5 93.080 Error@1 51.200\n",
            "eval_CIFAR.sh: line 58: --reset_weight: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Results"
      ],
      "metadata": {
        "id": "WNw5EXrLgthy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **BFA vs Random**"
      ],
      "metadata": {
        "id": "vIOxEL_1m363"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline  \n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "\n",
        "plt.subplots_adjust(hspace=0.5)\n",
        "plt.rcParams.update({'font.size': 13})"
      ],
      "metadata": {
        "id": "96NOo0O7g0fP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "498d6fdb-6887-4c13-f493-5e2ea0a63a7c"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "csv_path1 = '/content/BFA/save/2022-11-15/cifar10_resnet18_quan_BFA/attack_profile_3884.csv'\n",
        "csv_path2 = '/content/BFA/save/2022-11-15/cifar10_resnet18_quan_BFA/attack_profile_6741.csv'\n",
        "\n",
        "df1 = pd.read_csv(csv_path1, index_col=False)\n",
        "df2 = pd.read_csv(csv_path2, index_col=False)"
      ],
      "metadata": {
        "id": "rGr4hRdGg6QP"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**BFA**"
      ],
      "metadata": {
        "id": "taiQh8SWjrEW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(df1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pH-4dqZGjk2-",
        "outputId": "7337ccf5-e5dd-4ea5-93e5-3cb09e97226d"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   module idx  bit-flip idx            module name         weight idx  \\\n",
            "0          26             1  layer2.0.downsample.0  [114  50   0   0]   \n",
            "\n",
            "   weight before attack  weight after attack  validation accuracy  \\\n",
            "0                  -0.0               -128.0                 0.01   \n",
            "\n",
            "   accuracy drop  trial seed  \n",
            "0           0.01        3884  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Random BFA**"
      ],
      "metadata": {
        "id": "EHpIAGY6ju6f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(df2)"
      ],
      "metadata": {
        "id": "xtzNpE7Yg-pO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29d2e678-e4ce-40a0-c59f-9546083c2698"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   module idx  bit-flip idx module name  weight idx weight before attack  \\\n",
            "0  module_idx             1        loss      235465          tensor(-3.)   \n",
            "\n",
            "  weight after attack  validation accuracy  accuracy drop  trial seed  \n",
            "0         tensor(-3.)                 0.02            0.0        6741  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# fig, ax = plt.subplots(figsize=(6,2))\n",
        "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(8,3))\n",
        "\n",
        "sns.lineplot(x='bit-flip idx', y='validation accuracy', data=df1, label='Random Bit-Flip',color=\"black\", ax=ax[0])\n",
        "\n",
        "plt.grid(True, 'major', 'y', ls='--', lw=0.8, c='k', alpha=.3)\n",
        "plt.ylabel('')\n",
        "plt.xlabel('number of bit-flips')\n",
        "\n",
        "sns.lineplot(x='bit-flip idx', y='validation accuracy', data=df2, label='Bit-Flip Attack', color=\"red\", ax=ax[1])\n",
        "\n",
        "for ax_i in ax.flat:\n",
        "    ax_i.grid(True, 'major', 'y', ls='--', lw=0.8, c='k', alpha=.3)\n",
        "\n",
        "\n",
        "ax[0].set(xlabel='Number of bit-flips', ylabel='Validation accuracy (%)')\n",
        "ax[1].set(xlabel='Number of bit-flips', ylabel='')\n",
        "ax[1].set_xticks([0,1,2])\n",
        "\n",
        "# plt.grid(True, 'major', 'y', ls='--', lw=0.8, c='k', alpha=.3)\n",
        "# plt.ylabel('')\n",
        "# plt.xlabel('number of bit-flips')\n",
        "\n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "tBMF3RZohCN6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "c0f88169-df2d-42cd-d251-af1a4649640c"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.axis.XTick at 0x7ff10b68ea90>,\n",
              " <matplotlib.axis.XTick at 0x7ff10b68e690>,\n",
              " <matplotlib.axis.XTick at 0x7ff10b68efd0>]"
            ]
          },
          "metadata": {},
          "execution_count": 42
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x216 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **observation**"
      ],
      "metadata": {
        "id": "M4r65VwenUS0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "csv_dir = '/content/BFA/save/2022-11-15/cifar10_resnet18_quan_BFA'\n",
        "\n",
        "csv_file_list = [file for file in os.listdir(\n",
        "    csv_dir) if file.endswith('.csv')\n",
        "]\n",
        "\n",
        "# print(csv_file_list)\n",
        "\n",
        "csv_dict = {}\n",
        "\n",
        "# df = pd.DataFrame()\n",
        "for file in csv_file_list:\n",
        "    csv_dict[file] = pd.read_csv(os.path.join(csv_dir, file), index_col=False)\n",
        "\n",
        "df = pd.concat([csv_dict[file] for file in csv_dict], ignore_index=True)"
      ],
      "metadata": {
        "id": "Ku7NM-p7hRU0"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "Ri8ktahKhVhL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 797
        },
        "outputId": "6866f104-c103-4352-fc0e-051798697fa7"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    module idx  bit-flip idx            module name         weight idx  \\\n",
              "0           26           1.0  layer2.0.downsample.0  [114  50   0   0]   \n",
              "1   module_idx           1.0                   loss             235465   \n",
              "2          NaN           NaN                    NaN                NaN   \n",
              "3          NaN           NaN                    NaN                NaN   \n",
              "4          NaN           NaN                    NaN                NaN   \n",
              "..         ...           ...                    ...                ...   \n",
              "77         NaN           NaN                    NaN                NaN   \n",
              "78         NaN           NaN                    NaN                NaN   \n",
              "79         NaN           NaN                    NaN                NaN   \n",
              "80         NaN           NaN                    NaN                NaN   \n",
              "81         NaN           NaN                    NaN                NaN   \n",
              "\n",
              "   weight before attack weight after attack  validation accuracy  \\\n",
              "0                  -0.0              -128.0                 0.01   \n",
              "1           tensor(-3.)         tensor(-3.)                 0.02   \n",
              "2                   NaN                 NaN                  NaN   \n",
              "3                   NaN                 NaN                  NaN   \n",
              "4                   NaN                 NaN                  NaN   \n",
              "..                  ...                 ...                  ...   \n",
              "77                  NaN                 NaN                  NaN   \n",
              "78                  NaN                 NaN                  NaN   \n",
              "79                  NaN                 NaN                  NaN   \n",
              "80                  NaN                 NaN                  NaN   \n",
              "81                  NaN                 NaN                  NaN   \n",
              "\n",
              "    accuracy drop  trial seed  \\\n",
              "0            0.01      3884.0   \n",
              "1            0.00      6741.0   \n",
              "2             NaN         NaN   \n",
              "3             NaN         NaN   \n",
              "4             NaN         NaN   \n",
              "..            ...         ...   \n",
              "77            NaN         NaN   \n",
              "78            NaN         NaN   \n",
              "79            NaN         NaN   \n",
              "80            NaN         NaN   \n",
              "81            NaN         NaN   \n",
              "\n",
              "                                         top-1 output  BFA iteration  \n",
              "0                                                 NaN            NaN  \n",
              "1                                                 NaN            NaN  \n",
              "2   [156 628 500 536 865 349 276 642  30 954 241 5...            0.0  \n",
              "3   [ 70 148 963 554 510 802  35 912  26 106 975  ...            0.0  \n",
              "4   [372 510 912 973 509 555 580 537 698   6 118 9...            0.0  \n",
              "..                                                ...            ...  \n",
              "77  [118 937 895 170 865 779 454  35 116 146 878 9...            1.0  \n",
              "78  [847 289 762 537 466 983 865 403 311 536 468 9...            1.0  \n",
              "79  [973 865  89 116 104 519 118 404 825 510 625 5...            1.0  \n",
              "80  [537 751 621 566 802 509 104 339 275 540 379 5...            1.0  \n",
              "81  [865 580 979 586 510 970 537 825 311 263 580 5...            1.0  \n",
              "\n",
              "[82 rows x 11 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2d6de0a1-a21c-4266-b1a7-b1dad6bc005d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>module idx</th>\n",
              "      <th>bit-flip idx</th>\n",
              "      <th>module name</th>\n",
              "      <th>weight idx</th>\n",
              "      <th>weight before attack</th>\n",
              "      <th>weight after attack</th>\n",
              "      <th>validation accuracy</th>\n",
              "      <th>accuracy drop</th>\n",
              "      <th>trial seed</th>\n",
              "      <th>top-1 output</th>\n",
              "      <th>BFA iteration</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>26</td>\n",
              "      <td>1.0</td>\n",
              "      <td>layer2.0.downsample.0</td>\n",
              "      <td>[114  50   0   0]</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>-128.0</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>3884.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>module_idx</td>\n",
              "      <td>1.0</td>\n",
              "      <td>loss</td>\n",
              "      <td>235465</td>\n",
              "      <td>tensor(-3.)</td>\n",
              "      <td>tensor(-3.)</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.00</td>\n",
              "      <td>6741.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[156 628 500 536 865 349 276 642  30 954 241 5...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[ 70 148 963 554 510 802  35 912  26 106 975  ...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[372 510 912 973 509 555 580 537 698   6 118 9...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[118 937 895 170 865 779 454  35 116 146 878 9...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>78</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[847 289 762 537 466 983 865 403 311 536 468 9...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[973 865  89 116 104 519 118 404 825 510 625 5...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>80</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[537 751 621 566 802 509 104 339 275 540 379 5...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>81</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[865 580 979 586 510 970 537 825 311 263 580 5...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>82 rows × 11 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2d6de0a1-a21c-4266-b1a7-b1dad6bc005d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2d6de0a1-a21c-4266-b1a7-b1dad6bc005d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2d6de0a1-a21c-4266-b1a7-b1dad6bc005d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Analyze the attack**"
      ],
      "metadata": {
        "id": "nyFmyp0UheWF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bfs = []\n",
        "for idx in set(df['trial seed'].values.flatten()):\n",
        "    bfs.append(df.loc[df['trial seed']==idx]['bit-flip idx'].max())\n",
        "bfs = np.array(bfs)\n",
        "print(\n",
        "    'bit-flips for multiple trials {} \\n \\\n",
        "mean: {} \\n std: {}'.format(bfs, bfs.mean(), bfs.std())\n",
        ")"
      ],
      "metadata": {
        "id": "4MByEBTThgaH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8cd191b8-2995-439f-e2c2-e2f26735ad54"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bit-flips for multiple trials [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            "  1. nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            " nan nan nan  1. nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            " nan nan nan nan nan nan nan nan nan nan] \n",
            " mean: nan \n",
            " std: nan\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchsummary import summary\n",
        "from models import resnet18_quan\n",
        "import torch\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "m = resnet18_quan().to(device)\n",
        "summary(m, input_size=(3, 32, 32))"
      ],
      "metadata": {
        "id": "sy7hQiOKhirU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "9cc746289f49468ea8202f4a4a660577",
            "42f18a78f8024de2a6f7f4b8d2355a19",
            "29a3a9e3229e4475a1b1a93b98762bd6",
            "fcc6dacf100842fd9c24effc700fafe8",
            "c1a7e50170074b0d992b51e38a4c4a1a",
            "a3f49f0893bc42b68b0dc97c6d407244",
            "dde9f7af6d0b4eac81286f9508ee0ff3",
            "1f4a2cbc2b7346a1b3df787343acb816",
            "6e577595f3d947f4a804e7e2fb4a74f6",
            "3ed963a4272c4f1ab7d6541dd0bc6641",
            "ccf4b1ec45f84102aeef0b2db9510664"
          ]
        },
        "outputId": "baf4e64e-0a2c-4d13-b782-60d67c8995fc"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-5c106cde.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/44.7M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9cc746289f49468ea8202f4a4a660577"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "       quan_Conv2d-1           [-1, 64, 16, 16]           9,408\n",
            "       BatchNorm2d-2           [-1, 64, 16, 16]             128\n",
            "              ReLU-3           [-1, 64, 16, 16]               0\n",
            "         MaxPool2d-4             [-1, 64, 8, 8]               0\n",
            "       quan_Conv2d-5             [-1, 64, 8, 8]          36,864\n",
            "       BatchNorm2d-6             [-1, 64, 8, 8]             128\n",
            "              ReLU-7             [-1, 64, 8, 8]               0\n",
            "       quan_Conv2d-8             [-1, 64, 8, 8]          36,864\n",
            "       BatchNorm2d-9             [-1, 64, 8, 8]             128\n",
            "             ReLU-10             [-1, 64, 8, 8]               0\n",
            "       BasicBlock-11             [-1, 64, 8, 8]               0\n",
            "      quan_Conv2d-12             [-1, 64, 8, 8]          36,864\n",
            "      BatchNorm2d-13             [-1, 64, 8, 8]             128\n",
            "             ReLU-14             [-1, 64, 8, 8]               0\n",
            "      quan_Conv2d-15             [-1, 64, 8, 8]          36,864\n",
            "      BatchNorm2d-16             [-1, 64, 8, 8]             128\n",
            "             ReLU-17             [-1, 64, 8, 8]               0\n",
            "       BasicBlock-18             [-1, 64, 8, 8]               0\n",
            "      quan_Conv2d-19            [-1, 128, 4, 4]          73,728\n",
            "      BatchNorm2d-20            [-1, 128, 4, 4]             256\n",
            "             ReLU-21            [-1, 128, 4, 4]               0\n",
            "      quan_Conv2d-22            [-1, 128, 4, 4]         147,456\n",
            "      BatchNorm2d-23            [-1, 128, 4, 4]             256\n",
            "      quan_Conv2d-24            [-1, 128, 4, 4]           8,192\n",
            "      BatchNorm2d-25            [-1, 128, 4, 4]             256\n",
            "             ReLU-26            [-1, 128, 4, 4]               0\n",
            "       BasicBlock-27            [-1, 128, 4, 4]               0\n",
            "      quan_Conv2d-28            [-1, 128, 4, 4]         147,456\n",
            "      BatchNorm2d-29            [-1, 128, 4, 4]             256\n",
            "             ReLU-30            [-1, 128, 4, 4]               0\n",
            "      quan_Conv2d-31            [-1, 128, 4, 4]         147,456\n",
            "      BatchNorm2d-32            [-1, 128, 4, 4]             256\n",
            "             ReLU-33            [-1, 128, 4, 4]               0\n",
            "       BasicBlock-34            [-1, 128, 4, 4]               0\n",
            "      quan_Conv2d-35            [-1, 256, 2, 2]         294,912\n",
            "      BatchNorm2d-36            [-1, 256, 2, 2]             512\n",
            "             ReLU-37            [-1, 256, 2, 2]               0\n",
            "      quan_Conv2d-38            [-1, 256, 2, 2]         589,824\n",
            "      BatchNorm2d-39            [-1, 256, 2, 2]             512\n",
            "      quan_Conv2d-40            [-1, 256, 2, 2]          32,768\n",
            "      BatchNorm2d-41            [-1, 256, 2, 2]             512\n",
            "             ReLU-42            [-1, 256, 2, 2]               0\n",
            "       BasicBlock-43            [-1, 256, 2, 2]               0\n",
            "      quan_Conv2d-44            [-1, 256, 2, 2]         589,824\n",
            "      BatchNorm2d-45            [-1, 256, 2, 2]             512\n",
            "             ReLU-46            [-1, 256, 2, 2]               0\n",
            "      quan_Conv2d-47            [-1, 256, 2, 2]         589,824\n",
            "      BatchNorm2d-48            [-1, 256, 2, 2]             512\n",
            "             ReLU-49            [-1, 256, 2, 2]               0\n",
            "       BasicBlock-50            [-1, 256, 2, 2]               0\n",
            "      quan_Conv2d-51            [-1, 512, 1, 1]       1,179,648\n",
            "      BatchNorm2d-52            [-1, 512, 1, 1]           1,024\n",
            "             ReLU-53            [-1, 512, 1, 1]               0\n",
            "      quan_Conv2d-54            [-1, 512, 1, 1]       2,359,296\n",
            "      BatchNorm2d-55            [-1, 512, 1, 1]           1,024\n",
            "      quan_Conv2d-56            [-1, 512, 1, 1]         131,072\n",
            "      BatchNorm2d-57            [-1, 512, 1, 1]           1,024\n",
            "             ReLU-58            [-1, 512, 1, 1]               0\n",
            "       BasicBlock-59            [-1, 512, 1, 1]               0\n",
            "      quan_Conv2d-60            [-1, 512, 1, 1]       2,359,296\n",
            "      BatchNorm2d-61            [-1, 512, 1, 1]           1,024\n",
            "             ReLU-62            [-1, 512, 1, 1]               0\n",
            "      quan_Conv2d-63            [-1, 512, 1, 1]       2,359,296\n",
            "      BatchNorm2d-64            [-1, 512, 1, 1]           1,024\n",
            "             ReLU-65            [-1, 512, 1, 1]               0\n",
            "       BasicBlock-66            [-1, 512, 1, 1]               0\n",
            "AdaptiveAvgPool2d-67            [-1, 512, 1, 1]               0\n",
            "      quan_Linear-68                 [-1, 1000]         513,000\n",
            "================================================================\n",
            "Total params: 11,689,512\n",
            "Trainable params: 11,689,512\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 1.29\n",
            "Params size (MB): 44.59\n",
            "Estimated Total Size (MB): 45.90\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Plot for Observation-1**"
      ],
      "metadata": {
        "id": "5_Urji40nsdK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# plot style\n",
        "sns.set(style=\"whitegrid\")\n",
        "sns.set(style=\"ticks\")\n",
        "# sns.despine()\n",
        "sns.set_style({\"font.sans-serif\":\"DejaVu Sans\"})\n",
        "sns.set_style({\"grid.color\":'0.9'})\n",
        "sns.set_context(\"paper\", font_scale=1.5, rc={\"lines.linewidth\": 1})"
      ],
      "metadata": {
        "id": "fDRskZvNhltM"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# f, ax = plt.subplots(figsize=(8,8))\n",
        "\n",
        "g = sns.FacetGrid(df, col=\"trial seed\", hue='module name',\n",
        "                palette = 'seismic', margin_titles=True)\n",
        "g.map(plt.scatter, \"weight before attack\", \"weight after attack\", alpha=.7, s=50)\n",
        "g.add_legend()\n",
        "\n",
        "for ax in g.axes.flat:\n",
        "    ax.plot((-127, 127), (-127, 127), c=\".1\", ls=\"--\")"
      ],
      "metadata": {
        "id": "WVQO4um2hnx3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "outputId": "f98eda9c-fd7c-4b34-9f2e-dd5856d4982d"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 635.02x216 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**solution for color bar:**"
      ],
      "metadata": {
        "id": "Ld44RyITnw1N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "g = sns.FacetGrid(df, col=\"trial seed\", palette = 'seismic')\n",
        "\n",
        "def facet_scatter(x, y, c, **kwargs):\n",
        "    \"\"\"Draw scatterplot with point colors from a faceted DataFrame columns.\"\"\"\n",
        "    kwargs.pop(\"color\")\n",
        "    plt.scatter(x, y, c=c, **kwargs)\n",
        "\n",
        "# print(df['accuracy drop'].max())\n",
        "# vmin, vmax = 0, 30\n",
        "# vmin, vmax = df['accuracy drop'].min(), df['accuracy drop'].max()\n",
        "vmin, vmax = df['validation accuracy'].min(), df['validation accuracy'].max()\n",
        "\n",
        "# cmap = sns.diverging_palette(240, 10, l=65, center=\"dark\", as_cmap=True)\n",
        "# cmap = sns.diverging_palette(220, 20, sep=20, as_cmap=True, center=\"light\")\n",
        "# cmap = sns.light_palette(\"red\", as_cmap=True)\n",
        "# cmap = sns.diverging_palette(240, 10, n=9, as_cmap=True)\n",
        "cmap = 'coolwarm'\n",
        "\n",
        "g = g.map(facet_scatter,  \"weight before attack\", \"weight after attack\", 'validation accuracy',\n",
        "          s=70, alpha=0.5, vmin=vmin, vmax=vmax, cmap=cmap)\n",
        "\n",
        "# Make space for the colorbar\n",
        "g.fig.subplots_adjust(right=.92)\n",
        "\n",
        "# Define a new Axes where the colorbar will go\n",
        "cax = g.fig.add_axes([.94, .25, .02, .6])\n",
        "\n",
        "# Get a mappable object with the same colormap as the data\n",
        "points = plt.scatter([], [], c=[], vmin=vmin, vmax=vmax, cmap=cmap)\n",
        "\n",
        "# Draw the colorbar\n",
        "g.fig.colorbar(points, cax=cax)\n",
        "\n",
        "for ax in g.axes.flat:\n",
        "    ax.plot((-127, 127), (-127, 127), c=\".1\", ls=\"--\")"
      ],
      "metadata": {
        "id": "2gb3SGqaht8R",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "outputId": "55e46837-6f69-4437-ea6a-c8409c85cdc8"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x216 with 3 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "csv_dir = '/content/BFA/save/2022-11-15/cifar10_resnet18_quan_BFA_defense_test_binarized'\n",
        "\n",
        "csv_file_list = [file for file in os.listdir(\n",
        "    csv_dir) if file.endswith('.csv')\n",
        "]\n",
        "\n",
        "# print(csv_file_list)\n",
        "\n",
        "csv_dict = {}\n",
        "\n",
        "for file in csv_file_list:\n",
        "    if 'output_summary' in file:\n",
        "        csv_dict[file] = pd.read_csv(os.path.join(csv_dir, file), index_col=False)\n",
        "\n",
        "df = pd.concat([csv_dict[file] for file in csv_dict], ignore_index=True)"
      ],
      "metadata": {
        "id": "07-2eRs2jHSZ"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "DQf0K9GLoEOg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "c5634a57-5d46-47d3-d848-7249b6eb312f"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                           top-1 output  BFA iteration\n",
              "0     [6 7 0 4 0 4 8 9 6 1 5 6 2 7 4 6 8 1 8 8 1 4 0...             49\n",
              "1     [1 8 7 2 7 7 9 7 7 0 6 4 7 9 5 2 1 7 6 2 3 7 1...             49\n",
              "2     [7 7 6 1 2 8 0 7 4 9 3 4 6 6 5 0 7 0 2 7 1 4 7...             49\n",
              "3     [7 3 2 4 7 6 4 5 5 7 6 6 4 6 4 4 1 3 0 7 4 7 4...             49\n",
              "4     [7 3 0 0 4 5 4 5 6 4 5 7 8 4 8 7 8 9 7 5 4 5 6...             49\n",
              "...                                                 ...            ...\n",
              "4024  [6 4 6 0 2 2 0 0 6 9 2 7 9 4 2 2 0 7 7 2 2 0 4...             20\n",
              "4025  [0 9 2 2 2 0 7 8 4 2 0 2 4 1 0 2 3 0 2 2 3 0 2...             20\n",
              "4026  [0 6 2 6 3 2 6 2 9 2 6 1 2 0 2 2 1 2 6 9 0 4 0...             20\n",
              "4027  [3 8 2 3 3 0 4 2 6 2 6 9 0 1 4 1 0 2 7 6 0 4 2...             20\n",
              "4028                  [7 7 9 2 2 9 2 7 8 9 2 2 4 2 9 0]             20\n",
              "\n",
              "[4029 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3cd284f2-f407-4c53-9f90-62625c7a8fff\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>top-1 output</th>\n",
              "      <th>BFA iteration</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[6 7 0 4 0 4 8 9 6 1 5 6 2 7 4 6 8 1 8 8 1 4 0...</td>\n",
              "      <td>49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[1 8 7 2 7 7 9 7 7 0 6 4 7 9 5 2 1 7 6 2 3 7 1...</td>\n",
              "      <td>49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[7 7 6 1 2 8 0 7 4 9 3 4 6 6 5 0 7 0 2 7 1 4 7...</td>\n",
              "      <td>49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[7 3 2 4 7 6 4 5 5 7 6 6 4 6 4 4 1 3 0 7 4 7 4...</td>\n",
              "      <td>49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[7 3 0 0 4 5 4 5 6 4 5 7 8 4 8 7 8 9 7 5 4 5 6...</td>\n",
              "      <td>49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4024</th>\n",
              "      <td>[6 4 6 0 2 2 0 0 6 9 2 7 9 4 2 2 0 7 7 2 2 0 4...</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4025</th>\n",
              "      <td>[0 9 2 2 2 0 7 8 4 2 0 2 4 1 0 2 3 0 2 2 3 0 2...</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4026</th>\n",
              "      <td>[0 6 2 6 3 2 6 2 9 2 6 1 2 0 2 2 1 2 6 9 0 4 0...</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4027</th>\n",
              "      <td>[3 8 2 3 3 0 4 2 6 2 6 9 0 1 4 1 0 2 7 6 0 4 2...</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4028</th>\n",
              "      <td>[7 7 9 2 2 9 2 7 8 9 2 2 4 2 9 0]</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4029 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3cd284f2-f407-4c53-9f90-62625c7a8fff')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3cd284f2-f407-4c53-9f90-62625c7a8fff button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3cd284f2-f407-4c53-9f90-62625c7a8fff');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# plot style\n",
        "sns.set(style=\"whitegrid\")\n",
        "sns.set(style=\"ticks\")\n",
        "# sns.despine()\n",
        "sns.set_style({\"font.sans-serif\":\"DejaVu Sans\"})\n",
        "sns.set_style({\"grid.color\":'0.9'})\n",
        "sns.set_context(\"paper\", font_scale=1.5, rc={\"lines.linewidth\": 1})"
      ],
      "metadata": {
        "id": "HiGAfpZSoIhD"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f, ax = plt.subplots(figsize=(4,4))\n",
        "sns.distplot(df['top-1 output'], kde=False, vertical=True)\n",
        "label_list = ('airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "# plt.xticks(np.arange(0, 10))\n",
        "plt.yticks(np.arange(0, 10), label_list)"
      ],
      "metadata": {
        "id": "Kps9n6hNoNgG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evolution of output under BFA**"
      ],
      "metadata": {
        "id": "90fsaJ6-oWTs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "csv_dir = '/content/BFA/save/2022-11-15/cifar10_resnet18_quan_BFA'\n",
        "\n",
        "csv_file_list = [file for file in os.listdir(\n",
        "    csv_dir) if file.endswith('.csv')\n",
        "]\n",
        "\n",
        "# print(csv_file_list)\n",
        "\n",
        "csv_dict = {}\n",
        "\n",
        "for file in csv_file_list:\n",
        "    if 'output_summary' in file:\n",
        "        tmp_df = pd.read_csv(os.path.join(csv_dir, file), index_col=False)\n",
        "        csv_dict[file] = tmp_df\n",
        "\n",
        "df = pd.concat([csv_dict[file] for file in csv_dict], ignore_index=True)\n"
      ],
      "metadata": {
        "id": "hMGRyvy5oZta"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# change the header of certain column\n",
        "# https://stackoverflow.com/questions/19758364/rename-specific-columns-in-pandas \n",
        "try:\n",
        "    df.rename(columns={'BFA iteration':'iter'}, inplace=True)\n",
        "    df.rename(columns={'top-1 output':''}, inplace=True)\n",
        "except:\n",
        "    pass\n",
        "\n",
        "# drop several iterations for less subfigures\n",
        "# https://chrisalbon.com/python/data_wrangling/pandas_dropping_column_and_rows/\n",
        "for i in [1,2,4,5,7,8,10,11]:\n",
        "    # print(df[df['iter'] != i])\n",
        "    df = df[df['iter'] != i]\n",
        "    # df.drop(df['iter'] == i)\n",
        "\n",
        "# df = pd.concat([df['iter']==iter for iter in [0,3,6,9,12]], ignore_index=True)"
      ],
      "metadata": {
        "id": "SMCw-uProaaT"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "3ejjq-eqogfC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "360b3d38-fe80-4fff-bc8b-15b6d89cd3e4"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                       iter\n",
              "0   [156 628 500 536 865 349 276 642  30 954 241 5...     0\n",
              "1   [ 70 148 963 554 510 802  35 912  26 106 975  ...     0\n",
              "2   [372 510 912 973 509 555 580 537 698   6 118 9...     0\n",
              "3   [156 218 293 212 671 825 625 119 403 403 509 8...     0\n",
              "4   [ 79 555 776 309 403 580 786 625 509 825 628  ...     0\n",
              "5   [975 776 536 406 973 716 944 603  49 628  30 5...     0\n",
              "6   [586 509 509 186 537 540 975 804 670 118  54 4...     0\n",
              "7   [ 56 456 573 979 865 776 509 403 554  89 119 8...     0\n",
              "8   [810 139 758 943 104 251 825  30 664 509 562 9...     0\n",
              "9   [293 510 537 311 628 978 509 168 454 146 580 8...     0\n",
              "10  [976 978 628 973 510 970 802 825 912 776 140 9...     0\n",
              "11  [825 628 912 468 715 554 555 912 625 912 810 9...     0\n",
              "12  [403 537  76  61  67 275 661 251 251 860 683 2...     0\n",
              "13  [315  49 555 510 536 276 562 825 510 847  40 8...     0\n",
              "14  [810 603 843 865  50 253 621 979 628 118 374 8...     0\n",
              "15  [973 865 509 912 537 711 912 645 305  49 454 1...     0\n",
              "16  [118 864 509 373 148  61 642 510 123 634 865 8...     0\n",
              "17  [536 864 776 847 913 510  56  67 352 802  50  ...     0\n",
              "18  [ 30 403 509 275 912 916 912 555 554 918 509 6...     0\n",
              "19  [ 58 537 599 555 864 173 509 325 318 751 555 8...     0\n",
              "20  [912  50 537 509 219 153 148 946 510 410 865 3...     0\n",
              "21  [173 349  91  25 119 293 310 554 403 847 645 9...     0\n",
              "22  [ 61 832 664 122 847 488 802 663 939 865  65 9...     0\n",
              "23  [779 825 937 500 956  91 173 540 293 683 540 8...     0\n",
              "24  [218 300 916 743  35 580 912 561 192 970 346 8...     0\n",
              "25  [509 580 118 287 970 510 123 298 353 825 917 6...     0\n",
              "26  [786 791 218 324 325 510 628 802 634 295 251 6...     0\n",
              "27  [222  65 582 963  11 832 233 825 509 555 104 4...     0\n",
              "28  [683 537 946  68 172 825 698 825 802 860 251 8...     0\n",
              "29  [317 586 876 976 946 865 170 241 403 963 825 3...     0\n",
              "30  [403 663 186 825 946 628 802 631 458 825 865 9...     0\n",
              "31  [895 952 943 943 810 536 558 912 271 353  62 1...     0\n",
              "32  [537 468 621 403   2 847 802 624 310 663 104 5...     0\n",
              "33  [104 403 825 241 561 403 957  64 403 528 953 2...     0\n",
              "34  [ 30 979 688 780 776  61 847 895 410 293 825 4...     0\n",
              "35  [  1 741 483 628 305 536 353 540 403 751 628 3...     0\n",
              "36  [537 865 937 825 974 847 288  50 963 937 148 4...     0\n",
              "37  [865 510 275 825 956 825 979 865 310 177 415 1...     0\n",
              "38  [403 124 555 865 671 490 802 698 251 372 510 5...     0\n",
              "39  [554  65 878 916 864 692 403 996 858  49 776 8...     0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-40a51d7f-a7aa-44c1-bbab-1eb5cd69e991\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>iter</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[156 628 500 536 865 349 276 642  30 954 241 5...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[ 70 148 963 554 510 802  35 912  26 106 975  ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[372 510 912 973 509 555 580 537 698   6 118 9...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[156 218 293 212 671 825 625 119 403 403 509 8...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[ 79 555 776 309 403 580 786 625 509 825 628  ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>[975 776 536 406 973 716 944 603  49 628  30 5...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>[586 509 509 186 537 540 975 804 670 118  54 4...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>[ 56 456 573 979 865 776 509 403 554  89 119 8...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>[810 139 758 943 104 251 825  30 664 509 562 9...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>[293 510 537 311 628 978 509 168 454 146 580 8...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>[976 978 628 973 510 970 802 825 912 776 140 9...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>[825 628 912 468 715 554 555 912 625 912 810 9...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>[403 537  76  61  67 275 661 251 251 860 683 2...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>[315  49 555 510 536 276 562 825 510 847  40 8...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>[810 603 843 865  50 253 621 979 628 118 374 8...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>[973 865 509 912 537 711 912 645 305  49 454 1...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>[118 864 509 373 148  61 642 510 123 634 865 8...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>[536 864 776 847 913 510  56  67 352 802  50  ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>[ 30 403 509 275 912 916 912 555 554 918 509 6...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>[ 58 537 599 555 864 173 509 325 318 751 555 8...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>[912  50 537 509 219 153 148 946 510 410 865 3...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>[173 349  91  25 119 293 310 554 403 847 645 9...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>[ 61 832 664 122 847 488 802 663 939 865  65 9...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>[779 825 937 500 956  91 173 540 293 683 540 8...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>[218 300 916 743  35 580 912 561 192 970 346 8...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>[509 580 118 287 970 510 123 298 353 825 917 6...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>[786 791 218 324 325 510 628 802 634 295 251 6...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>[222  65 582 963  11 832 233 825 509 555 104 4...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>[683 537 946  68 172 825 698 825 802 860 251 8...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>[317 586 876 976 946 865 170 241 403 963 825 3...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>[403 663 186 825 946 628 802 631 458 825 865 9...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>[895 952 943 943 810 536 558 912 271 353  62 1...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>[537 468 621 403   2 847 802 624 310 663 104 5...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>[104 403 825 241 561 403 957  64 403 528 953 2...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>[ 30 979 688 780 776  61 847 895 410 293 825 4...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>[  1 741 483 628 305 536 353 540 403 751 628 3...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>[537 865 937 825 974 847 288  50 963 937 148 4...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>[865 510 275 825 956 825 979 865 310 177 415 1...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>[403 124 555 865 671 490 802 698 251 372 510 5...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>[554  65 878 916 864 692 403 996 858  49 776 8...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-40a51d7f-a7aa-44c1-bbab-1eb5cd69e991')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-40a51d7f-a7aa-44c1-bbab-1eb5cd69e991 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-40a51d7f-a7aa-44c1-bbab-1eb5cd69e991');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "g.fig.savefig(os.path.join(csv_dir,'BFA_output_evolution.pdf'), bbox_inches=\"tight\", transparent=True)\n"
      ],
      "metadata": {
        "id": "YmNqyB9XomG-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Single sample attack**"
      ],
      "metadata": {
        "id": "2ANwmIYQooq2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "csv_dir = '/content/BFA/save/2022-11-15/cifar10_resnet18_quan_BFA_defense_test_binarized'\n",
        "\n",
        "csv_file_list = [file for file in os.listdir(\n",
        "    csv_dir) if file.endswith('.csv')\n",
        "]\n",
        "\n",
        "# print(csv_file_list)\n",
        "\n",
        "csv_dict = {}\n",
        "\n",
        "for file in csv_file_list:\n",
        "    if 'output_summary' in file:\n",
        "        tmp_df = pd.read_csv(os.path.join(csv_dir, file), index_col=False)\n",
        "        csv_dict[file] = tmp_df\n",
        "\n",
        "df = pd.concat([csv_dict[file] for file in csv_dict], ignore_index=True)\n",
        "try:\n",
        "    df.rename(columns={'BFA iteration':'iter'}, inplace=True)\n",
        "    df.rename(columns={'top-1 output':''}, inplace=True)\n",
        "except:\n",
        "    pass\n"
      ],
      "metadata": {
        "id": "miQtkderorAY"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Attack Profile**"
      ],
      "metadata": {
        "id": "CVy4s3gfmYfH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "csv_path1 = '/content/BFA/save/2022-11-15/cifar10_resnet18_quan_BFA_defense_test_binarized/attack_profile_7442.csv'\n",
        "csv_path2 = '/content/BFA/save/2022-11-15/cifar10_resnet18_quan_BFA_defense_test_binarized/attack_profile_9348.csv'\n",
        "\n",
        "df1 = pd.read_csv(csv_path1, index_col=False)\n",
        "df2 = pd.read_csv(csv_path2, index_col=False)"
      ],
      "metadata": {
        "id": "w6dG6SE1jHgI"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LhhCBc0upJxe",
        "outputId": "6e0a7ccf-5b72-4d95-8ec1-647790409f69"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     module idx  bit-flip idx module name     weight idx  \\\n",
            "0             1             1       conv1  [55  1  1  1]   \n",
            "1             1             2       conv1  [55  1  3  0]   \n",
            "2             1             3       conv1  [55  1  6  6]   \n",
            "3             1             4       conv1  [55  2  3  0]   \n",
            "4             1             5       conv1  [59  1  2  0]   \n",
            "..          ...           ...         ...            ...   \n",
            "471           1           472       conv1  [59  1  4  2]   \n",
            "472           1           473       conv1  [59  1  4  3]   \n",
            "473           1           474       conv1  [59  1  4  4]   \n",
            "474           1           475       conv1  [59  1  5  3]   \n",
            "475           1           476       conv1  [59  1  5  4]   \n",
            "\n",
            "     weight before attack  weight after attack  validation accuracy  \\\n",
            "0                    -1.0                  1.0                 61.6   \n",
            "1                    -1.0                  1.0                 61.6   \n",
            "2                    -1.0                  1.0                 61.6   \n",
            "3                    -1.0                  1.0                 61.6   \n",
            "4                     1.0                 -1.0                 61.6   \n",
            "..                    ...                  ...                  ...   \n",
            "471                   1.0                 -1.0                 58.3   \n",
            "472                   1.0                 -1.0                 58.3   \n",
            "473                   1.0                 -1.0                 58.3   \n",
            "474                   1.0                 -1.0                 58.3   \n",
            "475                   1.0                 -1.0                 58.3   \n",
            "\n",
            "     accuracy drop  trial seed  \n",
            "0             0.76        7442  \n",
            "1             0.76        7442  \n",
            "2             0.76        7442  \n",
            "3             0.76        7442  \n",
            "4             0.76        7442  \n",
            "..             ...         ...  \n",
            "471          -1.38        7442  \n",
            "472          -1.38        7442  \n",
            "473          -1.38        7442  \n",
            "474          -1.38        7442  \n",
            "475          -1.38        7442  \n",
            "\n",
            "[476 rows x 9 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(figsize=(6,2))\n",
        "sns.lineplot(x='bit-flip idx', y='validation accuracy', data=df1, label='With defense',color=\"black\")\n",
        "sns.lineplot(x='bit-flip idx', y='validation accuracy', data=df2, label='Without defense', color=\"red\")\n",
        "plt.xlim(0,40)\n",
        "plt.grid(True, 'major', 'y', ls='--', lw=0.8, c='k', alpha=.3)\n",
        "plt.ylabel('accuracy (%)')\n",
        "plt.xlabel('number of bit-flips')"
      ],
      "metadata": {
        "id": "QqRTPiDOjKws",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "outputId": "dafcdcd4-f8ba-4124-c49c-be1131987792"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'number of bit-flips')"
            ]
          },
          "metadata": {},
          "execution_count": 90
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x144 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "def int2bin(input, num_bits):\n",
        "    '''\n",
        "    convert the signed integer value into unsigned integer (2's complement equivalently).\n",
        "    '''\n",
        "    output = input.clone()\n",
        "    output[input.lt(0)] = 2**num_bits + output[input.lt(0)]\n",
        "    return output\n",
        "\n",
        "input = torch.Tensor([-1])\n",
        "int2bin(input,1)"
      ],
      "metadata": {
        "id": "sLkTRxp5jPsi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b689502f-2e55-49aa-a675-d658bcf7bd26"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1.])"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    }
  ]
}